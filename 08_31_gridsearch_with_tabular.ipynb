{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_31_gridsearch_with_tabular.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxEwfj9fcbm7XHADDJdu6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-BS/breathsound-use-stethoscope/blob/main/08_31_gridsearch_with_tabular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFScTM2ibuZ-",
        "outputId": "7cd9e040-dda9-4839-bc3a-16589f95153c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag06Xx-tb_aP",
        "outputId": "3f301cbb-a541-45c2-9523-1aa53652120e"
      },
      "source": [
        "!pip install torchaudio\n",
        "!pip install skorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLAqCYbzBs"
      },
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchaudio\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from torch.utils.data import Subset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oSt87ytIb7Eo",
        "outputId": "d53fb34d-ce6c-4a9a-b568-81d78da35faf"
      },
      "source": [
        "Catholic_file = '/content/drive/MyDrive/breath_data/breath_v2.2/aug_train_v2.2.csv'\n",
        "df = pd.read_csv(Catholic_file)\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002-1.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002-3.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002-4.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1605</th>\n",
              "      <td>wn_0535-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>wn_0588-1.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1607</th>\n",
              "      <td>wn_0599-3.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>wn_0602-2.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>wn_0615-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1610 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           filename      category  class  sex  old\n",
              "0        0002-1.wav  non-wheezing      0    1    7\n",
              "1        0002-2.wav  non-wheezing      0    1    7\n",
              "2        0002-3.wav  non-wheezing      0    1    7\n",
              "3        0002-4.wav  non-wheezing      0    1    7\n",
              "4        0003-2.wav  non-wheezing      0    0    1\n",
              "...             ...           ...    ...  ...  ...\n",
              "1605  wn_0535-4.wav      wheezing      1    0    9\n",
              "1606  wn_0588-1.wav      wheezing      1    0    1\n",
              "1607  wn_0599-3.wav      wheezing      1    1    6\n",
              "1608  wn_0602-2.wav      wheezing      1    1    8\n",
              "1609  wn_0615-4.wav      wheezing      1    1   11\n",
              "\n",
              "[1610 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owHclteEcGZ1"
      },
      "source": [
        "mean = df.old.mean()\n",
        "std = df.old.std()\n",
        "df.old = (df.old - mean) / std"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "SKCd25K6cIsW",
        "outputId": "e52b2b47-d33f-481c-ef7a-8137271e7c33"
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002-1.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002-3.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002-4.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1605</th>\n",
              "      <td>wn_0535-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.523021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>wn_0588-1.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1607</th>\n",
              "      <td>wn_0599-3.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.596315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>wn_0602-2.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.214119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>wn_0615-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.140826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1610 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           filename      category  class  sex       old\n",
              "0        0002-1.wav  non-wheezing      0    1  0.905217\n",
              "1        0002-2.wav  non-wheezing      0    1  0.905217\n",
              "2        0002-3.wav  non-wheezing      0    1  0.905217\n",
              "3        0002-4.wav  non-wheezing      0    1  0.905217\n",
              "4        0003-2.wav  non-wheezing      0    0 -0.948195\n",
              "...             ...           ...    ...  ...       ...\n",
              "1605  wn_0535-4.wav      wheezing      1    0  1.523021\n",
              "1606  wn_0588-1.wav      wheezing      1    0 -0.948195\n",
              "1607  wn_0599-3.wav      wheezing      1    1  0.596315\n",
              "1608  wn_0602-2.wav      wheezing      1    1  1.214119\n",
              "1609  wn_0615-4.wav      wheezing      1    1  2.140826\n",
              "\n",
              "[1610 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "D5ylVOdPcKas",
        "outputId": "1e9e2796-f1dd-4da6-e68f-4f564f1890b7"
      },
      "source": [
        "df['relative_path'] = '/' + df['filename'].astype(str)\n",
        "df = df[['relative_path', 'class', 'sex', 'old']]\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relative_path</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/0002-1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/0002-2.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/0002-3.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/0002-4.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/0003-2.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  relative_path  class  sex       old\n",
              "0   /0002-1.wav      0    1  0.905217\n",
              "1   /0002-2.wav      0    1  0.905217\n",
              "2   /0002-3.wav      0    1  0.905217\n",
              "3   /0002-4.wav      0    1  0.905217\n",
              "4   /0003-2.wav      0    0 -0.948195"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nX3Nio1cL6x"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/breath_data/breath_v2.2/aug_train_v2.2'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1fDIF4EcNVI"
      },
      "source": [
        "class Breath_sound_Util():\n",
        "  \n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    \n",
        "    return (sig, sr)\n",
        "\n",
        "  def resample(aud, newsr):\n",
        "    sig, sr = aud\n",
        "    \n",
        "    if (sr == newsr):\n",
        "     return aud\n",
        "\n",
        "    num_channels = sig.shape[0]\n",
        "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
        "    if (num_channels > 1):\n",
        "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "\n",
        "    return ((resig, newsr))\n",
        "  \n",
        "\n",
        "  def pad(aud, max_ms):\n",
        "    sig, sr = aud\n",
        "    num_rows, sig_len = sig.shape\n",
        "    max_len = sr//1000 * max_ms\n",
        "   \n",
        "    if (sig_len > max_len):\n",
        "      sig = sig[:,:max_len]\n",
        " \n",
        "    elif (sig_len < max_len):\n",
        "\n",
        "      repeated = []\n",
        "      repeated.append(sig)\n",
        "      required_len = max_len - sig_len\n",
        "\n",
        "      while required_len > sig_len : \n",
        "        repeated.append(sig)\n",
        "        require_len -= sig_len\n",
        "      repeated.append(sig[:, :required_len])\n",
        " \n",
        "      sig = torch.cat(repeated, 1)\n",
        "\n",
        "    return (sig, sr)\n",
        "\n",
        "\n",
        "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
        "    sig,sr = aud\n",
        "    top_db = 80\n",
        "    \n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    return (spec)\n",
        "\n",
        "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "\n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    return aug_spec\n",
        "    print(aug_spec)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-oepUqIcQHP"
      },
      "source": [
        "class breathDS(Dataset):\n",
        "    \n",
        "  def __init__(self, df, data_path):\n",
        "    self.df = df\n",
        "    self.data_path = str(data_path)\n",
        "    self.duration = 4000\n",
        "    self.sr = 48000\n",
        "            \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
        "    class_id = self.df.loc[idx, 'class']\n",
        "    \n",
        "    aud = Breath_sound_Util.open(audio_file)\n",
        "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
        "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
        "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
        "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
        "    #여기부터 나이, 성별변수를 집어넣는 과정임\n",
        "    x = self.df.loc[idx, 'old']\n",
        "    y = self.df.loc[idx, 'sex']\n",
        "    x = torch.from_numpy(np.asarray(x).reshape((1,)))\n",
        "    y = torch.from_numpy(np.asarray(y).reshape((1,)))\n",
        "    tabular = torch.cat((x, y), 0)\n",
        "    tabular = tabular.float()\n",
        "    #print(tabular)\n",
        "    #x1 = [\"sex\", \"old\"]\n",
        "    #x2 = x2.\n",
        "    #x2 = x2.iloc[idx].values\n",
        "    \n",
        "    \n",
        "    return [aug_sgram, tabular], class_id"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5Tou6HeO6J"
      },
      "source": [
        "from skorch import NeuralNetClassifier"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8DWr7l9reS3"
      },
      "source": [
        "ds = breathDS(df, data_path)\n",
        "#inputs = ds[0]\n",
        "#inputs2 = ds[1]\n",
        "#outputs = ds[1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjfMK986cR-4"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from skorch import NeuralNetClassifier\n",
        "from datetime import datetime, time as datetime_time, timedelta\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class WhoWheezing(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        conv_layers = []\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv1.bias.data.zero_()\n",
        "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv2.bias.data.zero_()\n",
        "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv3.bias.data.zero_()\n",
        "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv4.bias.data.zero_()\n",
        "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
        "\n",
        "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.lin = nn.Linear(in_features=72, out_features=2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.conv = nn.Sequential(*conv_layers)\n",
        " \n",
        "        self.fc1 = nn.Linear(2, 10)\n",
        "        self.fc2 = nn.Linear(10, 8)\n",
        "\n",
        "    def forward(self, input):\n",
        "        inputs=input[0]\n",
        "        inputs2=input[1]\n",
        "        inputs = self.conv(inputs)\n",
        "        inputs = self.ap(inputs)\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        inputs2 = self.fc1(inputs2)\n",
        "        inputs2 = self.fc2(inputs2)\n",
        "        #inputs가 원래있던 멜스펙트로그램이고\n",
        "        #inputs2가 정형데이터임\n",
        "        x = torch.cat((inputs, inputs2), 1)\n",
        "        x = self.lin(x)\n",
        "        x = self.dropout(x)\n",
        "        inputs = self.sigmoid(x)\n",
        "        return x \n",
        "\n",
        "    '''def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.ap(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        #print(x.size())\n",
        "        #x2 = category\n",
        "        #x2 = x2(self.fc1(x2))\n",
        "        #x2 = x2(self.fc2(x2))\n",
        "        #x = x1 + x2\n",
        "        x = self.lin(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x'''\n",
        "    \n",
        "Model1 = WhoWheezing()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Model1 = Model1.to(device)\n",
        "next(Model1.parameters()).device\n",
        "#input = ds[0]\n",
        "\n",
        "\n",
        "\n",
        "params = {\n",
        "    'lr': [0.0001, 0.001],\n",
        "    'max_epochs': [40, 60, 80, 100],\n",
        "    'batch_size': [16, 32, 64]\n",
        "}\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    Model1,\n",
        "    max_epochs=50,\n",
        "    lr=0.001,\n",
        "    batch_size=16,\n",
        "    iterator_train__shuffle=True,\n",
        "    verbose=1,\n",
        "    train_split=None\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmXhucdjcofe"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkeisNDXPnab",
        "outputId": "bfd2500b-1c38-4452-9d5e-ae26be9689c1"
      },
      "source": [
        "print(ds[1][1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMm66VIDjqOy"
      },
      "source": [
        "from skorch.helper import SliceDataset\n",
        "input = SliceDataset(ds, idx=0)\n",
        "outputs = SliceDataset(ds, idx=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8G39givc2PN"
      },
      "source": [
        "gs = GridSearchCV(net, params, refit=False, cv=5, scoring='accuracy', error_score=\"raise\", verbose=3, n_jobs=-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxZ6X2eJ3Ze2"
      },
      "source": [
        "# row 생략 없이 출력\n",
        "pd.set_option('display.max_rows', None)\n",
        "# col 생략 없이 출력\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGe1544Wcmxd"
      },
      "source": [
        "gs.fit(input, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW2ajJziojio"
      },
      "source": [
        "pd.DataFrame(gs.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-kg8D1eks2"
      },
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebLC5GZsFnK2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}