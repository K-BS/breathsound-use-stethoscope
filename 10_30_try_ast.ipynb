{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535bfe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from torch.utils.data import Subset\n",
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bf1532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>wn_0535-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>wn_0588-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>wn_0599-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>wn_0602-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>wn_0615-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      category  class  sex  old\n",
       "0        0002-1.wav  non-wheezing      0    1    7\n",
       "1        0002-2.wav  non-wheezing      0    1    7\n",
       "2        0002-3.wav  non-wheezing      0    1    7\n",
       "3        0002-4.wav  non-wheezing      0    1    7\n",
       "4        0003-2.wav  non-wheezing      0    0    1\n",
       "...             ...           ...    ...  ...  ...\n",
       "1605  wn_0535-4.wav      wheezing      1    0    9\n",
       "1606  wn_0588-1.wav      wheezing      1    0    1\n",
       "1607  wn_0599-3.wav      wheezing      1    1    6\n",
       "1608  wn_0602-2.wav      wheezing      1    1    8\n",
       "1609  wn_0615-4.wav      wheezing      1    1   11\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catholic_file = 'aug_train_v2.2.csv'\n",
    "df = pd.read_csv(Catholic_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357008ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4f551a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>ts_0613-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>wn_0034-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>ts_0011-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>cp_0028-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>ts_0515-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>rs_0070-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>rs_0590-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>wn_0041-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>wn_0026-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0039-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      category  class  sex  old\n",
       "1362  ts_0613-3.wav      wheezing      1    0    1\n",
       "1470  wn_0034-4.wav  non-wheezing      0    1    2\n",
       "1175  ts_0011-2.wav  non-wheezing      0    1    0\n",
       "299   cp_0028-3.wav  non-wheezing      0    1    3\n",
       "1312  ts_0515-1.wav      wheezing      1    1    9\n",
       "...             ...           ...    ...  ...  ...\n",
       "1139  rs_0070-1.wav      wheezing      1    1    8\n",
       "1110  rs_0590-4.wav      wheezing      1    1    2\n",
       "1492  wn_0041-3.wav  non-wheezing      0    0    2\n",
       "1444  wn_0026-4.wav  non-wheezing      0    0    7\n",
       "105      0039-3.wav  non-wheezing      0    0    3\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27798019",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df.old.mean()\n",
    "std = df.old.std()\n",
    "df.old = (df.old - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46148e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>ts_0613-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.948195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>wn_0034-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>ts_0011-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.257097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>cp_0028-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>ts_0515-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.523021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>rs_0070-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.214119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>rs_0590-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>wn_0041-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>wn_0026-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0039-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      category  class  sex       old\n",
       "1362  ts_0613-3.wav      wheezing      1    0 -0.948195\n",
       "1470  wn_0034-4.wav  non-wheezing      0    1 -0.639293\n",
       "1175  ts_0011-2.wav  non-wheezing      0    1 -1.257097\n",
       "299   cp_0028-3.wav  non-wheezing      0    1 -0.330391\n",
       "1312  ts_0515-1.wav      wheezing      1    1  1.523021\n",
       "...             ...           ...    ...  ...       ...\n",
       "1139  rs_0070-1.wav      wheezing      1    1  1.214119\n",
       "1110  rs_0590-4.wav      wheezing      1    1 -0.639293\n",
       "1492  wn_0041-3.wav  non-wheezing      0    0 -0.639293\n",
       "1444  wn_0026-4.wav  non-wheezing      0    0  0.905217\n",
       "105      0039-3.wav  non-wheezing      0    0 -0.330391\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c01bb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>/ts_0613-3.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.948195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>/wn_0034-4.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>/ts_0011-2.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.257097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>/cp_0028-3.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>/ts_0515-1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.523021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relative_path  class  sex       old\n",
       "1362  /ts_0613-3.wav      1    0 -0.948195\n",
       "1470  /wn_0034-4.wav      0    1 -0.639293\n",
       "1175  /ts_0011-2.wav      0    1 -1.257097\n",
       "299   /cp_0028-3.wav      0    1 -0.330391\n",
       "1312  /ts_0515-1.wav      1    1  1.523021"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['relative_path'] = '/' + df['filename'].astype(str)\n",
    "df = df[['relative_path', 'class', 'sex', 'old']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd5c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'aug_train_v2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ee21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Breath_sound_Util():\n",
    "  \n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    \n",
    "    return (sig, sr)\n",
    "\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == newsr):\n",
    "     return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "  \n",
    "\n",
    "  def pad(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "   \n",
    "    if (sig_len > max_len):\n",
    "      sig = sig[:,:max_len]\n",
    " \n",
    "    elif (sig_len < max_len):\n",
    "\n",
    "      repeated = []\n",
    "      repeated.append(sig)\n",
    "      required_len = max_len - sig_len\n",
    "\n",
    "      while required_len > sig_len : \n",
    "        repeated.append(sig)\n",
    "        require_len -= sig_len\n",
    "      repeated.append(sig[:, :required_len])\n",
    " \n",
    "      sig = torch.cat(repeated, 1)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "    \n",
    "    spec = torchaudio.transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = torchaudio.transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = torchaudio.transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec\n",
    "    print(aug_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8253cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class breathDS(Dataset):\n",
    "    \n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 22050\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    class_id = self.df.loc[idx, 'class']\n",
    "    \n",
    "    aud = Breath_sound_Util.open(audio_file)\n",
    "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
    "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
    "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    #print(aug_sgram.size())\n",
    "    aug_sgram = aug_sgram.squeeze()\n",
    "    aug_sgram = torch.transpose(aug_sgram, 0, 1)\n",
    "    #print(aug_sgram.size())\n",
    "    #여기부터 나이, 성별변수를 집어넣는 과정임\n",
    "    x = self.df.loc[idx, 'old']\n",
    "    y = self.df.loc[idx, 'sex']\n",
    "    x = torch.from_numpy(np.asarray(x).reshape((1,)))\n",
    "    y = torch.from_numpy(np.asarray(y).reshape((1,)))\n",
    "    tabular = torch.cat((x, y), 0)\n",
    "    tabular = tabular.float()\n",
    "    #print(tabular)\n",
    "    #x1 = [\"sex\", \"old\"]\n",
    "    #x2 = x2.\n",
    "    #x2 = x2.iloc[idx].values\n",
    "    #aug_sgram = torch.cat((sgram, aug_sgram), 0)\n",
    "    \n",
    "    \n",
    "    return aug_sgram, tabular, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7434cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brds = breathDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f090449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(brds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53f9286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class BasicBlock(nn.Module):\\n    expansion = 1\\n\\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\\n        super(BasicBlock, self).__init__()\\n        self.conv1 = conv3x3(inplanes, planes, stride)\\n        self.bn1 = nn.BatchNorm2d(planes)\\n        self.relu = nn.ReLU(inplace=True)\\n        self.conv2 = conv3x3(planes, planes)\\n        self.bn2 = nn.BatchNorm2d(planes)\\n\\n        self.ca = ChannelAttention(planes)\\n        self.sa = SpatialAttention()\\n\\n        self.downsample = downsample\\n        self.stride = stride\\n\\n    def forward(self, x):\\n        residual = x\\n\\n        out = self.conv1(x)\\n        out = self.bn1(out)\\n        out = self.relu(out)\\n\\n        out = self.conv2(out)\\n        out = self.bn2(out)\\n\\n        out = self.ca(out) * out\\n        out = self.sa(out) * out\\n\\n        if self.downsample is not None:\\n            residual = self.downsample(x)\\n\\n        out += residual\\n        out = self.relu(out)\\n\\n        return out'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.ca = ChannelAttention(planes * 4)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out'''\n",
    "\n",
    "'''class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6ac7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class ResNet(nn.Module):\\n\\n    def __init__(self, block, layers, num_classes=2):\\n        self.inplanes = 64\\n        super(ResNet, self).__init__()\\n        self.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3,\\n                               bias=False)\\n        self.bn1 = nn.BatchNorm2d(64)\\n        self.relu = nn.ReLU(inplace=True)\\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\\n        self.layer1 = self._make_layer(block, 64, layers[0])\\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\\n        #self.fc_tab = nn.Linear(2, 8)\\n        self.fc_tab2 = nn.Linear(2, 16)\\n        self.fc = nn.Linear((512 * block.expansion)+16, 64)\\n        self.fc2 = nn.Linear(64, num_classes)\\n        #self.fc3 = nn.Linear(32, num_classes)\\n\\n        for m in self.modules():\\n            if isinstance(m, nn.Conv2d):\\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\\n                m.weight.data.normal_(0, math.sqrt(2. / n))\\n            elif isinstance(m, nn.BatchNorm2d):\\n                m.weight.data.fill_(1)\\n                m.bias.data.zero_()\\n\\n    def _make_layer(self, block, planes, blocks, stride=1):\\n        downsample = None\\n        if stride != 1 or self.inplanes != planes * block.expansion:\\n            downsample = nn.Sequential(\\n                nn.Conv2d(self.inplanes, planes * block.expansion,\\n                          kernel_size=1, stride=stride, bias=False),\\n                nn.BatchNorm2d(planes * block.expansion),\\n            )\\n\\n        layers = []\\n        layers.append(block(self.inplanes, planes, stride, downsample))\\n        self.inplanes = planes * block.expansion\\n        for i in range(1, blocks):\\n            layers.append(block(self.inplanes, planes))\\n\\n        return nn.Sequential(*layers)\\n\\n    def forward(self, x, x2):\\n        \\n        x = self.conv1(x)\\n        x = self.bn1(x)\\n        x = self.relu(x)\\n        x = self.maxpool(x)\\n\\n        x = self.layer1(x)\\n        x = self.layer2(x)\\n        x = self.layer3(x)\\n        x = self.layer4(x)\\n\\n        x = self.avgpool(x)\\n        x = x.view(x.size(0), -1)\\n        #x2 = self.fc_tab(x2)\\n        x2 = self.fc_tab2(x2)\\n        x = torch.cat((x, x2), 1)\\n        x = self.fc(x)\\n        x = self.fc2(x)\\n        #x = self.fc3(x)\\n\\n        return x'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #self.fc_tab = nn.Linear(2, 8)\n",
    "        self.fc_tab2 = nn.Linear(2, 16)\n",
    "        self.fc = nn.Linear((512 * block.expansion)+16, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        #self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #x2 = self.fc_tab(x2)\n",
    "        x2 = self.fc_tab2(x2)\n",
    "        x = torch.cat((x, x2), 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "\n",
    "        return x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "897389b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "import os\n",
    "import wget\n",
    "os.environ['TORCH_HOME'] = '../../pretrained_models'\n",
    "import timm\n",
    "from timm.models.layers import to_2tuple,trunc_normal_\n",
    "\n",
    "# override the timm package to relax the input shape constraint.\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=34, patch_size=12, in_chans=1, embed_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class ASTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The AST model.\n",
    "    :param label_dim: the label dimension, i.e., the number of total classes, it is 527 for AudioSet, 50 for ESC-50, and 35 for speechcommands v2-35\n",
    "    :param fstride: the stride of patch spliting on the frequency dimension, for 16*16 patchs, fstride=16 means no overlap, fstride=10 means overlap of 6\n",
    "    :param tstride: the stride of patch spliting on the time dimension, for 16*16 patchs, tstride=16 means no overlap, tstride=10 means overlap of 6\n",
    "    :param input_fdim: the number of frequency bins of the input spectrogram\n",
    "    :param input_tdim: the number of time frames of the input spectrogram\n",
    "    :param imagenet_pretrain: if use ImageNet pretrained model\n",
    "    :param audioset_pretrain: if use full AudioSet and ImageNet pretrained model\n",
    "    :param model_size: the model size of AST, should be in [tiny224, small224, base224, base384], base224 and base 384 are same model, but are trained differently during ImageNet pretraining.\n",
    "    \"\"\"\n",
    "    def __init__(self, label_dim=2, fstride=10, tstride=10, input_fdim=64, input_tdim=172, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=True):\n",
    "\n",
    "        super(ASTModel, self).__init__()\n",
    "        assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
    "\n",
    "        if verbose == True:\n",
    "            print('---------------AST Model Summary---------------')\n",
    "            print('ImageNet pretraining: {:s}, AudioSet pretraining: {:s}'.format(str(imagenet_pretrain),str(audioset_pretrain)))\n",
    "        # override timm input shape restriction\n",
    "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
    "\n",
    "        # if AudioSet pretraining is not used (but ImageNet pretraining may still apply)\n",
    "        if audioset_pretrain == False:\n",
    "            if model_size == 'tiny224':\n",
    "                self.v = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'small224':\n",
    "                self.v = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'base224':\n",
    "                self.v = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'base384':\n",
    "                self.v = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=imagenet_pretrain)\n",
    "            else:\n",
    "                raise Exception('Model size must be one of tiny224, small224, base224, base384.')\n",
    "            self.original_num_patches = self.v.patch_embed.num_patches\n",
    "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "            self.mlp_head = nn.Sequential(nn.LayerNorm(self.original_embedding_dim), nn.Linear(self.original_embedding_dim, label_dim))\n",
    "\n",
    "            # automatcially get the intermediate shape\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
    "            num_patches = f_dim * t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            if verbose == True:\n",
    "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
    "                print('number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # the linear projection layer\n",
    "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
    "            if imagenet_pretrain == True:\n",
    "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
    "                new_proj.bias = self.v.patch_embed.proj.bias\n",
    "            self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            # the positional embedding\n",
    "            if imagenet_pretrain == True:\n",
    "                # get the positional embedding from deit model, skip the first two tokens (cls token and distillation token), reshape it to original 2D shape (24*24).\n",
    "                new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)\n",
    "                # cut (from middle) or interpolate the second dimension of the positional embedding\n",
    "                if t_dim <= self.oringal_hw:\n",
    "                    new_pos_embed = new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2): int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]\n",
    "                else:\n",
    "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')\n",
    "                # cut (from middle) or interpolate the first dimension of the positional embedding\n",
    "                if f_dim <= self.oringal_hw:\n",
    "                    new_pos_embed = new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2): int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]\n",
    "                else:\n",
    "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
    "                # flatten the positional embedding\n",
    "                new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1,2)\n",
    "                # concatenate the above positional embedding with the cls token and distillation token of the deit model.\n",
    "                self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
    "                #print(self.v.pos_embed.size())\n",
    "            else:\n",
    "                # if not use imagenet pretrained model, just randomly initialize a learnable positional embedding\n",
    "                # TODO can use sinusoidal positional embedding instead\n",
    "                new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))\n",
    "                self.v.pos_embed = new_pos_embed\n",
    "                trunc_normal_(self.v.pos_embed, std=.02)\n",
    "\n",
    "        # now load a model that is pretrained on both ImageNet and AudioSet\n",
    "        elif audioset_pretrain == True:\n",
    "            if audioset_pretrain == True and imagenet_pretrain == False:\n",
    "                raise ValueError('currently model pretrained on only audioset is not supported, please set imagenet_pretrain = True to use audioset pretrained model.')\n",
    "            if model_size != 'base384':\n",
    "                raise ValueError('currently only has base384 AudioSet pretrained model.')\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            if os.path.exists('../../pretrained_models/audioset_10_10_0.4593.pth') == False:\n",
    "                # this model performs 0.4593 mAP on the audioset eval set\n",
    "                audioset_mdl_url = 'https://www.dropbox.com/s/cv4knew8mvbrnvq/audioset_0.4593.pth?dl=1'\n",
    "                wget.download(audioset_mdl_url, out='../../pretrained_models/audioset_10_10_0.4593.pth')\n",
    "            sd = torch.load('../../pretrained_models/audioset_10_10_0.4593.pth', map_location=device)\n",
    "            audio_model = ASTModel(label_dim=527, fstride=10, tstride=10, input_fdim=64, input_tdim=172, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
    "            audio_model = torch.nn.DataParallel(audio_model)\n",
    "            audio_model.load_state_dict(sd, strict=False)\n",
    "            self.v = audio_model.module.v\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "            self.mlp_head = nn.Sequential(nn.LayerNorm(self.original_embedding_dim), nn.Linear(self.original_embedding_dim, label_dim))\n",
    "\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
    "            num_patches = f_dim * t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            if verbose == True:\n",
    "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
    "                print('number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 256).transpose(1, 2).reshape(1, 256, 12, 101)\n",
    "            # if the input sequence length is larger than the original audioset (10s), then cut the positional embedding\n",
    "            if t_dim < 101:\n",
    "                new_pos_embed = new_pos_embed[:, :, :, 50 - int(t_dim/2): 50 - int(t_dim/2) + t_dim]\n",
    "            # otherwise interpolate\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')\n",
    "            new_pos_embed = new_pos_embed.reshape(1, 256, num_patches).transpose(1, 2)\n",
    "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
    "\n",
    "    def get_shape(self, fstride, tstride, input_fdim=64, input_tdim=172):\n",
    "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
    "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
    "        test_out = test_proj(test_input)\n",
    "        f_dim = test_out.shape[2]\n",
    "        t_dim = test_out.shape[3]\n",
    "        return f_dim, t_dim\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: the input spectrogram, expected shape: (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n",
    "        :return: prediction\n",
    "        \"\"\"\n",
    "        # expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n",
    "        #print(x.size())\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(x.size())\n",
    "        x = x.transpose(2, 3)\n",
    "        #x = x.squeeze(3)\n",
    "        #print(x.size())\n",
    "        B = x.shape[0]\n",
    "        #print(x.size())\n",
    "        x = self.v.patch_embed(x)\n",
    "        #print(x.size())\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "        dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        #print(x.size())\n",
    "        #print(self.v.pos_embed.size())\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        for blk in self.v.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.v.norm(x)\n",
    "        x = (x[:, 0] + x[:, 1]) / 2\n",
    "\n",
    "        x = self.mlp_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ce053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c32ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e8ecd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: False, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "Model1 = ASTModel(input_tdim=172,label_dim=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model1 = Model1.to(device)\n",
    "next(Model1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75b5cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, num_epochs):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  #optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "  base_optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "  optimizer = SWA(base_optimizer, swa_start=10, swa_freq=5, swa_lr=0.00005)\n",
    "  #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01,\n",
    "                                                ##steps_per_epoch=int(len(train_dl)),\n",
    "                                                #epochs=num_epochs,\n",
    "                                                #anneal_strategy='linear')\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    correct_prediction_1 = 0\n",
    "    total_prediction_1 = 0\n",
    "\n",
    "    for i, data in enumerate(train_dl):\n",
    "        x, labels = data[0].to(device), data[2].to(device)\n",
    "        #inputs, inputs2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        #여기에도 inputs2를 추가시켜줫음. 이제 data[1]이 가리키는건 breathDS의 tablular임\n",
    "        #print(x.size())\n",
    "        #print(x2.size())\n",
    "        x_m, x_s = x.mean(), x.std()\n",
    "        x = (x - x_m) / x_s\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "        _, prediction = torch.max(output,1)\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "    optimizer.swap_swa_sgd()\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/total_prediction\n",
    "    #val_acc = correct_prediction_1/total_prediction_1\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss:.4f}, Accuracy: {acc:.4f}')\n",
    "\n",
    "  print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "982d98d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from torchsummary import summary\\n\\nsummary(Model1, (2, 64, 172))'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from torchsummary import summary\n",
    "\n",
    "summary(Model1, (2, 64, 172))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daac1a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.8876, Accuracy: 0.6925\n",
      "Epoch: 1, Loss: 0.5100, Accuracy: 0.7429\n",
      "Epoch: 2, Loss: 0.5043, Accuracy: 0.7422\n",
      "Epoch: 3, Loss: 0.4964, Accuracy: 0.7391\n",
      "Epoch: 4, Loss: 0.4827, Accuracy: 0.7590\n",
      "Epoch: 5, Loss: 0.4954, Accuracy: 0.7559\n",
      "Epoch: 6, Loss: 0.4788, Accuracy: 0.7609\n",
      "Epoch: 7, Loss: 0.4820, Accuracy: 0.7547\n",
      "Epoch: 8, Loss: 0.4652, Accuracy: 0.7776\n",
      "Epoch: 9, Loss: 0.4837, Accuracy: 0.7640\n",
      "Epoch: 10, Loss: 0.4846, Accuracy: 0.7714\n",
      "Epoch: 11, Loss: 0.4875, Accuracy: 0.7683\n",
      "Epoch: 12, Loss: 0.4907, Accuracy: 0.7658\n",
      "Epoch: 13, Loss: 0.4608, Accuracy: 0.7807\n",
      "Epoch: 14, Loss: 0.4242, Accuracy: 0.8118\n",
      "Epoch: 15, Loss: 0.4541, Accuracy: 0.7876\n",
      "Epoch: 16, Loss: 0.4610, Accuracy: 0.8012\n",
      "Epoch: 17, Loss: 0.4146, Accuracy: 0.8236\n",
      "Epoch: 18, Loss: 0.4359, Accuracy: 0.8037\n",
      "Epoch: 19, Loss: 0.4381, Accuracy: 0.8093\n",
      "Epoch: 20, Loss: 0.4150, Accuracy: 0.8273\n",
      "Epoch: 21, Loss: 0.4101, Accuracy: 0.8304\n",
      "Epoch: 22, Loss: 0.4034, Accuracy: 0.8267\n",
      "Epoch: 23, Loss: 0.3890, Accuracy: 0.8348\n",
      "Epoch: 24, Loss: 0.4258, Accuracy: 0.8161\n",
      "Epoch: 25, Loss: 0.4162, Accuracy: 0.8286\n",
      "Epoch: 26, Loss: 0.3960, Accuracy: 0.8348\n",
      "Epoch: 27, Loss: 0.3810, Accuracy: 0.8453\n",
      "Epoch: 28, Loss: 0.3972, Accuracy: 0.8366\n",
      "Epoch: 29, Loss: 0.3981, Accuracy: 0.8385\n",
      "Epoch: 30, Loss: 0.4007, Accuracy: 0.8193\n",
      "Epoch: 31, Loss: 0.3905, Accuracy: 0.8398\n",
      "Epoch: 32, Loss: 0.3871, Accuracy: 0.8373\n",
      "Epoch: 33, Loss: 0.4473, Accuracy: 0.7938\n",
      "Epoch: 34, Loss: 0.3989, Accuracy: 0.8360\n",
      "Epoch: 35, Loss: 0.4186, Accuracy: 0.8280\n",
      "Epoch: 36, Loss: 0.4190, Accuracy: 0.8280\n",
      "Epoch: 37, Loss: 0.3954, Accuracy: 0.8317\n",
      "Epoch: 38, Loss: 0.4276, Accuracy: 0.8161\n",
      "Epoch: 39, Loss: 0.3696, Accuracy: 0.8590\n",
      "Epoch: 40, Loss: 0.4050, Accuracy: 0.8373\n",
      "Epoch: 41, Loss: 0.3572, Accuracy: 0.8509\n",
      "Epoch: 42, Loss: 0.3731, Accuracy: 0.8466\n",
      "Epoch: 43, Loss: 0.3556, Accuracy: 0.8602\n",
      "Epoch: 44, Loss: 0.3956, Accuracy: 0.8497\n",
      "Epoch: 45, Loss: 0.3763, Accuracy: 0.8441\n",
      "Epoch: 46, Loss: 0.3771, Accuracy: 0.8565\n",
      "Epoch: 47, Loss: 0.3499, Accuracy: 0.8540\n",
      "Epoch: 48, Loss: 0.3827, Accuracy: 0.8516\n",
      "Epoch: 49, Loss: 0.3624, Accuracy: 0.8484\n",
      "Epoch: 50, Loss: 0.4171, Accuracy: 0.8255\n",
      "Epoch: 51, Loss: 0.3445, Accuracy: 0.8547\n",
      "Epoch: 52, Loss: 0.4543, Accuracy: 0.7925\n",
      "Epoch: 53, Loss: 0.3535, Accuracy: 0.8503\n",
      "Epoch: 54, Loss: 0.3849, Accuracy: 0.8516\n",
      "Epoch: 55, Loss: 0.3768, Accuracy: 0.8447\n",
      "Epoch: 56, Loss: 0.4160, Accuracy: 0.8354\n",
      "Epoch: 57, Loss: 0.3566, Accuracy: 0.8472\n",
      "Epoch: 58, Loss: 0.3869, Accuracy: 0.8497\n",
      "Epoch: 59, Loss: 0.3497, Accuracy: 0.8615\n",
      "Epoch: 60, Loss: 0.3807, Accuracy: 0.8373\n",
      "Epoch: 61, Loss: 0.3403, Accuracy: 0.8627\n",
      "Epoch: 62, Loss: 0.3763, Accuracy: 0.8460\n",
      "Epoch: 63, Loss: 0.3530, Accuracy: 0.8522\n",
      "Epoch: 64, Loss: 0.4386, Accuracy: 0.7988\n",
      "Epoch: 65, Loss: 0.3426, Accuracy: 0.8658\n",
      "Epoch: 66, Loss: 0.5306, Accuracy: 0.7540\n",
      "Epoch: 67, Loss: 0.3602, Accuracy: 0.8516\n",
      "Epoch: 68, Loss: 0.5236, Accuracy: 0.7286\n",
      "Epoch: 69, Loss: 0.3569, Accuracy: 0.8528\n",
      "Epoch: 70, Loss: 0.4436, Accuracy: 0.8037\n",
      "Epoch: 71, Loss: 0.3981, Accuracy: 0.8342\n",
      "Epoch: 72, Loss: 0.4663, Accuracy: 0.7932\n",
      "Epoch: 73, Loss: 0.4230, Accuracy: 0.8124\n",
      "Epoch: 74, Loss: 0.4076, Accuracy: 0.8379\n",
      "Epoch: 75, Loss: 0.4102, Accuracy: 0.8273\n",
      "Epoch: 76, Loss: 0.4066, Accuracy: 0.8329\n",
      "Epoch: 77, Loss: 0.3904, Accuracy: 0.8360\n",
      "Epoch: 78, Loss: 0.4260, Accuracy: 0.8255\n",
      "Epoch: 79, Loss: 0.3761, Accuracy: 0.8553\n",
      "Epoch: 80, Loss: 0.4153, Accuracy: 0.8242\n",
      "Epoch: 81, Loss: 0.3869, Accuracy: 0.8453\n",
      "Epoch: 82, Loss: 0.4244, Accuracy: 0.8149\n",
      "Epoch: 83, Loss: 0.3542, Accuracy: 0.8646\n",
      "Epoch: 84, Loss: 0.3969, Accuracy: 0.8255\n",
      "Epoch: 85, Loss: 0.3533, Accuracy: 0.8683\n",
      "Epoch: 86, Loss: 0.3894, Accuracy: 0.8379\n",
      "Epoch: 87, Loss: 0.3480, Accuracy: 0.8627\n",
      "Epoch: 88, Loss: 0.3849, Accuracy: 0.8516\n",
      "Epoch: 89, Loss: 0.3622, Accuracy: 0.8621\n",
      "Epoch: 90, Loss: 0.3657, Accuracy: 0.8590\n",
      "Epoch: 91, Loss: 0.3549, Accuracy: 0.8571\n",
      "Epoch: 92, Loss: 0.3651, Accuracy: 0.8553\n",
      "Epoch: 93, Loss: 0.3582, Accuracy: 0.8571\n",
      "Epoch: 94, Loss: 0.3857, Accuracy: 0.8472\n",
      "Epoch: 95, Loss: 0.3795, Accuracy: 0.8497\n",
      "Epoch: 96, Loss: 0.3574, Accuracy: 0.8466\n",
      "Epoch: 97, Loss: 0.3490, Accuracy: 0.8584\n",
      "Epoch: 98, Loss: 0.3810, Accuracy: 0.8460\n",
      "Epoch: 99, Loss: 0.3423, Accuracy: 0.8733\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "training(Model1, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1271301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.save(Model1.state_dict(), 'best_resnet50_remodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fd32d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0007-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0008-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0010-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0012-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0012-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0014-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0014-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0015-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0018-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0019-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0021-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0022-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0023-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0024-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0026-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0027-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0028-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0029-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0031-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0032-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0033-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0035-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0036-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0037-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0038-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0039-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0610-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0539-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0261-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0043-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0001-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0107-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0411-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0526-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0535-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0538-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0549-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0559-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0063-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0533-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0614-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0606-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0600-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0590-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0568-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0594-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0609-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0615-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0603-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0588-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0025-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename      category  class  sex  old\n",
       "0   0001-2.wav  non-wheezing      0    0    0\n",
       "1   0003-1.wav  non-wheezing      0    0    1\n",
       "2   0004-1.wav  non-wheezing      0    0    1\n",
       "3   0004-4.wav  non-wheezing      0    0    1\n",
       "4   0006-1.wav  non-wheezing      0    1    1\n",
       "5   0007-1.wav  non-wheezing      0    0    7\n",
       "6   0008-1.wav  non-wheezing      0    0    2\n",
       "7   0009-1.wav  non-wheezing      0    0    3\n",
       "8   0010-3.wav  non-wheezing      0    1    3\n",
       "9   0012-1.wav  non-wheezing      0    0    2\n",
       "10  0012-4.wav  non-wheezing      0    0    2\n",
       "11  0014-2.wav  non-wheezing      0    0    2\n",
       "12  0014-3.wav  non-wheezing      0    0    2\n",
       "13  0015-4.wav  non-wheezing      0    1    2\n",
       "14  0018-1.wav  non-wheezing      0    0    1\n",
       "15  0019-4.wav  non-wheezing      0    0    1\n",
       "16  0021-3.wav  non-wheezing      0    0    0\n",
       "17  0022-2.wav  non-wheezing      0    0    3\n",
       "18  0023-2.wav  non-wheezing      0    0    4\n",
       "19  0024-4.wav  non-wheezing      0    0    0\n",
       "20  0026-3.wav  non-wheezing      0    0    7\n",
       "21  0027-1.wav  non-wheezing      0    0    1\n",
       "22  0028-1.wav  non-wheezing      0    1    3\n",
       "23  0029-3.wav  non-wheezing      0    0    0\n",
       "24  0031-4.wav  non-wheezing      0    0    1\n",
       "25  0032-4.wav  non-wheezing      0    1    2\n",
       "26  0033-3.wav  non-wheezing      0    1    5\n",
       "27  0035-1.wav  non-wheezing      0    1    3\n",
       "28  0036-2.wav  non-wheezing      0    0    5\n",
       "29  0037-1.wav  non-wheezing      0    1    2\n",
       "30  0038-3.wav  non-wheezing      0    0    6\n",
       "31  0039-4.wav  non-wheezing      0    0    3\n",
       "32  0610-3.wav  non-wheezing      0    0    7\n",
       "33  0539-2.wav  non-wheezing      0    0    4\n",
       "34  0261-4.wav  non-wheezing      0    0    7\n",
       "35  0043-1.wav  non-wheezing      0    0    1\n",
       "36  0001-4.wav      wheezing      1    0    0\n",
       "37  0107-3.wav      wheezing      1    0    8\n",
       "38  0411-1.wav      wheezing      1    0    8\n",
       "39  0526-4.wav      wheezing      1    0    4\n",
       "40  0535-3.wav      wheezing      1    0    9\n",
       "41  0538-4.wav      wheezing      1    0    1\n",
       "42  0549-2.wav      wheezing      1    0    5\n",
       "43  0559-4.wav      wheezing      1    0   11\n",
       "44  0063-3.wav      wheezing      1    1   11\n",
       "45  0533-3.wav      wheezing      1    0    2\n",
       "46  0614-2.wav      wheezing      1    0    4\n",
       "47  0606-2.wav      wheezing      1    1   10\n",
       "48  0600-1.wav      wheezing      1    0    2\n",
       "49  0590-1.wav      wheezing      1    1    2\n",
       "50  0568-4.wav      wheezing      1    0    0\n",
       "51  0594-1.wav      wheezing      1    1    4\n",
       "52  0609-4.wav      wheezing      1    1    6\n",
       "53  0615-2.wav      wheezing      1    1   11\n",
       "54  0603-2.wav      wheezing      1    1    6\n",
       "55  0588-4.wav      wheezing      1    0    1\n",
       "56  0025-3.wav      wheezing      1    1    0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catholic_file1 = 'test_v2.2.csv'\n",
    "df1 = pd.read_csv(Catholic_file1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "164b4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1.old.mean()\n",
    "std = df1.old.std()\n",
    "df1.old = (df1.old - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f04a66b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/0001-2.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.131772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/0003-1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/0004-1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/0004-4.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/0006-1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.809217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relative_path  class  sex       old\n",
       "0   /0001-2.wav      0    0 -1.131772\n",
       "1   /0003-1.wav      0    0 -0.809217\n",
       "2   /0004-1.wav      0    0 -0.809217\n",
       "3   /0004-4.wav      0    0 -0.809217\n",
       "4   /0006-1.wav      0    1 -0.809217"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['relative_path'] = '/' + df1['filename'].astype(str)\n",
    "df1 = df1[['relative_path', 'class', 'sex', 'old']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78df03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'test_v2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f3a0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Breath_sound_Util1():\n",
    "  \n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    \n",
    "    return (sig, sr)\n",
    "\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == newsr):\n",
    "     return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "  \n",
    "\n",
    "  def pad(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "   \n",
    "    if (sig_len > max_len):\n",
    "      sig = sig[:,:max_len]\n",
    " \n",
    "    elif (sig_len < max_len):\n",
    "\n",
    "      repeated = []\n",
    "      repeated.append(sig)\n",
    "      required_len = max_len - sig_len\n",
    "\n",
    "      while required_len > sig_len : \n",
    "        repeated.append(sig)\n",
    "        require_len -= sig_len\n",
    "      repeated.append(sig[:, :required_len])\n",
    " \n",
    "      sig = torch.cat(repeated, 1)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "    \n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ccafcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class breathDS1(Dataset):\n",
    "    \n",
    "  def __init__(self, df1, data_path):\n",
    "    self.df1 = df1\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 22050\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.df1)    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    audio_file = self.data_path + self.df1.loc[idx, 'relative_path']\n",
    "    class_id = self.df1.loc[idx, 'class']\n",
    "    \n",
    "    aud = Breath_sound_Util.open(audio_file)\n",
    "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
    "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
    "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    aug_sgram = aug_sgram.squeeze()\n",
    "    aug_sgram = torch.transpose(aug_sgram, 0, 1)\n",
    "    #여기부터 나이, 성별변수를 집어넣는 과정임\n",
    "    x = self.df1.loc[idx, 'old']\n",
    "    y = self.df1.loc[idx, 'sex']\n",
    "    x = torch.from_numpy(np.asarray(x).reshape((1,)))\n",
    "    y = torch.from_numpy(np.asarray(y).reshape((1,)))\n",
    "    tabular = torch.cat((x, y), 0)\n",
    "    tabular = tabular.float()\n",
    "    #print(tabular)\n",
    "    #x1 = [\"sex\", \"old\"]\n",
    "    #x2 = x2.\n",
    "    #x2 = x2.iloc[idx].values\n",
    "    #aug_sgram = torch.cat((sgram, aug_sgram), 0)\n",
    "    \n",
    "    \n",
    "    return aug_sgram, tabular, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0b142a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brds1 = breathDS1(df1, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d04d7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader(brds1, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d78978b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(28, device='cuda:0')\n",
      "Accuracy: 0.8070, Total items: 57\n",
      "precision: 0.6923, F1: 0.7660\n",
      "recall: 0.8571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.90      0.78      0.84        36\n",
      "    wheezing       0.69      0.86      0.77        21\n",
      "\n",
      "    accuracy                           0.81        57\n",
      "   macro avg       0.80      0.82      0.80        57\n",
      "weighted avg       0.83      0.81      0.81        57\n",
      "\n",
      "AUC:0.8174603174603174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def inference (model, test_dl):\n",
    "  correct_prediction = 0\n",
    "  total_prediction = 0\n",
    "  TP = 0 \n",
    "  TN = 0\n",
    "  FN = 0\n",
    "  FP = 0\n",
    "  a = []\n",
    "  b = []\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(test_dl):\n",
    "      \n",
    "      x, labels = data[0].to(device), data[2].to(device)\n",
    "      cpu_labels = data[2]\n",
    "      x_m, x_s = x.mean(), x.std()\n",
    "      x = (x - x_m) / x_s\n",
    "      outputs = model(x)\n",
    " \n",
    "      _, prediction = torch.max(outputs,1)\n",
    "      \n",
    "      cpu_prediction = prediction.to('cpu')\n",
    "      correct_prediction += (prediction == labels).sum().item()\n",
    "      total_prediction += prediction.shape[0]\n",
    "          \n",
    "\n",
    "      TP += ((prediction == 1) & (labels == 1)).sum()\n",
    "# TN predict and label are both 0\n",
    "      TN += ((prediction == 0) & (labels == 0)).sum()\n",
    "# FN    predict 0 label 1\n",
    "      FN += ((prediction == 0) & (labels == 1)).sum()\n",
    "# FP    predict 1 label 0\n",
    "      FP += ((prediction == 1) & (labels == 0)).sum()\n",
    "\n",
    "      c = cpu_labels.tolist()\n",
    "      a.extend(c)\n",
    "\n",
    "      d = cpu_prediction.tolist()\n",
    "      b.extend(d)\n",
    "    \n",
    "    # TP : 휘징인데 휘징이라고 판단(잘함)\n",
    "    # FP : 헬시인데 휘징이라고 판단(못함)\n",
    "    # TN : 헬시인데 헬시라고 판단(잘함)\n",
    "    # FN : 휘징인데 헬시라고 판단(못함)\n",
    "    \n",
    "    # POSITIVE : 1(휘징)이라고 판단\n",
    "    # NEGATIVE : 0(헬시)라고 판단\n",
    "    # TRUE : 정답값 1(휘징)\n",
    "    # FALSE : 정답값 0(헬시)\n",
    "    \n",
    "    # PRECISION : 휘징이라고 판단한 것 중 진짜 휘징\n",
    "    # RECALL : 휘징인데 휘징이라고 잘 판단\n",
    "    \n",
    "\n",
    "  precision = TP / (TP + FP)\n",
    "  recall = TP / (TP + FN)\n",
    "  F1 = 2 * recall * precision / (recall + precision)\n",
    "  print(TP)\n",
    "  print(FP)\n",
    "  print(FN)\n",
    "  print(TN)\n",
    "\n",
    "  acc = correct_prediction/total_prediction\n",
    "  print(f'Accuracy: {acc:.4f}, Total items: {total_prediction}')\n",
    "  print(f'precision: {precision:.4f}, F1: {F1:.4f}')\n",
    "  print(f'recall: {recall:.4f}')\n",
    "  target_names = ['healthy', 'wheezing']\n",
    "  print(classification_report(a, b, target_names = target_names))\n",
    "  print(\"AUC:{}\".format(roc_auc_score(a, b)))\n",
    "    \n",
    "  plt.title('Receiver Operating Characteristic')\n",
    "  plt.xlabel('False Positive Rate(1 - Specificity)')\n",
    "  plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "  false_positive_rate, true_positive_rate, thresholds = roc_curve(a, b)\n",
    "  roc_auc = metrics.roc_auc_score(a, b)\n",
    "  plt.plot(false_positive_rate, true_positive_rate, 'b', label='Model (AUC = %0.2f)'% roc_auc)\n",
    "  plt.plot([0,1],[1,1],'y--')\n",
    "  plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "inference(Model1, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adced1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2116f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908b3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
