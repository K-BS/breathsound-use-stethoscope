{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "08_31_train_validation_split.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBU7fbJ0yb-v"
      },
      "source": [
        "**해야할 것**\n",
        "\n",
        "---\n",
        "1. train셋, validation셋 나눠서 스코어 출력하기\n",
        "2. 5-fold cross validation으로 스코어 출력하기\n",
        "3. 5-fold cross validation에서 grid search하기\n",
        "---\n",
        "기존에는 GridsearchCV 패키지를 이용해 1,2,3번에 해당하는 작업을 편하게 진행했지만, INPUT에 정형데이터가 추가되어 더이상 GridsearchCV에 의존할 수 없다.\n",
        "\n",
        "이 노트북에서는 아직 1번까지 달성.\n",
        "2,3 번 빨리해야함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1VZLJ64z472",
        "outputId": "6f70b539-f555-4e40-c298-cee5fcacc655"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slLs9hWCy7nV",
        "outputId": "3f3f8947-095a-4de6-b5ec-2ec910d92f08"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XNu288ny9kX"
      },
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchaudio\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FAVQBI0BzSr-",
        "outputId": "f17dbcc9-0568-4be7-e751-81af92014073"
      },
      "source": [
        "Catholic_file = '/content/drive/MyDrive/breath_data/breath_v2.2/aug_train_v2.2.csv'\n",
        "df = pd.read_csv(Catholic_file)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002-1.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002-3.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002-4.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1605</th>\n",
              "      <td>wn_0535-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>wn_0588-1.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1607</th>\n",
              "      <td>wn_0599-3.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>wn_0602-2.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>wn_0615-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1610 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           filename      category  class  sex  old\n",
              "0        0002-1.wav  non-wheezing      0    1    7\n",
              "1        0002-2.wav  non-wheezing      0    1    7\n",
              "2        0002-3.wav  non-wheezing      0    1    7\n",
              "3        0002-4.wav  non-wheezing      0    1    7\n",
              "4        0003-2.wav  non-wheezing      0    0    1\n",
              "...             ...           ...    ...  ...  ...\n",
              "1605  wn_0535-4.wav      wheezing      1    0    9\n",
              "1606  wn_0588-1.wav      wheezing      1    0    1\n",
              "1607  wn_0599-3.wav      wheezing      1    1    6\n",
              "1608  wn_0602-2.wav      wheezing      1    1    8\n",
              "1609  wn_0615-4.wav      wheezing      1    1   11\n",
              "\n",
              "[1610 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pBssl_Sze5D"
      },
      "source": [
        "mean = df.old.mean()\n",
        "std = df.old.std()\n",
        "df.old = (df.old - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-LrnHfboznIy",
        "outputId": "ff428ab4-0ccc-41db-9da5-9cf6656240ba"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002-1.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002-3.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002-4.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003-2.wav</td>\n",
              "      <td>non-wheezing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1605</th>\n",
              "      <td>wn_0535-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.523021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>wn_0588-1.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1607</th>\n",
              "      <td>wn_0599-3.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.596315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>wn_0602-2.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.214119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>wn_0615-4.wav</td>\n",
              "      <td>wheezing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.140826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1610 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           filename      category  class  sex       old\n",
              "0        0002-1.wav  non-wheezing      0    1  0.905217\n",
              "1        0002-2.wav  non-wheezing      0    1  0.905217\n",
              "2        0002-3.wav  non-wheezing      0    1  0.905217\n",
              "3        0002-4.wav  non-wheezing      0    1  0.905217\n",
              "4        0003-2.wav  non-wheezing      0    0 -0.948195\n",
              "...             ...           ...    ...  ...       ...\n",
              "1605  wn_0535-4.wav      wheezing      1    0  1.523021\n",
              "1606  wn_0588-1.wav      wheezing      1    0 -0.948195\n",
              "1607  wn_0599-3.wav      wheezing      1    1  0.596315\n",
              "1608  wn_0602-2.wav      wheezing      1    1  1.214119\n",
              "1609  wn_0615-4.wav      wheezing      1    1  2.140826\n",
              "\n",
              "[1610 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2IpW5Xq3zoKy",
        "outputId": "9adc9522-07a7-476b-a7be-a113ef9f3f4b"
      },
      "source": [
        "df['relative_path'] = '/' + df['filename'].astype(str)\n",
        "df = df[['relative_path', 'class', 'sex', 'old']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relative_path</th>\n",
              "      <th>class</th>\n",
              "      <th>sex</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/0002-1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/0002-2.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/0002-3.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/0002-4.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/0003-2.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.948195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  relative_path  class  sex       old\n",
              "0   /0002-1.wav      0    1  0.905217\n",
              "1   /0002-2.wav      0    1  0.905217\n",
              "2   /0002-3.wav      0    1  0.905217\n",
              "3   /0002-4.wav      0    1  0.905217\n",
              "4   /0003-2.wav      0    0 -0.948195"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhiHV25MzpgG"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/breath_data/breath_v2.2/aug_train_v2.2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPk76R1XzuCP"
      },
      "source": [
        "class Breath_sound_Util():\n",
        "  \n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    \n",
        "    return (sig, sr)\n",
        "\n",
        "  def resample(aud, newsr):\n",
        "    sig, sr = aud\n",
        "    \n",
        "    if (sr == newsr):\n",
        "     return aud\n",
        "\n",
        "    num_channels = sig.shape[0]\n",
        "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
        "    if (num_channels > 1):\n",
        "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "\n",
        "    return ((resig, newsr))\n",
        "  \n",
        "\n",
        "  def pad(aud, max_ms):\n",
        "    sig, sr = aud\n",
        "    num_rows, sig_len = sig.shape\n",
        "    max_len = sr//1000 * max_ms\n",
        "   \n",
        "    if (sig_len > max_len):\n",
        "      sig = sig[:,:max_len]\n",
        " \n",
        "    elif (sig_len < max_len):\n",
        "\n",
        "      repeated = []\n",
        "      repeated.append(sig)\n",
        "      required_len = max_len - sig_len\n",
        "\n",
        "      while required_len > sig_len : \n",
        "        repeated.append(sig)\n",
        "        require_len -= sig_len\n",
        "      repeated.append(sig[:, :required_len])\n",
        " \n",
        "      sig = torch.cat(repeated, 1)\n",
        "\n",
        "    return (sig, sr)\n",
        "\n",
        "\n",
        "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
        "    sig,sr = aud\n",
        "    top_db = 80\n",
        "    \n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    return (spec)\n",
        "\n",
        "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "\n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    return aug_spec\n",
        "    print(aug_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gRONL5Dzv3m"
      },
      "source": [
        "class breathDS(Dataset):\n",
        "    \n",
        "  def __init__(self, df, data_path):\n",
        "    self.df = df\n",
        "    self.data_path = str(data_path)\n",
        "    self.duration = 4000\n",
        "    self.sr = 48000\n",
        "            \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
        "    class_id = self.df.loc[idx, 'class']\n",
        "    \n",
        "    aud = Breath_sound_Util.open(audio_file)\n",
        "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
        "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
        "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
        "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
        "    #여기부터 나이, 성별변수를 집어넣는 과정임\n",
        "    x = self.df.loc[idx, 'old']\n",
        "    y = self.df.loc[idx, 'sex']\n",
        "    x = torch.from_numpy(np.asarray(x).reshape((1,)))\n",
        "    y = torch.from_numpy(np.asarray(y).reshape((1,)))\n",
        "    tabular = torch.cat((x, y), 0)\n",
        "    tabular = tabular.float()\n",
        "    #print(tabular)\n",
        "    #x1 = [\"sex\", \"old\"]\n",
        "    #x2 = x2.\n",
        "    #x2 = x2.iloc[idx].values\n",
        "    \n",
        "    \n",
        "    return aug_sgram, tabular, class_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQddC09Rz7JN"
      },
      "source": [
        "brds = breathDS(df, data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Ah591iXJ2b",
        "outputId": "e4388330-e122-4067-bf96-6520b7c3c3bb"
      },
      "source": [
        "num_items = len(brds)\n",
        "print(len(brds))\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(brds, [num_train, num_val])\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_8MtPmL0AAf"
      },
      "source": [
        "train_dl = DataLoader(brds, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__LSN1Aa0BV4",
        "outputId": "5a3cab0c-55e1-4be6-9ba9-f8704ef008c6"
      },
      "source": [
        "# --------------------------------------------------------------\n",
        "# 호흡음의 Healthy, Wheezing을 판단하는 Binary Classification Model\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "\n",
        "class WhoWheezing(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        conv_layers = []\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv1.bias.data.zero_()\n",
        "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv2.bias.data.zero_()\n",
        "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv3.bias.data.zero_()\n",
        "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.2)\n",
        "        self.conv4.bias.data.zero_()\n",
        "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
        "\n",
        "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.lin = nn.Linear(in_features=72, out_features=2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.conv = nn.Sequential(*conv_layers)\n",
        " \n",
        "        self.fc1 = nn.Linear(2, 10)\n",
        "        self.fc2 = nn.Linear(10, 8)\n",
        "\n",
        "    def forward(self, inputs, inputs2):\n",
        "        inputs = self.conv(inputs)\n",
        "        inputs = self.ap(inputs)\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        inputs2 = self.fc1(inputs2)\n",
        "        inputs2 = self.fc2(inputs2)\n",
        "        #inputs가 원래있던 멜스펙트로그램이고\n",
        "        #inputs2가 정형데이터임\n",
        "        x = torch.cat((inputs, inputs2), 1)\n",
        "        x = self.lin(x)\n",
        "        x = self.dropout(x)\n",
        "        inputs = self.sigmoid(x)\n",
        "        return x       \n",
        "\n",
        "    '''def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.ap(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        #print(x.size())\n",
        "        #x2 = category\n",
        "        #x2 = x2(self.fc1(x2))\n",
        "        #x2 = x2(self.fc2(x2))\n",
        "        #x = x1 + x2\n",
        "        x = self.lin(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x'''\n",
        "    \n",
        "Model1 = WhoWheezing()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Model1 = Model1.to(device)\n",
        "next(Model1.parameters()).device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDyLmE6I0Cvi"
      },
      "source": [
        "def training(model, train_dl, val_dl, num_epochs):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
        "                                                steps_per_epoch=int(len(train_dl)),\n",
        "                                                epochs=num_epochs,\n",
        "                                                anneal_strategy='linear')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    correct_prediction_1 = 0\n",
        "    total_prediction_1 = 0\n",
        "\n",
        "    for i, data in enumerate(train_dl):\n",
        "        inputs, inputs2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
        "        #여기에도 inputs2를 추가시켜줫음. 이제 data[1]이 가리키는건 breathDS의 tablular임\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, inputs2)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        running_loss += loss.item()\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "    for i, data in enumerate(val_dl):\n",
        "        inputs, inputs2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
        "        #여기에도 inputs2를 추가시켜줫음. 이제 data[1]이 가리키는건 breathDS의 tablular임\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "        outputs = model(inputs, inputs2)\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        correct_prediction_1 += (prediction == labels).sum().item()\n",
        "        total_prediction_1 += prediction.shape[0]\n",
        "\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    val_acc = correct_prediction_1/total_prediction_1\n",
        "    print(f'Epoch: {epoch}, Loss: {avg_loss:.4f}, Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
        "\n",
        "  print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQtpSPDn0E1m",
        "outputId": "b0ae22e0-6539-4b73-e8c6-70527bbef37b"
      },
      "source": [
        "num_epochs=52\n",
        "training(Model1, train_dl, val_dl, num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.4910, Accuracy: 0.7943, Validation Accuracy: 0.7981\n",
            "Epoch: 1, Loss: 0.4853, Accuracy: 0.8106, Validation Accuracy: 0.7826\n",
            "Epoch: 2, Loss: 0.4671, Accuracy: 0.8253, Validation Accuracy: 0.8075\n",
            "Epoch: 3, Loss: 0.4457, Accuracy: 0.8191, Validation Accuracy: 0.8043\n",
            "Epoch: 4, Loss: 0.4686, Accuracy: 0.8152, Validation Accuracy: 0.8106\n",
            "Epoch: 5, Loss: 0.4510, Accuracy: 0.8168, Validation Accuracy: 0.8168\n",
            "Epoch: 6, Loss: 0.4386, Accuracy: 0.8230, Validation Accuracy: 0.7950\n",
            "Epoch: 7, Loss: 0.4480, Accuracy: 0.8175, Validation Accuracy: 0.8168\n",
            "Epoch: 8, Loss: 0.4508, Accuracy: 0.8245, Validation Accuracy: 0.8012\n",
            "Epoch: 9, Loss: 0.4553, Accuracy: 0.7958, Validation Accuracy: 0.8137\n",
            "Epoch: 10, Loss: 0.4526, Accuracy: 0.8175, Validation Accuracy: 0.8261\n",
            "Epoch: 11, Loss: 0.4181, Accuracy: 0.8377, Validation Accuracy: 0.8323\n",
            "Epoch: 12, Loss: 0.4249, Accuracy: 0.8284, Validation Accuracy: 0.8075\n",
            "Epoch: 13, Loss: 0.4433, Accuracy: 0.8276, Validation Accuracy: 0.8012\n",
            "Epoch: 14, Loss: 0.4334, Accuracy: 0.8113, Validation Accuracy: 0.8199\n",
            "Epoch: 15, Loss: 0.4237, Accuracy: 0.8315, Validation Accuracy: 0.8012\n",
            "Epoch: 16, Loss: 0.4436, Accuracy: 0.8175, Validation Accuracy: 0.8075\n",
            "Epoch: 17, Loss: 0.4333, Accuracy: 0.8191, Validation Accuracy: 0.8354\n",
            "Epoch: 18, Loss: 0.4547, Accuracy: 0.8137, Validation Accuracy: 0.8261\n",
            "Epoch: 19, Loss: 0.4288, Accuracy: 0.8339, Validation Accuracy: 0.8106\n",
            "Epoch: 20, Loss: 0.4215, Accuracy: 0.8346, Validation Accuracy: 0.7919\n",
            "Epoch: 21, Loss: 0.4170, Accuracy: 0.8183, Validation Accuracy: 0.8323\n",
            "Epoch: 22, Loss: 0.4220, Accuracy: 0.8269, Validation Accuracy: 0.8354\n",
            "Epoch: 23, Loss: 0.4260, Accuracy: 0.8113, Validation Accuracy: 0.8447\n",
            "Epoch: 24, Loss: 0.4193, Accuracy: 0.8362, Validation Accuracy: 0.8012\n",
            "Epoch: 25, Loss: 0.4415, Accuracy: 0.8339, Validation Accuracy: 0.8137\n",
            "Epoch: 26, Loss: 0.4142, Accuracy: 0.8307, Validation Accuracy: 0.8137\n",
            "Epoch: 27, Loss: 0.3998, Accuracy: 0.8393, Validation Accuracy: 0.8106\n",
            "Epoch: 28, Loss: 0.4029, Accuracy: 0.8238, Validation Accuracy: 0.8447\n",
            "Epoch: 29, Loss: 0.4312, Accuracy: 0.8323, Validation Accuracy: 0.8106\n",
            "Epoch: 30, Loss: 0.3972, Accuracy: 0.8377, Validation Accuracy: 0.8106\n",
            "Epoch: 31, Loss: 0.4274, Accuracy: 0.8315, Validation Accuracy: 0.8106\n",
            "Epoch: 32, Loss: 0.3904, Accuracy: 0.8416, Validation Accuracy: 0.8075\n",
            "Epoch: 33, Loss: 0.4045, Accuracy: 0.8370, Validation Accuracy: 0.8043\n",
            "Epoch: 34, Loss: 0.4062, Accuracy: 0.8339, Validation Accuracy: 0.8199\n",
            "Epoch: 35, Loss: 0.3974, Accuracy: 0.8517, Validation Accuracy: 0.8012\n",
            "Epoch: 36, Loss: 0.4134, Accuracy: 0.8339, Validation Accuracy: 0.7857\n",
            "Epoch: 37, Loss: 0.3947, Accuracy: 0.8416, Validation Accuracy: 0.8012\n",
            "Epoch: 38, Loss: 0.4054, Accuracy: 0.8447, Validation Accuracy: 0.8168\n",
            "Epoch: 39, Loss: 0.4149, Accuracy: 0.8470, Validation Accuracy: 0.8261\n",
            "Epoch: 40, Loss: 0.3991, Accuracy: 0.8362, Validation Accuracy: 0.8137\n",
            "Epoch: 41, Loss: 0.4070, Accuracy: 0.8385, Validation Accuracy: 0.8075\n",
            "Epoch: 42, Loss: 0.4006, Accuracy: 0.8245, Validation Accuracy: 0.8043\n",
            "Epoch: 43, Loss: 0.4035, Accuracy: 0.8377, Validation Accuracy: 0.8168\n",
            "Epoch: 44, Loss: 0.3969, Accuracy: 0.8323, Validation Accuracy: 0.8012\n",
            "Epoch: 45, Loss: 0.3842, Accuracy: 0.8416, Validation Accuracy: 0.8199\n",
            "Epoch: 46, Loss: 0.3898, Accuracy: 0.8385, Validation Accuracy: 0.8292\n",
            "Epoch: 47, Loss: 0.4069, Accuracy: 0.8331, Validation Accuracy: 0.8168\n",
            "Epoch: 48, Loss: 0.3973, Accuracy: 0.8408, Validation Accuracy: 0.8385\n",
            "Epoch: 49, Loss: 0.3845, Accuracy: 0.8556, Validation Accuracy: 0.8168\n",
            "Epoch: 50, Loss: 0.4007, Accuracy: 0.8463, Validation Accuracy: 0.8199\n",
            "Epoch: 51, Loss: 0.3808, Accuracy: 0.8393, Validation Accuracy: 0.8292\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknlXyBq1qHy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}