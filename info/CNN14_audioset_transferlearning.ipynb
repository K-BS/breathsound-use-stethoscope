{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa215f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9990e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>minus_0614-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>minus_0614-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>minus_0615-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>minus_0615-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>minus_0615-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  category  class\n",
       "0           0001-1.wav  wheezing      1\n",
       "1           0001-2.wav   healthy      0\n",
       "2           0001-3.wav  wheezing      1\n",
       "3           0001-4.wav  wheezing      1\n",
       "4           0002-1.wav   healthy      0\n",
       "...                ...       ...    ...\n",
       "1465  minus_0614-3.wav  wheezing      1\n",
       "1466  minus_0614-4.wav  wheezing      1\n",
       "1467  minus_0615-1.wav  wheezing      1\n",
       "1468  minus_0615-2.wav  wheezing      1\n",
       "1469  minus_0615-4.wav   healthy      0\n",
       "\n",
       "[1470 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catholic_file = 'breathdata/augment_train.csv'\n",
    "df = pd.read_csv(Catholic_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217ae0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/0001-1.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/0001-2.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/0001-3.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/0001-4.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/0002-1.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relative_path  class\n",
       "0   /0001-1.wav      1\n",
       "1   /0001-2.wav      0\n",
       "2   /0001-3.wav      1\n",
       "3   /0001-4.wav      1\n",
       "4   /0002-1.wav      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['relative_path'] = '/' + df['filename'].astype(str)\n",
    "df = df[['relative_path', 'class']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918677ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'breathdata/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a57363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "\n",
    "class Breath_sound_Util():\n",
    "  \n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == newsr):\n",
    "     return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "  \n",
    "\n",
    "  def pad(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "   \n",
    "    if (sig_len > max_len):\n",
    "      sig = sig[:,:max_len]\n",
    " \n",
    "    elif (sig_len < max_len):\n",
    "\n",
    "      repeated = []\n",
    "      repeated.append(sig)\n",
    "      required_len = max_len - sig_len\n",
    "\n",
    "      while required_len > sig_len : \n",
    "        repeated.append(sig)\n",
    "        require_len -= sig_len\n",
    "      repeated.append(sig[:, :required_len])\n",
    " \n",
    "      sig = torch.cat(repeated, 1)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "    \n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec\n",
    "    print(aug_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde27747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "class breathDS(Dataset):\n",
    "    \n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 44100\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    class_id = self.df.loc[idx, 'class']\n",
    "    aud = Breath_sound_Util.open(audio_file)\n",
    "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
    "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
    "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    #aug_sgram = aug_sgram.view([-1, 64])\n",
    "    \n",
    "    \n",
    "    return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268605b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "brds = breathDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21def2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(brds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c62954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369477f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_utils import do_mixup, interpolate, pad_framewise_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f264518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "PRETRAINED_CHECKPOINT_PATH=\"/home/nextgen/Desktop/braeth/Cnn14_mAP=0.431.pth\"   # Trained by a later code version, achieves higher mAP than the paper.\n",
    "MODEL_TYPE=\"Cnn14\"\n",
    "\n",
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1),\n",
    "                               padding=(1, 1), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1),\n",
    "                               padding=(1, 1), bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a35d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn14(nn.Module):\n",
    "    def __init__(self, classes_num):\n",
    "        \n",
    "        super(Cnn14, self).__init__()\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    " \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        #x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        #x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        #x = input.unsqueeze(0)\n",
    "        x = input.transpose(1, 3)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "\n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "\n",
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self,classes_num, pretrain_checkpoint=None):\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "        classes_num = 2\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn14(audioset_classes_num)\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"Cnn14_mAP=0.431.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output_dict = self.base(input, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "\n",
    "        clipwise_output =  torch.log_softmax(self.base.fc_audioset(embedding), dim=-1)\n",
    "        #output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return clipwise_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32aeacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transfer_Cnn14(\n",
       "  (base): Cnn14(\n",
       "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_block1): ConvBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block3): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block4): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block5): ConvBlock(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block6): ConvBlock(\n",
       "      (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (fc_audioset): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transfer_Cnn14(classes_num=2,pretrain_checkpoint=\"Cnn14_mAP=0.431.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c351a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1=Transfer_Cnn14(classes_num=2,pretrain_checkpoint=\"Cnn14_mAP=0.431.pth\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model1 = Model1.to(device)\n",
    "next(Model1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20703fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:19<31:51, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6177, Accuracy: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:38<31:15, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.4151, Accuracy: 0.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:57<30:49, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.3203, Accuracy: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:16<30:23, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.2634, Accuracy: 0.9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:34<29:39, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.2126, Accuracy: 0.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:52<29:06, 18.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.2093, Accuracy: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [02:11<28:44, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.1584, Accuracy: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [02:29<28:23, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.1405, Accuracy: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [02:48<28:02, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.1317, Accuracy: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [03:06<27:38, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.1107, Accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [03:24<27:17, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.1056, Accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [03:43<26:58, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.0793, Accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [04:01<26:38, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.0879, Accuracy: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [04:19<26:18, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.1025, Accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [04:38<26:05, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.0791, Accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [04:56<25:45, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.1146, Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [05:15<25:27, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.0888, Accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [05:33<25:08, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.1183, Accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [05:51<24:49, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.0946, Accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [06:10<24:29, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.0963, Accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [06:28<24:10, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.0946, Accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [06:46<23:52, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.1210, Accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [07:05<23:32, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.1089, Accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [07:23<23:15, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.1133, Accuracy: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [07:42<22:59, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.1109, Accuracy: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [08:00<22:40, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.1132, Accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [08:18<22:23, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.0991, Accuracy: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [08:37<22:05, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.1093, Accuracy: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [08:55<21:48, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.1141, Accuracy: 0.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [09:14<21:31, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.4387, Accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [09:32<21:13, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.2544, Accuracy: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [09:51<20:54, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.1301, Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [10:09<20:34, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.0953, Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [10:27<20:17, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.0410, Accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [10:46<19:58, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.1155, Accuracy: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [11:04<19:39, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 0.1369, Accuracy: 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [11:23<19:21, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.1226, Accuracy: 0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [11:41<19:02, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 0.0537, Accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [12:00<18:44, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.0686, Accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [12:18<18:23, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 0.0396, Accuracy: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [12:36<18:04, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 0.1790, Accuracy: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [12:55<17:47, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 0.0554, Accuracy: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [13:13<17:31, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Loss: 0.0371, Accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [13:32<17:13, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 0.0158, Accuracy: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [13:50<16:54, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Loss: 0.0311, Accuracy: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [14:09<16:36, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Loss: 0.0120, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [14:27<16:17, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Loss: 0.0157, Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [14:45<15:57, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Loss: 0.0279, Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [15:04<15:39, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Loss: 0.0142, Accuracy: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [15:22<15:21, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Loss: 0.0310, Accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [15:41<15:02, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 0.0177, Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [15:59<14:45, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Loss: 0.0243, Accuracy: 0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [16:18<14:26, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Loss: 0.0382, Accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [16:36<14:10, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Loss: 0.0103, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [16:55<13:52, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Loss: 0.0176, Accuracy: 0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [17:13<13:32, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Loss: 0.0145, Accuracy: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [17:32<13:12, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Loss: 0.0217, Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [17:50<12:53, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Loss: 0.0113, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [18:08<12:34, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Loss: 0.0069, Accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [18:27<12:17, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, Loss: 0.0155, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [18:45<11:58, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 0.0140, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [19:04<11:39, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Loss: 0.0153, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [19:22<11:25, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Loss: 0.0378, Accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [19:41<11:06, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, Loss: 0.0099, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [20:00<10:50, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Loss: 0.0112, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [20:18<10:29, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Loss: 0.0170, Accuracy: 0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [20:36<10:09, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Loss: 0.0136, Accuracy: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [20:55<09:50, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, Loss: 0.0205, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [21:13<09:32, 18.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Loss: 0.0064, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [21:32<09:18, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Loss: 0.0081, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [21:51<09:00, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Loss: 0.0044, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [22:10<08:42, 18.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, Loss: 0.0148, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [22:29<08:27, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Loss: 0.0080, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [22:48<08:12, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Loss: 0.0044, Accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [23:07<07:55, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Loss: 0.0033, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [23:26<07:36, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, Loss: 0.0031, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [23:45<07:15, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Loss: 0.0050, Accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [24:03<06:53, 18.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Loss: 0.0008, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [24:22<06:34, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Loss: 0.0061, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [24:41<06:14, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, Loss: 0.0043, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [24:59<05:54, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 0.0045, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [25:18<05:38, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81, Loss: 0.0068, Accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [25:37<05:19, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, Loss: 0.0081, Accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [25:56<05:00, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, Loss: 0.0066, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [26:14<04:40, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, Loss: 0.0018, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [26:33<04:21, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, Loss: 0.0039, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [26:52<04:02, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86, Loss: 0.0007, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [27:10<03:44, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, Loss: 0.0007, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [27:29<03:24, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88, Loss: 0.0037, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [27:48<03:06, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, Loss: 0.0016, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [28:07<02:49, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss: 0.0017, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [28:26<02:31, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, Loss: 0.0021, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [28:45<02:12, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92, Loss: 0.0002, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [29:03<01:52, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, Loss: 0.0004, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [29:22<01:33, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, Loss: 0.0020, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [29:40<01:14, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95, Loss: 0.0021, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [29:59<00:55, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Loss: 0.0027, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [30:18<00:37, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, Loss: 0.0019, Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [30:36<00:18, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98, Loss: 0.0017, Accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [30:55<00:00, 18.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Loss: 0.0011, Accuracy: 0.9993\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "def training(model, train_dl, num_epochs):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    for i, data in enumerate(train_dl):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "        \n",
    "\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss:.4f}, Accuracy: {acc:.4f}')\n",
    "\n",
    "  print('Finished Training')\n",
    "    \n",
    "num_epochs=100\n",
    "training(Model1, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c18ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0012-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0013-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0015-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0020-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0020-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0020-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0021-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0023-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0024-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0025-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0029-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0030-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0030-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0031-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0032-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0034-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0036-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0036-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0036-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0037-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0037-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0037-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0038-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0041-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0042-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0043-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0044-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0044-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0063-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0063-3.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0070-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0107-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0526-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0533-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0534-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0559-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0581-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0588-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0588-4.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0593-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0594-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0597-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0600-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0602-2.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0611-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0612-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0613-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0614-1.wav</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  category  class\n",
       "0   0003-1.wav   healthy      0\n",
       "1   0004-1.wav   healthy      0\n",
       "2   0007-1.wav   healthy      0\n",
       "3   0009-1.wav   healthy      0\n",
       "4   0009-4.wav   healthy      0\n",
       "5   0012-2.wav   healthy      0\n",
       "6   0013-2.wav   healthy      0\n",
       "7   0015-1.wav   healthy      0\n",
       "8   0020-1.wav  wheezing      1\n",
       "9   0020-3.wav  wheezing      1\n",
       "10  0020-4.wav  wheezing      1\n",
       "11  0021-2.wav   healthy      0\n",
       "12  0023-1.wav   healthy      0\n",
       "13  0024-3.wav   healthy      0\n",
       "14  0025-3.wav  wheezing      1\n",
       "15  0029-2.wav   healthy      0\n",
       "16  0030-3.wav   healthy      0\n",
       "17  0030-4.wav   healthy      0\n",
       "18  0031-1.wav   healthy      0\n",
       "19  0032-2.wav   healthy      0\n",
       "20  0034-1.wav   healthy      0\n",
       "21  0036-2.wav   healthy      0\n",
       "22  0036-3.wav   healthy      0\n",
       "23  0036-4.wav   healthy      0\n",
       "24  0037-1.wav   healthy      0\n",
       "25  0037-3.wav   healthy      0\n",
       "26  0037-4.wav   healthy      0\n",
       "27  0038-3.wav   healthy      0\n",
       "28  0041-3.wav   healthy      0\n",
       "29  0042-4.wav   healthy      0\n",
       "30  0043-3.wav   healthy      0\n",
       "31  0044-3.wav   healthy      0\n",
       "32  0044-4.wav   healthy      0\n",
       "33  0063-2.wav   healthy      0\n",
       "34  0063-3.wav   healthy      0\n",
       "35  0070-1.wav   healthy      0\n",
       "36  0107-1.wav  wheezing      1\n",
       "37  0526-3.wav  wheezing      1\n",
       "38  0533-2.wav  wheezing      1\n",
       "39  0534-4.wav  wheezing      1\n",
       "40  0559-4.wav  wheezing      1\n",
       "41  0581-4.wav  wheezing      1\n",
       "42  0588-1.wav   healthy      0\n",
       "43  0588-4.wav   healthy      0\n",
       "44  0593-3.wav  wheezing      1\n",
       "45  0594-2.wav  wheezing      1\n",
       "46  0597-2.wav  wheezing      1\n",
       "47  0600-1.wav  wheezing      1\n",
       "48  0602-2.wav   healthy      0\n",
       "49  0611-4.wav  wheezing      1\n",
       "50  0612-1.wav  wheezing      1\n",
       "51  0613-2.wav  wheezing      1\n",
       "52  0614-1.wav   healthy      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catholic_file1 = 'breathdata/test.csv'\n",
    "df1 = pd.read_csv(Catholic_file1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "493fa2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/0003-1.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/0004-1.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/0007-1.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/0009-1.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/0009-4.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relative_path  class\n",
       "0   /0003-1.wav      0\n",
       "1   /0004-1.wav      0\n",
       "2   /0007-1.wav      0\n",
       "3   /0009-1.wav      0\n",
       "4   /0009-4.wav      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['relative_path'] = '/' + df1['filename'].astype(str)\n",
    "df1 = df1[['relative_path', 'class']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b994c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'breathdata/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d9ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Breath_sound_Util1():\n",
    "  \n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    \n",
    "    return (sig, sr)\n",
    "\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == newsr):\n",
    "     return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "  \n",
    "\n",
    "  def pad(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "   \n",
    "    if (sig_len > max_len):\n",
    "      sig = sig[:,:max_len]\n",
    " \n",
    "    elif (sig_len < max_len):\n",
    "\n",
    "      repeated = []\n",
    "      repeated.append(sig)\n",
    "      required_len = max_len - sig_len\n",
    "\n",
    "      while required_len > sig_len : \n",
    "        repeated.append(sig)\n",
    "        require_len -= sig_len\n",
    "      repeated.append(sig[:, :required_len])\n",
    " \n",
    "      sig = torch.cat(repeated, 1)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "    \n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e8a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class breathDS1(Dataset):\n",
    "    \n",
    "  def __init__(self, df1, data_path):\n",
    "    self.df1 = df1\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 44100\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.df1)    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    audio_file = self.data_path + self.df1.loc[idx, 'relative_path']\n",
    "    class_id = self.df1.loc[idx, 'class']\n",
    "    aud = Breath_sound_Util1.open(audio_file)\n",
    "    reaud = Breath_sound_Util1.resample(aud, self.sr)\n",
    "    dur_aud = Breath_sound_Util1.pad(reaud, self.duration)\n",
    "    sgram = Breath_sound_Util1.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "\n",
    "    \n",
    "    return sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e445a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brds1 = breathDS1(df1, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "735cd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = torch.utils.data.DataLoader(brds1, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "778a46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7925, Total items: 53\n",
      "precision: 0.7143, F1: 0.6452\n",
      "recall: 0.5882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.82      0.89      0.85        36\n",
      "    wheezing       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.77      0.74      0.75        53\n",
      "weighted avg       0.79      0.79      0.79        53\n",
      "\n",
      "AUC:0.738562091503268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def inference (Model1, val_dl):\n",
    "  correct_prediction = 0\n",
    "  total_prediction = 0\n",
    "  TP = 0 \n",
    "  TN = 0\n",
    "  FN = 0\n",
    "  FP = 0\n",
    "  a = []\n",
    "  b = []\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(val_dl):\n",
    "      \n",
    "      inputs, labels = data[0].to(device), data[1].to(device)\n",
    "      cpu_labels = data[1]\n",
    "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "      inputs = (inputs - inputs_m) / inputs_s\n",
    "      outputs = Model1(inputs)\n",
    " \n",
    "      _, prediction = torch.max(outputs,1)\n",
    "      \n",
    "      cpu_prediction = prediction.to('cpu')\n",
    "      correct_prediction += (prediction == labels).sum().item()\n",
    "      total_prediction += prediction.shape[0]\n",
    "          \n",
    "\n",
    "      TP += ((prediction == 1) & (labels == 1)).sum()\n",
    "# TN predict and label are both 0\n",
    "      TN += ((prediction == 0) & (labels == 0)).sum()\n",
    "# FN    predict 0 label 1\n",
    "      FN += ((prediction == 0) & (labels == 1)).sum()\n",
    "# FP    predict 1 label 0\n",
    "      FP += ((prediction == 1) & (labels == 0)).sum()\n",
    "\n",
    "      c = cpu_labels.tolist()\n",
    "      a.extend(c)\n",
    "\n",
    "      d = cpu_prediction.tolist()\n",
    "      b.extend(d)\n",
    "    \n",
    "    # TP : 휘징인데 휘징이라고 판단(잘함)\n",
    "    # FP : 헬시인데 휘징이라고 판단(못함)\n",
    "    # TN : 헬시인데 헬시라고 판단(잘함)\n",
    "    # FN : 휘징인데 헬시라고 판단(못함)\n",
    "    \n",
    "    # POSITIVE : 1(휘징)이라고 판단\n",
    "    # NEGATIVE : 0(헬시)라고 판단\n",
    "    # TRUE : 정답값 1(휘징)\n",
    "    # FALSE : 정답값 0(헬시)\n",
    "    \n",
    "    # PRECISION : 휘징이라고 판단한 것 중 진짜 휘징\n",
    "    # RECALL : 휘징인데 휘징이라고 잘 판단\n",
    "    \n",
    "\n",
    "  precision = TP / (TP + FP)\n",
    "  recall = TP / (TP + FN)\n",
    "  F1 = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "  acc = correct_prediction/total_prediction\n",
    "  print(f'Accuracy: {acc:.4f}, Total items: {total_prediction}')\n",
    "  print(f'precision: {precision:.4f}, F1: {F1:.4f}')\n",
    "  print(f'recall: {recall:.4f}')\n",
    "  target_names = ['healthy', 'wheezing']\n",
    "  print(classification_report(a, b, target_names = target_names))\n",
    "  print(\"AUC:{}\".format(roc_auc_score(a, b)))\n",
    "\n",
    "inference(Model1, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b0bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d6361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
