{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_-LdXOGYWjA"
   },
   "source": [
    "train, validation은 일단 나눔. 그리고 cbam적용하는 것이 목표임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AkCLAqCYbzBs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "oSt87ytIb7Eo",
    "outputId": "8ebf5aee-1b50-43c5-df15-d012cc7f8f64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002-3.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>wn_0535-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>wn_0588-1.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>wn_0599-3.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>wn_0602-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>wn_0615-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      category  class  sex  old\n",
       "0        0002-1.wav  non-wheezing      0    1    7\n",
       "1        0002-2.wav  non-wheezing      0    1    7\n",
       "2        0002-3.wav  non-wheezing      0    1    7\n",
       "3        0002-4.wav  non-wheezing      0    1    7\n",
       "4        0003-2.wav  non-wheezing      0    0    1\n",
       "...             ...           ...    ...  ...  ...\n",
       "1605  wn_0535-4.wav      wheezing      1    0    9\n",
       "1606  wn_0588-1.wav      wheezing      1    0    1\n",
       "1607  wn_0599-3.wav      wheezing      1    1    6\n",
       "1608  wn_0602-2.wav      wheezing      1    1    8\n",
       "1609  wn_0615-4.wav      wheezing      1    1   11\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catholic_file = 'aug_train_v2.2.csv'\n",
    "df = pd.read_csv(Catholic_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dVpwEoZ_PmBS"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "jcPf_hvLPwqa",
    "outputId": "7155ec8f-b4d5-4777-a90a-06119a534321"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>rs_0581-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0010-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>cs_0615-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>minus_0042-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>cs_0015-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>cp_0261-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>cp_0108-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>cs_0011-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>cp_0534-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>rs_0016-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename      category  class  sex  old\n",
       "1105     rs_0581-4.wav      wheezing      1    1    7\n",
       "21          0010-1.wav  non-wheezing      0    1    3\n",
       "689      cs_0615-4.wav      wheezing      1    1   11\n",
       "807   minus_0042-4.wav  non-wheezing      0    1    3\n",
       "497      cs_0015-2.wav  non-wheezing      0    1    2\n",
       "...                ...           ...    ...  ...  ...\n",
       "387      cp_0261-2.wav      wheezing      1    0    7\n",
       "450      cp_0108-2.wav      wheezing      1    0    8\n",
       "487      cs_0011-4.wav  non-wheezing      0    1    0\n",
       "398      cp_0534-4.wav      wheezing      1    0    9\n",
       "962      rs_0016-4.wav  non-wheezing      0    0    3\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "owHclteEcGZ1"
   },
   "outputs": [],
   "source": [
    "mean = df.old.mean()\n",
    "std = df.old.std()\n",
    "df.old = (df.old - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "SKCd25K6cIsW",
    "outputId": "7b4273a2-7b7f-425e-af98-4ba9c74812e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>rs_0581-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0010-1.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>cs_0615-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>minus_0042-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>cs_0015-2.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>cp_0261-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>cp_0108-2.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.214119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>cs_0011-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.257097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>cp_0534-4.wav</td>\n",
       "      <td>wheezing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.523021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>rs_0016-4.wav</td>\n",
       "      <td>non-wheezing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename      category  class  sex       old\n",
       "1105     rs_0581-4.wav      wheezing      1    1  0.905217\n",
       "21          0010-1.wav  non-wheezing      0    1 -0.330391\n",
       "689      cs_0615-4.wav      wheezing      1    1  2.140826\n",
       "807   minus_0042-4.wav  non-wheezing      0    1 -0.330391\n",
       "497      cs_0015-2.wav  non-wheezing      0    1 -0.639293\n",
       "...                ...           ...    ...  ...       ...\n",
       "387      cp_0261-2.wav      wheezing      1    0  0.905217\n",
       "450      cp_0108-2.wav      wheezing      1    0  1.214119\n",
       "487      cs_0011-4.wav  non-wheezing      0    1 -1.257097\n",
       "398      cp_0534-4.wav      wheezing      1    0  1.523021\n",
       "962      rs_0016-4.wav  non-wheezing      0    0 -0.330391\n",
       "\n",
       "[1610 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D5ylVOdPcKas",
    "outputId": "dff100e1-4e1c-4319-d146-50936e5aa13a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>/rs_0581-4.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/0010-1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>/cs_0615-4.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>/minus_0042-4.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.330391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>/cs_0015-2.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          relative_path  class  sex       old\n",
       "1105     /rs_0581-4.wav      1    1  0.905217\n",
       "21          /0010-1.wav      0    1 -0.330391\n",
       "689      /cs_0615-4.wav      1    1  2.140826\n",
       "807   /minus_0042-4.wav      0    1 -0.330391\n",
       "497      /cs_0015-2.wav      0    1 -0.639293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['relative_path'] = '/' + df['filename'].astype(str)\n",
    "df = df[['relative_path', 'class', 'sex', 'old']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0nX3Nio1cL6x"
   },
   "outputs": [],
   "source": [
    "data_path = 'aug_train_v2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F1fDIF4EcNVI"
   },
   "outputs": [],
   "source": [
    "class Breath_sound_Util():\n",
    "  \n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    \n",
    "    return (sig, sr)\n",
    "\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == newsr):\n",
    "     return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "  \n",
    "\n",
    "  def pad(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "   \n",
    "    if (sig_len > max_len):\n",
    "      sig = sig[:,:max_len]\n",
    " \n",
    "    elif (sig_len < max_len):\n",
    "\n",
    "      repeated = []\n",
    "      repeated.append(sig)\n",
    "      required_len = max_len - sig_len\n",
    "\n",
    "      while required_len > sig_len : \n",
    "        repeated.append(sig)\n",
    "        require_len -= sig_len\n",
    "      repeated.append(sig[:, :required_len])\n",
    " \n",
    "      sig = torch.cat(repeated, 1)\n",
    "\n",
    "    return (sig, sr)\n",
    "\n",
    "\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "    \n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec\n",
    "    print(aug_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UvNuQ9Irmkqd"
   },
   "outputs": [],
   "source": [
    "class breathDS(Dataset):\n",
    "    \n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 22050\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    class_id = self.df.loc[idx, 'class']\n",
    "    \n",
    "    aud = Breath_sound_Util.open(audio_file)\n",
    "    reaud = Breath_sound_Util.resample(aud, self.sr)\n",
    "    dur_aud = Breath_sound_Util.pad(reaud, self.duration)\n",
    "    sgram = Breath_sound_Util.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = Breath_sound_Util.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    #여기부터 나이, 성별변수를 집어넣는 과정임\n",
    "    x = self.df.loc[idx, 'old']\n",
    "    y = self.df.loc[idx, 'sex']\n",
    "    x = torch.from_numpy(np.asarray(x).reshape((1,)))\n",
    "    y = torch.from_numpy(np.asarray(y).reshape((1,)))\n",
    "    tabular = torch.cat((x, y), 0)\n",
    "    tabular = tabular.float()\n",
    "    #print(tabular)\n",
    "    #x1 = [\"sex\", \"old\"]\n",
    "    #x2 = x2.\n",
    "    #x2 = x2.iloc[idx].values\n",
    "    \n",
    "    \n",
    "    return [aug_sgram, tabular], class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k4pg8lMmvpAi"
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O8DWr7l9reS3"
   },
   "outputs": [],
   "source": [
    "ds = breathDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "hexvLjRtZdMa",
    "outputId": "d3d9604a-771d-4cc4-c0ab-a8a9df222492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_items = len(brds)\\nprint(len(brds))\\nnum_train = round(num_items * 0.8)\\nnum_val = num_items - num_train\\ntrain_ds, val_ds = random_split(brds, [num_train, num_val])\\n\\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''num_items = len(brds)\n",
    "print(len(brds))\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(brds, [num_train, num_val])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YUGpbgkAZda7"
   },
   "outputs": [],
   "source": [
    "#train_dl = DataLoader(brds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EINH3YPeq28K"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aqrBgNrhq2-T"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        #self.fc1 = nn.Linear(2, 8)\n",
    "        #self.fc = nn.Linear((512 * block.expansion)+8, num_classes)\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_tab = nn.Linear(2, 8)\n",
    "        self.fc_tab2 = nn.Linear(8, 16)\n",
    "        self.fc = nn.Linear((512 * block.expansion)+16, num_classes)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        #self.fc1 = nn.Linear(2, 8)\n",
    "        #self.fc2 = nn.Linear(8, 16)\n",
    "        #self.fc = nn.Linear((512 * block.expansion)+16, num_classes)\n",
    "        #self.fc = nn.Linear((512 * block.expansion), 128)\n",
    "        #self.fc_ = nn.Linear(160, num_classes)\n",
    "\n",
    "    def forward(self, x_):\n",
    "        x = x_[0]\n",
    "        x2 = x_[1]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.size())\n",
    "        #x2 = self.fc1(x2)\n",
    "        #x2 = self.fc2(x2)\n",
    "        #print(x2.size())\n",
    "        #x_ = torch.cat((x1, x2), 1)\n",
    "        #x = self.fc(x)\n",
    "        x2 = self.fc_tab(x2)\n",
    "        x2 = self.fc_tab2(x2)\n",
    "        #x2 = self.fc2(x2)\n",
    "        #print(x.size())\n",
    "        #print(x2.size())\n",
    "        x = torch.cat((x, x2), 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yETCdXe07TC9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from skorch.helper import SliceDataset\n",
    "\n",
    "Model1 = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model1 = Model1.to(device)\n",
    "next(Model1.parameters()).device\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'max_epochs': [40, 60, 80],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    Model1,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    max_epochs=80,\n",
    "    lr=0.001,\n",
    "    batch_size=16,\n",
    "    iterator_train__shuffle=True,\n",
    "    verbose=1,\n",
    "    train_split=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ffjq4Gbv8u-Q"
   },
   "outputs": [],
   "source": [
    "x_ = SliceDataset(ds, idx=0)\n",
    "outputs = SliceDataset(ds, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fEyUY_lSElbK"
   },
   "outputs": [],
   "source": [
    "from skorch.helper import SliceDataset\n",
    "\n",
    "#gs = GridSearchCV(net, params, refit=False, cv=5, scoring='accuracy', error_score=\"raise\", verbose=3, n_jobs=-1)\n",
    "gg = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "gs = GridSearchCV(net, params, refit=False, cv=gg, scoring='accuracy', error_score=\"raise\", verbose=3)\n",
    "# row 생략 없이 출력\n",
    "pd.set_option('display.max_rows', None)\n",
    "# col 생략 없이 출력\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "lOKKwFG0MLE2",
    "outputId": "c504da80-ae75-44c8-b176-8e6244f16b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nextgen/anaconda3/envs/kbs_3060/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4328\u001b[0m  35.6904\n",
      "      2        \u001b[36m0.3857\u001b[0m  32.8897\n",
      "      3        \u001b[36m0.3539\u001b[0m  35.0175\n",
      "      4        0.3746  31.5391\n",
      "      5        0.3781  28.4739\n",
      "      6        \u001b[36m0.3486\u001b[0m  28.2469\n",
      "      7        0.3611  28.9684\n",
      "      8        0.3517  29.8711\n",
      "      9        \u001b[36m0.3376\u001b[0m  28.9848\n",
      "     10        \u001b[36m0.3273\u001b[0m  28.9279\n",
      "     11        \u001b[36m0.3060\u001b[0m  28.4486\n",
      "     12        0.3130  29.8069\n",
      "     13        \u001b[36m0.2961\u001b[0m  29.2132\n",
      "     14        \u001b[36m0.2895\u001b[0m  28.2574\n",
      "     15        \u001b[36m0.2694\u001b[0m  28.1237\n",
      "     16        \u001b[36m0.2657\u001b[0m  27.5992\n",
      "     17        \u001b[36m0.2496\u001b[0m  27.6085\n",
      "     18        \u001b[36m0.2282\u001b[0m  27.5776\n",
      "     19        0.2324  27.5819\n",
      "     20        \u001b[36m0.2129\u001b[0m  27.5706\n",
      "     21        \u001b[36m0.2027\u001b[0m  27.7277\n",
      "     22        \u001b[36m0.1878\u001b[0m  27.7005\n",
      "     23        0.1962  27.6702\n",
      "     24        \u001b[36m0.1612\u001b[0m  28.7530\n",
      "     25        0.1768  31.1267\n",
      "     26        0.1826  31.8287\n",
      "     27        \u001b[36m0.1431\u001b[0m  29.5144\n",
      "     28        \u001b[36m0.1257\u001b[0m  29.3228\n",
      "     29        0.1309  30.5935\n",
      "     30        \u001b[36m0.1224\u001b[0m  30.1069\n",
      "     31        \u001b[36m0.1210\u001b[0m  29.2805\n",
      "     32        \u001b[36m0.1061\u001b[0m  32.1952\n",
      "     33        0.1089  29.7066\n",
      "     34        \u001b[36m0.0879\u001b[0m  29.5066\n",
      "     35        0.1047  29.4907\n",
      "     36        0.0985  28.4643\n",
      "     37        0.1061  29.8844\n",
      "     38        0.0948  28.9317\n",
      "     39        \u001b[36m0.0865\u001b[0m  31.5681\n",
      "     40        0.0872  29.5201\n",
      "[CV 1/5] END batch_size=16, lr=0.001, max_epochs=40;, score=0.901 total time=20.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4556\u001b[0m  29.0961\n",
      "      2        \u001b[36m0.3797\u001b[0m  29.0494\n",
      "      3        \u001b[36m0.3793\u001b[0m  28.8525\n",
      "      4        0.3904  29.0433\n",
      "      5        \u001b[36m0.3650\u001b[0m  27.8856\n",
      "      6        \u001b[36m0.3527\u001b[0m  27.5352\n",
      "      7        \u001b[36m0.3504\u001b[0m  27.5706\n",
      "      8        \u001b[36m0.3395\u001b[0m  27.5691\n",
      "      9        \u001b[36m0.3340\u001b[0m  27.5579\n",
      "     10        \u001b[36m0.3259\u001b[0m  27.6022\n",
      "     11        0.3329  27.9636\n",
      "     12        \u001b[36m0.3259\u001b[0m  27.7844\n",
      "     13        \u001b[36m0.3195\u001b[0m  28.0524\n",
      "     14        \u001b[36m0.3009\u001b[0m  27.8020\n",
      "     15        \u001b[36m0.2885\u001b[0m  28.0804\n",
      "     16        0.3102  28.4742\n",
      "     17        \u001b[36m0.2694\u001b[0m  28.5305\n",
      "     18        \u001b[36m0.2448\u001b[0m  30.5972\n",
      "     19        0.2656  31.1094\n",
      "     20        0.2678  27.7413\n",
      "     21        \u001b[36m0.2230\u001b[0m  28.7821\n",
      "     22        0.2384  28.1480\n",
      "     23        \u001b[36m0.1952\u001b[0m  27.6952\n",
      "     24        0.2034  27.7001\n",
      "     25        \u001b[36m0.1813\u001b[0m  28.6754\n",
      "     26        \u001b[36m0.1791\u001b[0m  28.5280\n",
      "     27        0.1934  27.8496\n",
      "     28        \u001b[36m0.1618\u001b[0m  27.7638\n",
      "     29        \u001b[36m0.1490\u001b[0m  27.8439\n",
      "     30        \u001b[36m0.1456\u001b[0m  27.7313\n",
      "     31        \u001b[36m0.1322\u001b[0m  27.6701\n",
      "     32        \u001b[36m0.1221\u001b[0m  28.4909\n",
      "     33        \u001b[36m0.1204\u001b[0m  27.8899\n",
      "     34        0.1352  27.6378\n",
      "     35        0.1260  29.5085\n",
      "     36        \u001b[36m0.1011\u001b[0m  28.7376\n",
      "     37        \u001b[36m0.0934\u001b[0m  28.6522\n",
      "     38        0.1020  28.8709\n",
      "     39        0.1118  28.7423\n",
      "     40        \u001b[36m0.0845\u001b[0m  28.6210\n",
      "[CV 2/5] END batch_size=16, lr=0.001, max_epochs=40;, score=0.938 total time=19.4min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4362\u001b[0m  28.9224\n",
      "      2        \u001b[36m0.3896\u001b[0m  28.7320\n",
      "      3        \u001b[36m0.3767\u001b[0m  27.7521\n",
      "      4        \u001b[36m0.3649\u001b[0m  27.7589\n",
      "      5        \u001b[36m0.3471\u001b[0m  27.5742\n",
      "      6        \u001b[36m0.3450\u001b[0m  27.5871\n",
      "      7        \u001b[36m0.3183\u001b[0m  27.7449\n",
      "      8        \u001b[36m0.3167\u001b[0m  27.8209\n",
      "      9        0.3315  27.7787\n",
      "     10        0.3228  27.7207\n",
      "     11        \u001b[36m0.3086\u001b[0m  27.6712\n",
      "     12        \u001b[36m0.2977\u001b[0m  27.6968\n",
      "     13        \u001b[36m0.2894\u001b[0m  27.6175\n",
      "     14        \u001b[36m0.2828\u001b[0m  27.6244\n",
      "     15        \u001b[36m0.2777\u001b[0m  27.5578\n",
      "     16        \u001b[36m0.2668\u001b[0m  27.5463\n",
      "     17        \u001b[36m0.2444\u001b[0m  27.5795\n",
      "     18        \u001b[36m0.2304\u001b[0m  27.5620\n",
      "     19        \u001b[36m0.2230\u001b[0m  27.4857\n",
      "     20        0.2231  27.4953\n",
      "     21        \u001b[36m0.2016\u001b[0m  27.6003\n",
      "     22        0.2082  27.5951\n",
      "     23        0.2087  27.5987\n",
      "     24        \u001b[36m0.1754\u001b[0m  27.5705\n",
      "     25        \u001b[36m0.1738\u001b[0m  27.5109\n",
      "     26        \u001b[36m0.1433\u001b[0m  27.5701\n",
      "     27        0.1438  27.5551\n",
      "     28        0.1707  27.5172\n",
      "     29        \u001b[36m0.1262\u001b[0m  27.5475\n",
      "     30        0.1375  27.5983\n",
      "     31        0.1279  27.6201\n",
      "     32        \u001b[36m0.1211\u001b[0m  27.5209\n",
      "     33        0.1273  27.5287\n",
      "     34        \u001b[36m0.1113\u001b[0m  27.5875\n",
      "     35        0.1393  27.5358\n",
      "     36        \u001b[36m0.0894\u001b[0m  27.4866\n",
      "     37        0.1180  27.7058\n",
      "     38        0.0963  27.6160\n",
      "     39        \u001b[36m0.0724\u001b[0m  27.7010\n",
      "     40        \u001b[36m0.0701\u001b[0m  27.7131\n",
      "[CV 3/5] END batch_size=16, lr=0.001, max_epochs=40;, score=0.898 total time=18.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4282\u001b[0m  27.6526\n",
      "      2        \u001b[36m0.3939\u001b[0m  27.6573\n",
      "      3        0.3952  27.6623\n",
      "      4        \u001b[36m0.3590\u001b[0m  27.6130\n",
      "      5        0.3765  27.6534\n",
      "      6        \u001b[36m0.3523\u001b[0m  27.7312\n",
      "      7        \u001b[36m0.3382\u001b[0m  28.8554\n",
      "      8        0.3417  29.7058\n",
      "      9        0.3428  28.3731\n",
      "     10        0.3423  28.5125\n",
      "     11        \u001b[36m0.3116\u001b[0m  29.4935\n",
      "     12        0.3188  28.6161\n",
      "     13        \u001b[36m0.3008\u001b[0m  28.3265\n",
      "     14        \u001b[36m0.2877\u001b[0m  28.2458\n",
      "     15        0.2946  30.2525\n",
      "     16        \u001b[36m0.2825\u001b[0m  29.6400\n",
      "     17        \u001b[36m0.2678\u001b[0m  29.2625\n",
      "     18        \u001b[36m0.2467\u001b[0m  28.5565\n",
      "     19        0.2585  27.9457\n",
      "     20        \u001b[36m0.2389\u001b[0m  28.7713\n",
      "     21        \u001b[36m0.2283\u001b[0m  28.5879\n",
      "     22        \u001b[36m0.2184\u001b[0m  27.8763\n",
      "     23        \u001b[36m0.2099\u001b[0m  28.7494\n",
      "     24        \u001b[36m0.2093\u001b[0m  28.0097\n",
      "     25        \u001b[36m0.1947\u001b[0m  27.8275\n",
      "     26        \u001b[36m0.1794\u001b[0m  28.1044\n",
      "     27        \u001b[36m0.1681\u001b[0m  28.3577\n",
      "     28        \u001b[36m0.1385\u001b[0m  29.0017\n",
      "     29        0.1815  27.9228\n",
      "     30        0.1656  27.8317\n",
      "     31        0.1435  27.5058\n",
      "     32        \u001b[36m0.1271\u001b[0m  27.7166\n",
      "     33        \u001b[36m0.1224\u001b[0m  28.3906\n",
      "     34        0.1286  27.9874\n",
      "     35        \u001b[36m0.1097\u001b[0m  28.6010\n",
      "     36        \u001b[36m0.0952\u001b[0m  27.9464\n",
      "     37        0.1221  27.8560\n",
      "     38        0.0987  28.4236\n",
      "     39        \u001b[36m0.0842\u001b[0m  28.8838\n",
      "     40        0.0944  29.7263\n",
      "[CV 4/5] END batch_size=16, lr=0.001, max_epochs=40;, score=0.907 total time=19.4min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4456\u001b[0m  28.8614\n",
      "      2        \u001b[36m0.3806\u001b[0m  28.7049\n",
      "      3        \u001b[36m0.3564\u001b[0m  28.2088\n",
      "      4        0.3715  27.5831\n",
      "      5        0.3634  27.6371\n",
      "      6        \u001b[36m0.3497\u001b[0m  27.6748\n",
      "      7        0.3511  27.7314\n",
      "      8        \u001b[36m0.3247\u001b[0m  27.6593\n",
      "      9        0.3371  27.7098\n",
      "     10        0.3309  27.7448\n",
      "     11        \u001b[36m0.2931\u001b[0m  27.7609\n",
      "     12        0.3106  27.7486\n",
      "     13        \u001b[36m0.2833\u001b[0m  27.6172\n",
      "     14        \u001b[36m0.2714\u001b[0m  27.5891\n",
      "     15        \u001b[36m0.2417\u001b[0m  27.6355\n",
      "     16        0.2599  27.5478\n",
      "     17        0.2447  27.6014\n",
      "     18        \u001b[36m0.2395\u001b[0m  27.6641\n",
      "     19        \u001b[36m0.2244\u001b[0m  27.5920\n",
      "     20        \u001b[36m0.2012\u001b[0m  27.6069\n",
      "     21        \u001b[36m0.1960\u001b[0m  27.6254\n",
      "     22        \u001b[36m0.1949\u001b[0m  27.6515\n",
      "     23        \u001b[36m0.1673\u001b[0m  27.6011\n",
      "     24        \u001b[36m0.1599\u001b[0m  27.5199\n",
      "     25        \u001b[36m0.1476\u001b[0m  27.4986\n",
      "     26        \u001b[36m0.1385\u001b[0m  27.5516\n",
      "     27        0.1554  27.5966\n",
      "     28        0.1481  27.7046\n",
      "     29        \u001b[36m0.1198\u001b[0m  27.7223\n",
      "     30        \u001b[36m0.1177\u001b[0m  27.6984\n",
      "     31        0.1455  27.7075\n",
      "     32        \u001b[36m0.1067\u001b[0m  27.7468\n",
      "     33        0.1097  27.7254\n",
      "     34        \u001b[36m0.1033\u001b[0m  27.7589\n",
      "     35        \u001b[36m0.0758\u001b[0m  27.7287\n",
      "     36        0.0859  27.5140\n",
      "     37        0.0852  27.5201\n",
      "     38        0.0927  28.1212\n",
      "     39        0.0802  27.5242\n",
      "     40        0.1031  28.0341\n",
      "[CV 5/5] END batch_size=16, lr=0.001, max_epochs=40;, score=0.851 total time=19.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4239\u001b[0m  27.5927\n",
      "      2        \u001b[36m0.3788\u001b[0m  27.6225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.3857  27.8673\n",
      "      4        \u001b[36m0.3650\u001b[0m  28.5805\n",
      "      5        \u001b[36m0.3570\u001b[0m  28.0511\n",
      "      6        0.3628  28.9034\n",
      "      7        \u001b[36m0.3505\u001b[0m  27.8441\n",
      "      8        \u001b[36m0.3367\u001b[0m  29.2521\n",
      "      9        \u001b[36m0.3341\u001b[0m  28.2375\n",
      "     10        \u001b[36m0.3107\u001b[0m  28.7352\n",
      "     11        0.3185  29.3530\n",
      "     12        \u001b[36m0.3025\u001b[0m  29.4627\n",
      "     13        \u001b[36m0.2784\u001b[0m  28.6358\n",
      "     14        0.2861  29.1840\n",
      "     15        \u001b[36m0.2647\u001b[0m  29.1849\n",
      "     16        \u001b[36m0.2524\u001b[0m  28.8177\n",
      "     17        \u001b[36m0.2390\u001b[0m  28.2498\n",
      "     18        \u001b[36m0.2221\u001b[0m  30.0158\n",
      "     19        0.2232  28.6442\n",
      "     20        \u001b[36m0.2152\u001b[0m  28.8832\n",
      "     21        \u001b[36m0.1836\u001b[0m  27.8555\n",
      "     22        \u001b[36m0.1773\u001b[0m  27.7898\n",
      "     23        \u001b[36m0.1632\u001b[0m  27.6680\n",
      "     24        0.1735  28.2876\n",
      "     25        \u001b[36m0.1612\u001b[0m  28.5192\n",
      "     26        \u001b[36m0.1303\u001b[0m  29.4371\n",
      "     27        0.1416  28.6511\n",
      "     28        0.1470  28.0895\n",
      "     29        0.1370  28.1024\n",
      "     30        \u001b[36m0.1015\u001b[0m  28.6730\n",
      "     31        \u001b[36m0.0963\u001b[0m  27.9200\n",
      "     32        0.1103  28.0997\n",
      "     33        0.0977  29.0495\n",
      "     34        0.1185  27.8489\n",
      "     35        0.1133  27.8899\n",
      "     36        0.0978  27.8757\n",
      "     37        \u001b[36m0.0742\u001b[0m  27.8686\n",
      "     38        0.0771  27.9013\n",
      "     39        0.0943  27.8176\n",
      "     40        0.0861  27.8777\n",
      "     41        0.0801  28.2212\n",
      "     42        \u001b[36m0.0618\u001b[0m  29.4658\n",
      "     43        0.0717  28.8463\n",
      "     44        \u001b[36m0.0564\u001b[0m  29.2607\n",
      "     45        0.0987  28.7902\n",
      "     46        0.0582  28.5594\n",
      "     47        \u001b[36m0.0524\u001b[0m  28.5615\n",
      "     48        \u001b[36m0.0502\u001b[0m  27.7578\n",
      "     49        0.0926  28.0721\n",
      "     50        0.0556  28.6275\n",
      "     51        0.0757  28.9424\n",
      "     52        0.0678  28.6785\n",
      "     53        0.0503  28.8203\n",
      "     54        0.0573  28.3648\n",
      "     55        \u001b[36m0.0408\u001b[0m  28.1053\n",
      "     56        0.0695  28.8708\n",
      "     57        0.0506  28.6988\n",
      "     58        0.0564  28.0597\n",
      "     59        \u001b[36m0.0385\u001b[0m  28.8164\n",
      "     60        0.0416  28.1458\n",
      "[CV 1/5] END batch_size=16, lr=0.001, max_epochs=60;, score=0.907 total time=28.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4282\u001b[0m  28.0463\n",
      "      2        \u001b[36m0.4144\u001b[0m  28.2552\n",
      "      3        \u001b[36m0.3742\u001b[0m  27.7463\n",
      "      4        \u001b[36m0.3679\u001b[0m  27.6540\n",
      "      5        \u001b[36m0.3523\u001b[0m  27.6590\n",
      "      6        0.3581  27.6317\n",
      "      7        0.3598  27.6697\n",
      "      8        \u001b[36m0.3386\u001b[0m  27.6983\n",
      "      9        0.3512  27.6601\n",
      "     10        \u001b[36m0.3328\u001b[0m  27.6885\n",
      "     11        \u001b[36m0.3212\u001b[0m  27.6253\n",
      "     12        \u001b[36m0.3032\u001b[0m  27.7251\n",
      "     13        0.3068  27.6194\n",
      "     14        \u001b[36m0.2992\u001b[0m  27.5662\n",
      "     15        0.3236  27.6274\n",
      "     16        \u001b[36m0.2885\u001b[0m  27.6608\n",
      "     17        \u001b[36m0.2709\u001b[0m  27.6209\n",
      "     18        \u001b[36m0.2520\u001b[0m  27.5769\n",
      "     19        0.2692  27.6146\n",
      "     20        \u001b[36m0.2366\u001b[0m  27.6337\n",
      "     21        \u001b[36m0.2317\u001b[0m  27.6488\n",
      "     22        \u001b[36m0.2253\u001b[0m  27.6917\n",
      "     23        \u001b[36m0.2077\u001b[0m  27.6656\n",
      "     24        0.2253  27.8012\n",
      "     25        \u001b[36m0.2064\u001b[0m  27.7673\n",
      "     26        0.2114  27.7328\n",
      "     27        \u001b[36m0.1591\u001b[0m  27.7441\n",
      "     28        0.1656  27.9259\n",
      "     29        \u001b[36m0.1422\u001b[0m  27.7431\n",
      "     30        0.1527  27.7372\n",
      "     31        0.1483  27.7492\n",
      "     32        0.1658  27.7037\n",
      "     33        0.1509  27.6958\n",
      "     34        \u001b[36m0.1208\u001b[0m  27.7690\n",
      "     35        \u001b[36m0.1101\u001b[0m  27.6298\n",
      "     36        0.1196  27.6427\n",
      "     37        \u001b[36m0.1011\u001b[0m  27.6692\n",
      "     38        0.1259  27.6659\n",
      "     39        \u001b[36m0.0966\u001b[0m  27.7048\n",
      "     40        \u001b[36m0.0886\u001b[0m  27.5999\n",
      "     41        \u001b[36m0.0829\u001b[0m  27.7206\n",
      "     42        0.0983  27.7143\n",
      "     43        0.1098  27.6167\n",
      "     44        0.0895  27.6907\n",
      "     45        \u001b[36m0.0778\u001b[0m  27.6668\n",
      "     46        0.0806  27.6509\n",
      "     47        0.0854  27.6937\n",
      "     48        \u001b[36m0.0550\u001b[0m  27.6960\n",
      "     49        0.1133  27.6698\n",
      "     50        0.0753  27.6851\n",
      "     51        0.0663  27.7324\n",
      "     52        0.0809  27.7361\n",
      "     53        0.0850  27.6865\n",
      "     54        0.0580  27.6919\n",
      "     55        0.0761  27.7291\n",
      "     56        0.0664  27.7352\n",
      "     57        \u001b[36m0.0500\u001b[0m  27.7626\n",
      "     58        0.0656  27.8091\n",
      "     59        \u001b[36m0.0498\u001b[0m  27.8441\n",
      "     60        0.0738  27.8242\n",
      "[CV 2/5] END batch_size=16, lr=0.001, max_epochs=60;, score=0.922 total time=28.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4250\u001b[0m  27.7725\n",
      "      2        \u001b[36m0.3925\u001b[0m  27.7952\n",
      "      3        \u001b[36m0.3708\u001b[0m  27.8359\n",
      "      4        0.3723  27.8001\n",
      "      5        0.3736  27.7605\n",
      "      6        \u001b[36m0.3610\u001b[0m  27.7930\n",
      "      7        \u001b[36m0.3474\u001b[0m  27.8064\n",
      "      8        \u001b[36m0.3293\u001b[0m  27.7625\n",
      "      9        \u001b[36m0.3220\u001b[0m  27.8089\n",
      "     10        0.3281  27.7514\n",
      "     11        \u001b[36m0.2990\u001b[0m  27.7864\n",
      "     12        0.3288  27.8421\n",
      "     13        \u001b[36m0.2958\u001b[0m  27.8102\n",
      "     14        0.3044  27.7901\n",
      "     15        \u001b[36m0.2876\u001b[0m  27.7935\n",
      "     16        0.3065  27.7780\n",
      "     17        \u001b[36m0.2722\u001b[0m  27.7648\n",
      "     18        \u001b[36m0.2524\u001b[0m  27.7553\n",
      "     19        \u001b[36m0.2423\u001b[0m  27.7769\n",
      "     20        \u001b[36m0.2235\u001b[0m  27.8422\n",
      "     21        0.2337  28.0612\n",
      "     22        0.2277  27.6925\n",
      "     23        \u001b[36m0.2019\u001b[0m  27.5745\n",
      "     24        0.2061  27.5052\n",
      "     25        \u001b[36m0.1807\u001b[0m  27.5448\n",
      "     26        0.1807  27.5279\n",
      "     27        0.2065  27.5402\n",
      "     28        \u001b[36m0.1473\u001b[0m  27.7760\n",
      "     29        \u001b[36m0.1409\u001b[0m  27.7583\n",
      "     30        0.1676  27.7884\n",
      "     31        \u001b[36m0.1193\u001b[0m  27.5027\n",
      "     32        0.1247  27.5424\n",
      "     33        0.1511  27.5849\n",
      "     34        0.1724  27.5652\n",
      "     35        \u001b[36m0.1168\u001b[0m  27.5997\n",
      "     36        \u001b[36m0.1028\u001b[0m  27.5204\n",
      "     37        \u001b[36m0.0913\u001b[0m  27.5702\n",
      "     38        0.1167  27.5919\n",
      "     39        0.1111  27.5384\n",
      "     40        0.1004  27.5698\n",
      "     41        0.0915  27.7620\n",
      "     42        \u001b[36m0.0696\u001b[0m  27.6601\n",
      "     43        0.0808  27.5776\n",
      "     44        0.0702  27.5649\n",
      "     45        0.0897  27.5640\n",
      "     46        0.0825  27.5641\n",
      "     47        \u001b[36m0.0656\u001b[0m  27.5438\n",
      "     48        0.0720  27.5738\n",
      "     49        0.0802  27.5938\n",
      "     50        0.0723  27.6662\n",
      "     51        0.0703  27.6821\n",
      "     52        \u001b[36m0.0544\u001b[0m  27.5589\n",
      "     53        0.0765  27.5317\n",
      "     54        \u001b[36m0.0378\u001b[0m  27.5884\n",
      "     55        0.0816  27.5741\n",
      "     56        0.0605  27.5641\n",
      "     57        0.0480  27.5635\n",
      "     58        0.0628  27.5742\n",
      "     59        0.0647  27.6211\n",
      "     60        0.0618  27.5977\n",
      "[CV 3/5] END batch_size=16, lr=0.001, max_epochs=60;, score=0.901 total time=28.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4338\u001b[0m  27.6249\n",
      "      2        \u001b[36m0.3943\u001b[0m  27.5872\n",
      "      3        \u001b[36m0.3744\u001b[0m  27.5939\n",
      "      4        \u001b[36m0.3713\u001b[0m  27.6036\n",
      "      5        \u001b[36m0.3604\u001b[0m  27.6142\n",
      "      6        \u001b[36m0.3595\u001b[0m  27.6235\n",
      "      7        \u001b[36m0.3555\u001b[0m  27.6174\n",
      "      8        \u001b[36m0.3363\u001b[0m  27.6380\n",
      "      9        \u001b[36m0.3247\u001b[0m  27.6952\n",
      "     10        \u001b[36m0.3127\u001b[0m  27.6151\n",
      "     11        0.3133  27.6125\n",
      "     12        \u001b[36m0.3001\u001b[0m  27.6583\n",
      "     13        0.3126  27.5770\n",
      "     14        0.3037  27.6101\n",
      "     15        \u001b[36m0.2789\u001b[0m  27.5663\n",
      "     16        \u001b[36m0.2700\u001b[0m  27.6329\n",
      "     17        \u001b[36m0.2558\u001b[0m  27.6843\n",
      "     18        \u001b[36m0.2417\u001b[0m  27.6939\n",
      "     19        \u001b[36m0.2416\u001b[0m  27.6985\n",
      "     20        \u001b[36m0.2097\u001b[0m  27.7959\n",
      "     21        0.2198  27.7775\n",
      "     22        \u001b[36m0.2055\u001b[0m  27.7675\n",
      "     23        \u001b[36m0.1895\u001b[0m  27.6974\n",
      "     24        0.1975  27.6885\n",
      "     25        0.1944  27.7630\n",
      "     26        \u001b[36m0.1626\u001b[0m  27.7142\n",
      "     27        \u001b[36m0.1607\u001b[0m  27.7228\n",
      "     28        \u001b[36m0.1451\u001b[0m  27.6499\n",
      "     29        0.1483  27.6194\n",
      "     30        \u001b[36m0.1080\u001b[0m  27.4978\n",
      "     31        0.1484  27.5158\n",
      "     32        0.1187  27.5293\n",
      "     33        0.1510  27.6079\n",
      "     34        0.1385  27.4921\n",
      "     35        \u001b[36m0.0923\u001b[0m  27.4691\n",
      "     36        0.1039  27.5453\n",
      "     37        \u001b[36m0.0868\u001b[0m  27.6135\n",
      "     38        0.1088  27.6599\n",
      "     39        0.1118  27.5977\n",
      "     40        0.0924  27.6393\n",
      "     41        \u001b[36m0.0838\u001b[0m  27.6182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42        \u001b[36m0.0611\u001b[0m  27.6301\n",
      "     43        0.0838  27.6059\n",
      "     44        0.0782  27.5333\n",
      "     45        0.0998  27.5282\n",
      "     46        0.0709  27.5425\n",
      "     47        \u001b[36m0.0547\u001b[0m  27.5040\n",
      "     48        0.0638  27.5365\n",
      "     49        \u001b[36m0.0439\u001b[0m  27.5328\n",
      "     50        0.0718  27.5612\n",
      "     51        0.0751  27.5428\n",
      "     52        0.0482  27.6286\n",
      "     53        0.0706  27.6766\n",
      "     54        0.0746  27.7294\n",
      "     55        0.0661  27.6543\n",
      "     56        0.0622  27.5804\n",
      "     57        0.0624  27.6102\n",
      "     58        \u001b[36m0.0398\u001b[0m  27.6303\n",
      "     59        0.0610  27.6390\n",
      "     60        0.0450  27.5609\n",
      "[CV 4/5] END batch_size=16, lr=0.001, max_epochs=60;, score=0.898 total time=28.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4376\u001b[0m  27.4718\n",
      "      2        \u001b[36m0.3869\u001b[0m  27.4764\n",
      "      3        \u001b[36m0.3825\u001b[0m  27.4474\n",
      "      4        \u001b[36m0.3818\u001b[0m  27.4466\n",
      "      5        \u001b[36m0.3539\u001b[0m  27.4587\n",
      "      6        0.3713  27.4750\n",
      "      7        \u001b[36m0.3503\u001b[0m  27.4695\n",
      "      8        \u001b[36m0.3442\u001b[0m  27.3855\n",
      "      9        \u001b[36m0.3421\u001b[0m  27.3703\n",
      "     10        \u001b[36m0.3183\u001b[0m  27.4010\n",
      "     11        0.3257  27.3817\n",
      "     12        \u001b[36m0.3129\u001b[0m  27.3604\n",
      "     13        0.3133  27.3735\n",
      "     14        \u001b[36m0.2927\u001b[0m  27.6346\n",
      "     15        \u001b[36m0.2663\u001b[0m  27.3672\n",
      "     16        0.2861  27.3997\n",
      "     17        \u001b[36m0.2540\u001b[0m  27.3610\n",
      "     18        \u001b[36m0.2500\u001b[0m  27.3643\n",
      "     19        0.2778  27.3859\n",
      "     20        \u001b[36m0.2283\u001b[0m  27.3922\n",
      "     21        \u001b[36m0.2239\u001b[0m  27.3678\n",
      "     22        \u001b[36m0.1920\u001b[0m  27.3257\n",
      "     23        0.1985  27.3351\n",
      "     24        0.2000  27.3331\n",
      "     25        \u001b[36m0.1755\u001b[0m  27.4209\n",
      "     26        \u001b[36m0.1664\u001b[0m  27.4052\n",
      "     27        \u001b[36m0.1578\u001b[0m  27.3423\n",
      "     28        \u001b[36m0.1542\u001b[0m  27.3718\n",
      "     29        \u001b[36m0.1435\u001b[0m  27.4573\n",
      "     30        0.1470  27.3438\n",
      "     31        \u001b[36m0.1259\u001b[0m  27.3499\n",
      "     32        0.1435  27.3603\n",
      "     33        0.1333  27.4145\n",
      "     34        \u001b[36m0.1031\u001b[0m  27.3868\n",
      "     35        0.1279  27.4127\n",
      "     36        0.1047  27.4016\n",
      "     37        \u001b[36m0.0933\u001b[0m  27.4679\n",
      "     38        0.1022  27.4766\n",
      "     39        0.0936  27.5819\n",
      "     40        0.1130  27.4870\n",
      "     41        \u001b[36m0.0750\u001b[0m  27.5424\n",
      "     42        0.0902  27.5234\n",
      "     43        0.0875  27.3784\n",
      "     44        0.1010  27.3942\n",
      "     45        0.0861  27.4714\n",
      "     46        \u001b[36m0.0639\u001b[0m  27.4814\n",
      "     47        0.0811  27.5423\n",
      "     48        0.0779  27.5178\n",
      "     49        0.0701  27.4488\n",
      "     50        0.0681  27.4587\n",
      "     51        \u001b[36m0.0535\u001b[0m  27.5406\n",
      "     52        0.0668  27.5137\n",
      "     53        0.0650  27.4032\n",
      "     54        \u001b[36m0.0503\u001b[0m  27.4369\n",
      "     55        \u001b[36m0.0499\u001b[0m  27.4375\n",
      "     56        \u001b[36m0.0472\u001b[0m  27.3800\n",
      "     57        0.0819  27.4067\n",
      "     58        0.0591  27.4341\n",
      "     59        \u001b[36m0.0471\u001b[0m  27.7833\n",
      "     60        \u001b[36m0.0393\u001b[0m  27.7411\n",
      "[CV 5/5] END batch_size=16, lr=0.001, max_epochs=60;, score=0.925 total time=27.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4250\u001b[0m  27.7683\n",
      "      2        \u001b[36m0.4017\u001b[0m  27.7740\n",
      "      3        \u001b[36m0.3955\u001b[0m  27.8304\n",
      "      4        \u001b[36m0.3599\u001b[0m  27.7922\n",
      "      5        \u001b[36m0.3525\u001b[0m  27.7864\n",
      "      6        \u001b[36m0.3445\u001b[0m  27.7370\n",
      "      7        0.3470  27.7886\n",
      "      8        0.3521  27.7709\n",
      "      9        \u001b[36m0.3374\u001b[0m  27.7347\n",
      "     10        0.3451  27.7484\n",
      "     11        \u001b[36m0.3260\u001b[0m  27.7566\n",
      "     12        \u001b[36m0.3034\u001b[0m  27.7100\n",
      "     13        0.3046  27.6463\n",
      "     14        \u001b[36m0.2589\u001b[0m  27.6222\n",
      "     15        0.2616  27.6571\n",
      "     16        0.2654  27.6348\n",
      "     17        0.2607  27.6859\n",
      "     18        \u001b[36m0.2219\u001b[0m  27.6954\n",
      "     19        0.2422  27.6513\n",
      "     20        \u001b[36m0.2123\u001b[0m  27.5949\n",
      "     21        \u001b[36m0.1958\u001b[0m  27.5665\n",
      "     22        \u001b[36m0.1917\u001b[0m  27.6388\n",
      "     23        0.1950  27.6583\n",
      "     24        \u001b[36m0.1583\u001b[0m  27.5774\n",
      "     25        \u001b[36m0.1264\u001b[0m  27.5823\n",
      "     26        0.1875  27.6010\n",
      "     27        0.1488  27.6241\n",
      "     28        0.1467  27.6875\n",
      "     29        \u001b[36m0.1170\u001b[0m  27.7073\n",
      "     30        \u001b[36m0.1170\u001b[0m  27.6342\n",
      "     31        \u001b[36m0.1149\u001b[0m  27.5615\n",
      "     32        0.1312  27.6790\n",
      "     33        \u001b[36m0.1101\u001b[0m  27.6384\n",
      "     34        0.1109  27.6049\n",
      "     35        0.1168  27.5806\n",
      "     36        \u001b[36m0.0899\u001b[0m  27.5980\n",
      "     37        \u001b[36m0.0727\u001b[0m  27.6010\n",
      "     38        0.1065  28.2325\n",
      "     39        0.0850  27.5436\n",
      "     40        0.0820  27.5508\n",
      "     41        \u001b[36m0.0698\u001b[0m  27.5414\n",
      "     42        0.0942  28.1853\n",
      "     43        \u001b[36m0.0524\u001b[0m  27.8796\n",
      "     44        0.0588  27.6392\n",
      "     45        0.0641  27.6089\n",
      "     46        0.0708  27.6428\n",
      "     47        \u001b[36m0.0448\u001b[0m  27.6176\n",
      "     48        0.0700  27.5370\n",
      "     49        0.0936  27.5922\n",
      "     50        0.0631  27.6164\n",
      "     51        0.0649  27.7108\n",
      "     52        0.0617  27.6341\n",
      "     53        0.0811  27.6436\n",
      "     54        \u001b[36m0.0371\u001b[0m  27.6468\n",
      "     55        0.0447  27.6420\n",
      "     56        0.0553  27.6476\n",
      "     57        0.0592  27.5656\n",
      "     58        \u001b[36m0.0270\u001b[0m  27.5642\n",
      "     59        0.0521  27.5421\n",
      "     60        0.0376  27.5439\n",
      "     61        0.0583  27.5411\n",
      "     62        0.0446  27.5506\n",
      "     63        0.0404  27.6232\n",
      "     64        0.0318  27.5871\n",
      "     65        0.0635  27.5620\n",
      "     66        0.0430  27.5442\n",
      "     67        0.0278  27.5566\n",
      "     68        0.0481  27.6230\n",
      "     69        0.0386  27.5565\n",
      "     70        \u001b[36m0.0230\u001b[0m  27.6466\n",
      "     71        0.0322  27.6492\n",
      "     72        0.0321  27.7142\n",
      "     73        0.0723  27.6500\n",
      "     74        0.0439  27.7402\n",
      "     75        0.0388  27.5805\n",
      "     76        0.0279  27.5821\n",
      "     77        0.0398  27.5648\n",
      "     78        \u001b[36m0.0190\u001b[0m  27.7420\n",
      "     79        0.0284  27.7331\n",
      "     80        0.0338  27.7327\n",
      "[CV 1/5] END batch_size=16, lr=0.001, max_epochs=80;, score=0.898 total time=37.3min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4533\u001b[0m  27.5639\n",
      "      2        \u001b[36m0.4060\u001b[0m  27.5124\n",
      "      3        \u001b[36m0.3950\u001b[0m  27.9812\n",
      "      4        \u001b[36m0.3823\u001b[0m  27.9803\n",
      "      5        \u001b[36m0.3733\u001b[0m  27.5636\n",
      "      6        \u001b[36m0.3594\u001b[0m  27.5663\n",
      "      7        \u001b[36m0.3502\u001b[0m  27.5701\n",
      "      8        \u001b[36m0.3452\u001b[0m  27.6868\n",
      "      9        \u001b[36m0.3421\u001b[0m  27.6389\n",
      "     10        \u001b[36m0.3407\u001b[0m  27.6250\n",
      "     11        \u001b[36m0.3357\u001b[0m  27.6419\n",
      "     12        \u001b[36m0.3135\u001b[0m  27.6474\n",
      "     13        \u001b[36m0.3085\u001b[0m  27.6801\n",
      "     14        0.3123  27.6459\n",
      "     15        \u001b[36m0.3061\u001b[0m  27.5578\n",
      "     16        \u001b[36m0.2802\u001b[0m  27.5837\n",
      "     17        \u001b[36m0.2756\u001b[0m  27.6601\n",
      "     18        \u001b[36m0.2561\u001b[0m  27.6747\n",
      "     19        0.2709  27.6608\n",
      "     20        \u001b[36m0.2384\u001b[0m  27.6787\n",
      "     21        \u001b[36m0.2185\u001b[0m  27.6981\n",
      "     22        \u001b[36m0.2183\u001b[0m  28.0820\n",
      "     23        \u001b[36m0.2129\u001b[0m  27.6477\n",
      "     24        \u001b[36m0.2021\u001b[0m  27.5501\n",
      "     25        \u001b[36m0.1906\u001b[0m  27.6901\n",
      "     26        0.2056  27.7050\n",
      "     27        \u001b[36m0.1688\u001b[0m  27.7906\n",
      "     28        \u001b[36m0.1653\u001b[0m  27.7981\n",
      "     29        \u001b[36m0.1472\u001b[0m  27.7645\n",
      "     30        0.1778  27.6892\n",
      "     31        \u001b[36m0.1305\u001b[0m  27.8627\n",
      "     32        \u001b[36m0.1167\u001b[0m  27.7217\n",
      "     33        \u001b[36m0.1063\u001b[0m  27.9490\n",
      "     34        0.1202  27.7746\n",
      "     35        0.1186  27.6090\n",
      "     36        0.1114  27.5964\n",
      "     37        0.1418  27.5735\n",
      "     38        0.1074  27.4902\n",
      "     39        \u001b[36m0.0937\u001b[0m  27.4941\n",
      "     40        \u001b[36m0.0762\u001b[0m  27.5420\n",
      "     41        0.1077  27.4929\n",
      "     42        0.0887  27.4822\n",
      "     43        0.1140  27.4875\n",
      "     44        0.0900  27.4783\n",
      "     45        0.0845  27.6244\n",
      "     46        \u001b[36m0.0750\u001b[0m  27.9336\n",
      "     47        \u001b[36m0.0703\u001b[0m  27.5689\n",
      "     48        0.0961  27.7061\n",
      "     49        0.0845  27.5799\n",
      "     50        \u001b[36m0.0646\u001b[0m  27.6809\n",
      "     51        0.0654  27.6583\n",
      "     52        0.0803  27.5466\n",
      "     53        \u001b[36m0.0556\u001b[0m  27.8045\n",
      "     54        \u001b[36m0.0373\u001b[0m  27.8923\n",
      "     55        0.0630  27.4086\n",
      "     56        0.0560  27.3949\n",
      "     57        0.0773  27.3604\n",
      "     58        0.0771  27.3700\n",
      "     59        0.0667  27.3816\n",
      "     60        0.0819  27.3976\n",
      "     61        0.0645  27.4633\n",
      "     62        0.0477  27.5371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     63        0.0479  27.3727\n",
      "     64        0.0429  27.4108\n",
      "     65        0.0380  27.4151\n",
      "     66        0.0642  27.4410\n",
      "     67        0.0609  27.4583\n",
      "     68        0.0384  27.4570\n",
      "     69        0.0494  27.5235\n",
      "     70        0.0525  27.4743\n",
      "     71        0.0457  27.5020\n",
      "     72        \u001b[36m0.0318\u001b[0m  27.6490\n",
      "     73        0.0324  27.6406\n",
      "     74        0.0342  27.6472\n",
      "     75        0.0441  27.6630\n",
      "     76        0.0441  27.6300\n",
      "     77        0.0461  27.5966\n",
      "     78        0.0572  27.5999\n",
      "     79        0.0336  27.5132\n",
      "     80        \u001b[36m0.0261\u001b[0m  27.4916\n",
      "[CV 2/5] END batch_size=16, lr=0.001, max_epochs=80;, score=0.929 total time=37.3min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4374\u001b[0m  27.4482\n",
      "      2        \u001b[36m0.3862\u001b[0m  27.5779\n",
      "      3        \u001b[36m0.3602\u001b[0m  27.5747\n",
      "      4        0.3619  27.5749\n",
      "      5        \u001b[36m0.3594\u001b[0m  27.5824\n",
      "      6        0.3623  27.5634\n",
      "      7        \u001b[36m0.3480\u001b[0m  27.5868\n",
      "      8        \u001b[36m0.3454\u001b[0m  27.5506\n",
      "      9        \u001b[36m0.3245\u001b[0m  27.5967\n",
      "     10        0.3250  27.5765\n",
      "     11        \u001b[36m0.3137\u001b[0m  27.5675\n",
      "     12        \u001b[36m0.2948\u001b[0m  27.5754\n",
      "     13        \u001b[36m0.2925\u001b[0m  27.6078\n",
      "     14        \u001b[36m0.2716\u001b[0m  27.4830\n",
      "     15        0.2947  27.5910\n",
      "     16        \u001b[36m0.2652\u001b[0m  27.6083\n",
      "     17        \u001b[36m0.2547\u001b[0m  27.5674\n",
      "     18        0.2629  27.6099\n",
      "     19        \u001b[36m0.2336\u001b[0m  27.4242\n",
      "     20        \u001b[36m0.2208\u001b[0m  27.4924\n",
      "     21        0.2255  27.5021\n",
      "     22        0.2284  27.4773\n",
      "     23        0.2284  27.4699\n",
      "     24        \u001b[36m0.1895\u001b[0m  27.4799\n",
      "     25        0.1914  27.4604\n",
      "     26        \u001b[36m0.1857\u001b[0m  27.4832\n",
      "     27        0.1946  27.6356\n",
      "     28        \u001b[36m0.1818\u001b[0m  27.6424\n",
      "     29        \u001b[36m0.1613\u001b[0m  27.4753\n",
      "     30        \u001b[36m0.1302\u001b[0m  27.4742\n",
      "     31        \u001b[36m0.1167\u001b[0m  27.5382\n",
      "     32        0.1477  27.5448\n",
      "     33        0.1511  27.5293\n",
      "     34        0.1519  27.5889\n",
      "     35        0.1204  27.5514\n",
      "     36        \u001b[36m0.1148\u001b[0m  27.6182\n",
      "     37        \u001b[36m0.1113\u001b[0m  27.5434\n",
      "     38        \u001b[36m0.0967\u001b[0m  27.6131\n",
      "     39        0.1176  27.5504\n",
      "     40        \u001b[36m0.0958\u001b[0m  27.6143\n",
      "     41        0.1008  27.5786\n",
      "     42        0.1013  27.6112\n",
      "     43        0.1125  27.5614\n",
      "     44        \u001b[36m0.0737\u001b[0m  27.5961\n",
      "     45        0.0779  27.6144\n",
      "     46        \u001b[36m0.0606\u001b[0m  27.5922\n",
      "     47        0.0701  27.5551\n",
      "     48        0.0779  27.5821\n",
      "     49        0.0856  27.5041\n",
      "     50        0.0774  27.5207\n",
      "     51        0.0698  27.5421\n",
      "     52        0.0686  27.5830\n",
      "     53        0.0663  27.5452\n",
      "     54        \u001b[36m0.0595\u001b[0m  27.5729\n",
      "     55        0.0650  27.5604\n",
      "     56        \u001b[36m0.0410\u001b[0m  27.5445\n",
      "     57        0.0471  27.5529\n",
      "     58        0.0527  27.5641\n",
      "     59        0.0629  28.4114\n",
      "     60        0.0703  27.6144\n",
      "     61        0.0501  27.4799\n",
      "     62        0.0588  27.5380\n",
      "     63        0.0452  27.4991\n",
      "     64        \u001b[36m0.0222\u001b[0m  27.5361\n",
      "     65        0.0403  27.4718\n",
      "     66        0.0724  27.5365\n",
      "     67        0.0391  27.5839\n",
      "     68        0.0299  27.4906\n",
      "     69        0.0581  27.4572\n",
      "     70        0.0430  27.5127\n",
      "     71        0.0449  27.5349\n",
      "     72        0.0494  27.8564\n",
      "     73        0.0604  27.6899\n",
      "     74        0.0309  27.5353\n",
      "     75        0.0716  27.5011\n",
      "     76        0.0271  27.5388\n",
      "     77        0.0222  27.4868\n",
      "     78        0.0612  27.5704\n",
      "     79        0.0394  27.4951\n",
      "     80        0.0343  27.5000\n",
      "[CV 3/5] END batch_size=16, lr=0.001, max_epochs=80;, score=0.935 total time=37.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4416\u001b[0m  27.9581\n",
      "      2        \u001b[36m0.4029\u001b[0m  27.4656\n",
      "      3        \u001b[36m0.3776\u001b[0m  27.5159\n",
      "      4        \u001b[36m0.3736\u001b[0m  27.3836\n",
      "      5        \u001b[36m0.3546\u001b[0m  27.4330\n",
      "      6        0.3548  27.4065\n",
      "      7        \u001b[36m0.3486\u001b[0m  27.4744\n",
      "      8        \u001b[36m0.3402\u001b[0m  27.5495\n",
      "      9        0.3590  27.6818\n",
      "     10        \u001b[36m0.3176\u001b[0m  27.4928\n",
      "     11        \u001b[36m0.3168\u001b[0m  27.4488\n",
      "     12        0.3233  27.5208\n",
      "     13        \u001b[36m0.3094\u001b[0m  27.4446\n",
      "     14        0.3183  27.4311\n",
      "     15        \u001b[36m0.2927\u001b[0m  27.4967\n",
      "     16        \u001b[36m0.2691\u001b[0m  27.5819\n",
      "     17        0.2709  27.5312\n",
      "     18        0.2739  27.4160\n",
      "     19        \u001b[36m0.2438\u001b[0m  27.4076\n",
      "     20        \u001b[36m0.2341\u001b[0m  27.4229\n",
      "     21        \u001b[36m0.2297\u001b[0m  27.4776\n",
      "     22        \u001b[36m0.2033\u001b[0m  27.4211\n",
      "     23        \u001b[36m0.2007\u001b[0m  27.4115\n",
      "     24        \u001b[36m0.1706\u001b[0m  27.5356\n",
      "     25        0.2118  27.5742\n",
      "     26        \u001b[36m0.1589\u001b[0m  27.5428\n",
      "     27        0.1655  27.4688\n",
      "     28        0.1751  28.0121\n",
      "     29        \u001b[36m0.1468\u001b[0m  27.5331\n",
      "     30        \u001b[36m0.1285\u001b[0m  27.5573\n",
      "     31        \u001b[36m0.1171\u001b[0m  27.5811\n",
      "     32        0.1314  27.6043\n",
      "     33        0.1221  27.5290\n",
      "     34        \u001b[36m0.1061\u001b[0m  27.5822\n",
      "     35        0.1126  27.5149\n",
      "     36        0.1214  27.5087\n",
      "     37        \u001b[36m0.0964\u001b[0m  27.5559\n",
      "     38        \u001b[36m0.0852\u001b[0m  27.4853\n",
      "     39        0.0925  27.4520\n",
      "     40        \u001b[36m0.0758\u001b[0m  27.5717\n",
      "     41        0.0999  27.5332\n",
      "     42        0.0843  27.5085\n",
      "     43        0.0779  27.5469\n",
      "     44        \u001b[36m0.0693\u001b[0m  27.6096\n",
      "     45        \u001b[36m0.0602\u001b[0m  28.0158\n",
      "     46        0.0627  27.5955\n",
      "     47        0.0763  27.6115\n",
      "     48        0.0921  27.7007\n",
      "     49        0.1058  27.5283\n",
      "     50        0.0704  27.5113\n",
      "     51        0.0724  27.5158\n",
      "     52        \u001b[36m0.0522\u001b[0m  27.4729\n",
      "     53        0.0704  27.5295\n",
      "     54        0.0626  27.5240\n",
      "     55        \u001b[36m0.0415\u001b[0m  27.5005\n",
      "     56        0.0581  27.6294\n",
      "     57        0.0776  27.6104\n",
      "     58        0.0520  27.5702\n",
      "     59        0.0897  27.7156\n",
      "     60        \u001b[36m0.0393\u001b[0m  27.7108\n",
      "     61        \u001b[36m0.0357\u001b[0m  27.7447\n",
      "     62        0.0419  27.6658\n",
      "     63        0.0752  27.7493\n",
      "     64        0.0448  27.8011\n",
      "     65        0.0697  27.6827\n",
      "     66        \u001b[36m0.0323\u001b[0m  27.6659\n",
      "     67        0.0479  27.6816\n",
      "     68        0.0371  27.6784\n",
      "     69        0.0578  27.7278\n",
      "     70        0.0423  27.7509\n",
      "     71        \u001b[36m0.0287\u001b[0m  27.6978\n",
      "     72        \u001b[36m0.0120\u001b[0m  27.6745\n",
      "     73        0.0315  27.5104\n",
      "     74        0.0570  27.5121\n",
      "     75        0.0227  27.5192\n",
      "     76        0.0241  27.5723\n",
      "     77        0.0387  27.6146\n",
      "     78        0.0495  27.5505\n",
      "     79        0.0330  27.5747\n",
      "     80        0.0489  27.5713\n",
      "[CV 4/5] END batch_size=16, lr=0.001, max_epochs=80;, score=0.916 total time=37.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4233\u001b[0m  27.4859\n",
      "      2        \u001b[36m0.4111\u001b[0m  27.5396\n",
      "      3        \u001b[36m0.3831\u001b[0m  27.5337\n",
      "      4        \u001b[36m0.3588\u001b[0m  27.3454\n",
      "      5        0.3716  27.3854\n",
      "      6        0.3665  27.3744\n",
      "      7        \u001b[36m0.3459\u001b[0m  27.4131\n",
      "      8        0.3488  27.4815\n",
      "      9        \u001b[36m0.3209\u001b[0m  27.3889\n",
      "     10        0.3252  27.3951\n",
      "     11        \u001b[36m0.3016\u001b[0m  27.3750\n",
      "     12        0.3157  27.4137\n",
      "     13        0.3020  27.4338\n",
      "     14        \u001b[36m0.2948\u001b[0m  27.5471\n",
      "     15        0.2958  27.4204\n",
      "     16        \u001b[36m0.2659\u001b[0m  27.3532\n",
      "     17        \u001b[36m0.2344\u001b[0m  27.8572\n",
      "     18        0.2388  27.4988\n",
      "     19        0.2384  27.4034\n",
      "     20        \u001b[36m0.1945\u001b[0m  27.3887\n",
      "     21        0.2117  27.4736\n",
      "     22        \u001b[36m0.1817\u001b[0m  27.4282\n",
      "     23        0.1834  27.3886\n",
      "     24        \u001b[36m0.1701\u001b[0m  27.3636\n",
      "     25        \u001b[36m0.1582\u001b[0m  27.3933\n",
      "     26        \u001b[36m0.1580\u001b[0m  27.3868\n",
      "     27        \u001b[36m0.1539\u001b[0m  27.3995\n",
      "     28        \u001b[36m0.1208\u001b[0m  28.3473\n",
      "     29        0.1332  30.3686\n",
      "     30        0.1567  27.7402\n",
      "     31        \u001b[36m0.1128\u001b[0m  27.7039\n",
      "     32        \u001b[36m0.1017\u001b[0m  27.6786\n",
      "     33        0.1073  27.6409\n",
      "     34        0.1483  27.7274\n",
      "     35        0.1228  27.7182\n",
      "     36        \u001b[36m0.0927\u001b[0m  27.7001\n",
      "     37        \u001b[36m0.0917\u001b[0m  27.7448\n",
      "     38        0.0937  27.7211\n",
      "     39        0.1035  27.6869\n",
      "     40        0.1016  27.7341\n",
      "     41        \u001b[36m0.0847\u001b[0m  27.5928\n",
      "     42        \u001b[36m0.0585\u001b[0m  27.5786\n",
      "     43        0.0734  27.5351\n",
      "     44        0.0843  27.5873\n",
      "     45        0.0587  27.5003\n",
      "     46        0.0772  27.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     47        0.0673  27.5378\n",
      "     48        0.0689  27.5219\n",
      "     49        \u001b[36m0.0559\u001b[0m  27.5235\n",
      "     50        0.0689  27.4846\n",
      "     51        \u001b[36m0.0526\u001b[0m  27.4620\n",
      "     52        0.0814  28.0011\n",
      "     53        0.0683  27.7270\n",
      "     54        0.0543  27.4379\n",
      "     55        0.0625  27.4387\n",
      "     56        0.0908  27.4636\n",
      "     57        \u001b[36m0.0485\u001b[0m  27.5031\n",
      "     58        \u001b[36m0.0471\u001b[0m  27.4617\n",
      "     59        0.0641  27.4304\n",
      "     60        0.0523  27.4676\n",
      "     61        0.0722  27.3695\n",
      "     62        \u001b[36m0.0381\u001b[0m  27.4480\n",
      "     63        0.0452  27.3692\n",
      "     64        0.0436  27.3145\n",
      "     65        \u001b[36m0.0352\u001b[0m  27.3045\n",
      "     66        0.0387  27.4087\n",
      "     67        \u001b[36m0.0216\u001b[0m  27.3588\n",
      "     68        0.0362  27.4197\n",
      "     69        0.0576  27.3906\n",
      "     70        0.0481  27.4317\n",
      "     71        0.0741  27.3956\n",
      "     72        0.0375  27.3258\n",
      "     73        0.0489  27.4317\n",
      "     74        0.0288  27.3802\n",
      "     75        0.0378  27.3772\n",
      "     76        0.0631  27.3256\n",
      "     77        0.0439  27.3547\n",
      "     78        0.0241  27.4286\n",
      "     79        \u001b[36m0.0212\u001b[0m  27.9692\n",
      "     80        0.0324  27.7275\n",
      "[CV 5/5] END batch_size=16, lr=0.001, max_epochs=80;, score=0.907 total time=37.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5486\u001b[0m  27.5803\n",
      "      2        \u001b[36m0.4148\u001b[0m  27.6214\n",
      "      3        \u001b[36m0.3877\u001b[0m  27.6600\n",
      "      4        \u001b[36m0.3842\u001b[0m  27.6609\n",
      "      5        \u001b[36m0.3728\u001b[0m  27.5761\n",
      "      6        \u001b[36m0.3687\u001b[0m  27.6453\n",
      "      7        \u001b[36m0.3603\u001b[0m  27.6882\n",
      "      8        0.3689  27.6341\n",
      "      9        0.3696  27.6060\n",
      "     10        \u001b[36m0.3545\u001b[0m  27.6766\n",
      "     11        0.3641  27.7232\n",
      "     12        0.3570  27.7329\n",
      "     13        \u001b[36m0.3426\u001b[0m  27.7567\n",
      "     14        0.3509  27.6730\n",
      "     15        \u001b[36m0.3345\u001b[0m  27.7069\n",
      "     16        0.3659  28.6325\n",
      "     17        0.3478  27.7698\n",
      "     18        \u001b[36m0.3287\u001b[0m  28.0189\n",
      "     19        \u001b[36m0.3212\u001b[0m  27.8788\n",
      "     20        0.3252  27.8000\n",
      "     21        0.3242  27.9676\n",
      "     22        \u001b[36m0.3200\u001b[0m  27.8423\n",
      "     23        0.3225  27.7758\n",
      "     24        \u001b[36m0.3044\u001b[0m  27.8652\n",
      "     25        0.3246  27.8066\n",
      "     26        0.3103  27.9202\n",
      "     27        \u001b[36m0.2834\u001b[0m  27.8825\n",
      "     28        0.3136  27.9108\n",
      "     29        \u001b[36m0.2621\u001b[0m  27.8870\n",
      "     30        0.2753  27.8903\n",
      "     31        0.2677  28.1589\n",
      "     32        \u001b[36m0.2530\u001b[0m  28.1155\n",
      "     33        0.2605  28.1529\n",
      "     34        0.2856  28.1288\n",
      "     35        \u001b[36m0.2409\u001b[0m  28.0958\n",
      "     36        \u001b[36m0.2287\u001b[0m  28.1038\n",
      "     37        0.2306  28.0692\n",
      "     38        \u001b[36m0.2249\u001b[0m  28.0189\n",
      "     39        \u001b[36m0.2184\u001b[0m  28.0087\n",
      "     40        \u001b[36m0.2147\u001b[0m  28.2995\n",
      "[CV 1/5] END batch_size=16, lr=0.01, max_epochs=40;, score=0.882 total time=19.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4969\u001b[0m  27.5856\n",
      "      2        \u001b[36m0.4550\u001b[0m  27.6079\n",
      "      3        \u001b[36m0.4075\u001b[0m  27.6342\n",
      "      4        0.4176  27.6995\n",
      "      5        \u001b[36m0.3787\u001b[0m  27.6042\n",
      "      6        0.3913  27.6324\n",
      "      7        \u001b[36m0.3785\u001b[0m  27.6428\n",
      "      8        0.3856  27.6425\n",
      "      9        \u001b[36m0.3673\u001b[0m  27.6823\n",
      "     10        \u001b[36m0.3569\u001b[0m  27.6169\n",
      "     11        0.3726  27.6196\n",
      "     12        \u001b[36m0.3434\u001b[0m  27.5984\n",
      "     13        0.3607  27.6614\n",
      "     14        0.3498  27.5909\n",
      "     15        \u001b[36m0.3426\u001b[0m  27.5802\n",
      "     16        0.3477  27.6380\n",
      "     17        0.3440  27.6791\n",
      "     18        \u001b[36m0.3308\u001b[0m  27.8019\n",
      "     19        \u001b[36m0.3229\u001b[0m  27.7490\n",
      "     20        0.3465  27.8094\n",
      "     21        0.3247  28.0855\n",
      "     22        0.3257  28.5724\n",
      "     23        \u001b[36m0.3219\u001b[0m  28.3013\n",
      "     24        \u001b[36m0.3219\u001b[0m  27.9845\n",
      "     25        \u001b[36m0.3058\u001b[0m  28.0063\n",
      "     26        0.3181  28.1633\n",
      "     27        \u001b[36m0.2791\u001b[0m  28.1422\n",
      "     28        0.2841  28.1595\n",
      "     29        0.2820  28.1269\n",
      "     30        0.2848  28.2826\n",
      "     31        0.2842  28.2603\n",
      "     32        0.2904  28.0593\n",
      "     33        \u001b[36m0.2571\u001b[0m  28.0503\n",
      "     34        0.2643  28.2026\n",
      "     35        0.2744  28.2704\n",
      "     36        \u001b[36m0.2475\u001b[0m  28.2666\n",
      "     37        \u001b[36m0.2448\u001b[0m  28.2132\n",
      "     38        0.2475  28.1115\n",
      "     39        \u001b[36m0.2344\u001b[0m  28.3680\n",
      "     40        0.2457  28.3628\n",
      "[CV 2/5] END batch_size=16, lr=0.01, max_epochs=40;, score=0.929 total time=19.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5251\u001b[0m  27.6089\n",
      "      2        \u001b[36m0.4492\u001b[0m  27.6362\n",
      "      3        \u001b[36m0.4167\u001b[0m  27.6200\n",
      "      4        \u001b[36m0.3968\u001b[0m  27.6065\n",
      "      5        \u001b[36m0.3965\u001b[0m  27.5569\n",
      "      6        \u001b[36m0.3911\u001b[0m  27.8097\n",
      "      7        0.3912  27.7601\n",
      "      8        \u001b[36m0.3791\u001b[0m  27.7752\n",
      "      9        0.3817  27.7477\n",
      "     10        \u001b[36m0.3715\u001b[0m  27.7869\n",
      "     11        \u001b[36m0.3622\u001b[0m  27.8320\n",
      "     12        0.3801  27.8888\n",
      "     13        \u001b[36m0.3607\u001b[0m  27.9061\n",
      "     14        0.3653  28.1089\n",
      "     15        0.3658  27.8643\n",
      "     16        \u001b[36m0.3487\u001b[0m  27.8005\n",
      "     17        \u001b[36m0.3393\u001b[0m  27.7419\n",
      "     18        0.3508  27.7562\n",
      "     19        0.3462  27.8999\n",
      "     20        0.3414  27.8622\n",
      "     21        \u001b[36m0.3319\u001b[0m  27.8662\n",
      "     22        0.3504  27.8172\n",
      "     23        0.3379  27.8904\n",
      "     24        0.3380  27.8798\n",
      "     25        0.3398  27.8636\n",
      "     26        \u001b[36m0.3232\u001b[0m  27.8621\n",
      "     27        0.3271  28.0317\n",
      "     28        \u001b[36m0.3129\u001b[0m  28.0361\n",
      "     29        \u001b[36m0.3108\u001b[0m  28.0223\n",
      "     30        \u001b[36m0.2943\u001b[0m  28.0165\n",
      "     31        0.2971  28.1062\n",
      "     32        0.2956  28.0957\n",
      "     33        \u001b[36m0.2877\u001b[0m  27.9569\n",
      "     34        \u001b[36m0.2794\u001b[0m  27.9647\n",
      "     35        \u001b[36m0.2755\u001b[0m  27.9530\n",
      "     36        0.2852  27.9315\n",
      "     37        0.2813  28.1104\n",
      "     38        \u001b[36m0.2636\u001b[0m  28.0365\n",
      "     39        \u001b[36m0.2632\u001b[0m  28.0431\n",
      "     40        0.2754  27.9704\n",
      "[CV 3/5] END batch_size=16, lr=0.01, max_epochs=40;, score=0.854 total time=19.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5341\u001b[0m  27.5342\n",
      "      2        \u001b[36m0.4628\u001b[0m  27.6225\n",
      "      3        \u001b[36m0.3973\u001b[0m  27.6217\n",
      "      4        0.4006  27.6174\n",
      "      5        0.4008  27.5370\n",
      "      6        \u001b[36m0.3711\u001b[0m  27.5532\n",
      "      7        0.3852  27.5849\n",
      "      8        \u001b[36m0.3684\u001b[0m  27.6326\n",
      "      9        0.3814  27.7389\n",
      "     10        \u001b[36m0.3620\u001b[0m  27.6953\n",
      "     11        \u001b[36m0.3589\u001b[0m  27.6170\n",
      "     12        0.3698  27.8319\n",
      "     13        \u001b[36m0.3476\u001b[0m  27.8201\n",
      "     14        0.3522  27.7680\n",
      "     15        \u001b[36m0.3414\u001b[0m  27.8311\n",
      "     16        0.3634  27.9312\n",
      "     17        0.3419  27.9707\n",
      "     18        \u001b[36m0.3372\u001b[0m  27.8999\n",
      "     19        0.3386  28.1423\n",
      "     20        \u001b[36m0.3299\u001b[0m  28.5697\n",
      "     21        \u001b[36m0.3147\u001b[0m  27.9784\n",
      "     22        \u001b[36m0.3090\u001b[0m  28.0614\n",
      "     23        0.3128  28.0033\n",
      "     24        \u001b[36m0.3019\u001b[0m  28.0164\n",
      "     25        \u001b[36m0.3007\u001b[0m  28.0986\n",
      "     26        \u001b[36m0.2974\u001b[0m  28.0880\n",
      "     27        \u001b[36m0.2755\u001b[0m  28.0755\n",
      "     28        0.2819  28.0538\n",
      "     29        0.2820  28.2376\n",
      "     30        0.3068  28.2047\n",
      "     31        \u001b[36m0.2710\u001b[0m  28.1470\n",
      "     32        \u001b[36m0.2674\u001b[0m  28.1087\n",
      "     33        \u001b[36m0.2490\u001b[0m  28.3408\n",
      "     34        \u001b[36m0.2396\u001b[0m  28.3152\n",
      "     35        \u001b[36m0.2224\u001b[0m  28.4366\n",
      "     36        0.2319  28.3712\n",
      "     37        \u001b[36m0.2000\u001b[0m  28.4795\n",
      "     38        \u001b[36m0.1979\u001b[0m  28.6037\n",
      "     39        0.2050  28.5446\n",
      "     40        \u001b[36m0.1863\u001b[0m  28.5540\n",
      "[CV 4/5] END batch_size=16, lr=0.01, max_epochs=40;, score=0.891 total time=19.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5307\u001b[0m  27.3930\n",
      "      2        \u001b[36m0.4064\u001b[0m  27.4539\n",
      "      3        0.4163  27.5434\n",
      "      4        0.4092  27.3580\n",
      "      5        0.4242  27.4732\n",
      "      6        \u001b[36m0.3725\u001b[0m  27.6369\n",
      "      7        0.3737  27.5849\n",
      "      8        0.3771  28.7164\n",
      "      9        \u001b[36m0.3635\u001b[0m  28.3006\n",
      "     10        0.3726  27.5718\n",
      "     11        0.3711  27.5581\n",
      "     12        \u001b[36m0.3496\u001b[0m  27.5228\n",
      "     13        0.3704  27.5481\n",
      "     14        0.3652  27.4609\n",
      "     15        0.3583  27.5421\n",
      "     16        0.3521  27.4451\n",
      "     17        0.3677  27.3598\n",
      "     18        \u001b[36m0.3365\u001b[0m  27.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.3495  27.4826\n",
      "     20        0.3469  27.5028\n",
      "     21        \u001b[36m0.3274\u001b[0m  27.5372\n",
      "     22        0.3311  27.5288\n",
      "     23        0.3423  27.4998\n",
      "     24        \u001b[36m0.3149\u001b[0m  27.5716\n",
      "     25        0.3271  27.6350\n",
      "     26        \u001b[36m0.3053\u001b[0m  27.6576\n",
      "     27        0.3203  27.7262\n",
      "     28        0.3144  28.3055\n",
      "     29        0.3135  27.6805\n",
      "     30        \u001b[36m0.2861\u001b[0m  27.7671\n",
      "     31        0.2921  28.5868\n",
      "     32        \u001b[36m0.2819\u001b[0m  29.1229\n",
      "     33        \u001b[36m0.2570\u001b[0m  27.6160\n",
      "     34        0.2657  27.4523\n",
      "     35        0.2700  27.5246\n",
      "     36        \u001b[36m0.2454\u001b[0m  27.5588\n",
      "     37        0.2699  27.5746\n",
      "     38        0.2490  27.5107\n",
      "     39        \u001b[36m0.2290\u001b[0m  27.6397\n",
      "     40        0.2309  27.6419\n",
      "[CV 5/5] END batch_size=16, lr=0.01, max_epochs=40;, score=0.848 total time=18.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4930\u001b[0m  27.7120\n",
      "      2        \u001b[36m0.4276\u001b[0m  27.7053\n",
      "      3        \u001b[36m0.4060\u001b[0m  27.7044\n",
      "      4        \u001b[36m0.3820\u001b[0m  27.7470\n",
      "      5        0.3831  27.6499\n",
      "      6        0.3858  27.6874\n",
      "      7        \u001b[36m0.3746\u001b[0m  29.2935\n",
      "      8        \u001b[36m0.3659\u001b[0m  27.8580\n",
      "      9        \u001b[36m0.3634\u001b[0m  27.8084\n",
      "     10        \u001b[36m0.3628\u001b[0m  27.6992\n",
      "     11        \u001b[36m0.3560\u001b[0m  27.6699\n",
      "     12        \u001b[36m0.3496\u001b[0m  27.6693\n",
      "     13        \u001b[36m0.3483\u001b[0m  27.7512\n",
      "     14        \u001b[36m0.3387\u001b[0m  27.7833\n",
      "     15        0.3545  27.7309\n",
      "     16        0.3600  27.7545\n",
      "     17        0.3418  27.7425\n",
      "     18        0.3408  27.7157\n",
      "     19        0.3471  27.7130\n",
      "     20        \u001b[36m0.3337\u001b[0m  27.7072\n",
      "     21        0.3347  27.8916\n",
      "     22        \u001b[36m0.3259\u001b[0m  27.9212\n",
      "     23        \u001b[36m0.3172\u001b[0m  27.9784\n",
      "     24        \u001b[36m0.3085\u001b[0m  28.0043\n",
      "     25        \u001b[36m0.3060\u001b[0m  28.0333\n",
      "     26        0.3088  28.1361\n",
      "     27        \u001b[36m0.3035\u001b[0m  28.1764\n",
      "     28        0.3045  28.1592\n",
      "     29        \u001b[36m0.2893\u001b[0m  28.1869\n",
      "     30        0.2970  28.1460\n",
      "     31        \u001b[36m0.2635\u001b[0m  28.1516\n",
      "     32        0.2751  28.2600\n",
      "     33        \u001b[36m0.2451\u001b[0m  28.3016\n",
      "     34        0.2695  28.1310\n",
      "     35        0.2457  28.1806\n",
      "     36        \u001b[36m0.2167\u001b[0m  28.0558\n",
      "     37        \u001b[36m0.2102\u001b[0m  27.9841\n",
      "     38        0.2176  28.1640\n",
      "     39        0.2517  28.0239\n",
      "     40        \u001b[36m0.1929\u001b[0m  28.0749\n",
      "     41        \u001b[36m0.1754\u001b[0m  28.1863\n",
      "     42        0.1960  28.1875\n",
      "     43        0.1799  28.1760\n",
      "     44        0.1888  28.1290\n",
      "     45        0.1801  28.0735\n",
      "     46        \u001b[36m0.1483\u001b[0m  28.1193\n",
      "     47        \u001b[36m0.1301\u001b[0m  28.1774\n",
      "     48        0.1432  28.2691\n",
      "     49        0.1553  28.2609\n",
      "     50        0.1662  28.2333\n",
      "     51        0.1463  28.3201\n",
      "     52        \u001b[36m0.1249\u001b[0m  28.1740\n",
      "     53        \u001b[36m0.1130\u001b[0m  28.4826\n",
      "     54        \u001b[36m0.1002\u001b[0m  28.4324\n",
      "     55        0.1101  28.5812\n",
      "     56        0.1130  28.4639\n",
      "     57        \u001b[36m0.0949\u001b[0m  28.4881\n",
      "     58        0.0987  28.4416\n",
      "     59        0.1017  28.5564\n",
      "     60        0.1193  28.5952\n",
      "[CV 1/5] END batch_size=16, lr=0.01, max_epochs=60;, score=0.891 total time=28.5min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5107\u001b[0m  27.6016\n",
      "      2        \u001b[36m0.4132\u001b[0m  27.6304\n",
      "      3        0.4427  27.7019\n",
      "      4        \u001b[36m0.4039\u001b[0m  27.6764\n",
      "      5        0.4105  27.6654\n",
      "      6        \u001b[36m0.4003\u001b[0m  27.6911\n",
      "      7        0.4071  27.7000\n",
      "      8        \u001b[36m0.3888\u001b[0m  27.7013\n",
      "      9        \u001b[36m0.3752\u001b[0m  27.7195\n",
      "     10        0.3847  27.7221\n",
      "     11        \u001b[36m0.3660\u001b[0m  27.6523\n",
      "     12        \u001b[36m0.3574\u001b[0m  27.6366\n",
      "     13        0.3646  27.6069\n",
      "     14        \u001b[36m0.3562\u001b[0m  27.5816\n",
      "     15        0.3659  27.7220\n",
      "     16        0.3653  27.8077\n",
      "     17        \u001b[36m0.3470\u001b[0m  27.7668\n",
      "     18        \u001b[36m0.3429\u001b[0m  27.7665\n",
      "     19        0.3537  27.8447\n",
      "     20        0.3503  27.7582\n",
      "     21        0.3464  27.7190\n",
      "     22        0.3553  27.7395\n",
      "     23        0.3513  27.7492\n",
      "     24        0.3602  27.8080\n",
      "     25        \u001b[36m0.3394\u001b[0m  27.9525\n",
      "     26        \u001b[36m0.3267\u001b[0m  27.7869\n",
      "     27        \u001b[36m0.3226\u001b[0m  27.8223\n",
      "     28        0.3481  27.7928\n",
      "     29        0.3367  27.8018\n",
      "     30        0.3323  27.8878\n",
      "     31        0.3329  27.8811\n",
      "     32        \u001b[36m0.3159\u001b[0m  27.9084\n",
      "     33        \u001b[36m0.3151\u001b[0m  27.9448\n",
      "     34        \u001b[36m0.3063\u001b[0m  28.0009\n",
      "     35        \u001b[36m0.2982\u001b[0m  28.0700\n",
      "     36        0.3299  28.1491\n",
      "     37        0.3048  28.2590\n",
      "     38        0.3000  28.2730\n",
      "     39        \u001b[36m0.2976\u001b[0m  28.2206\n",
      "     40        \u001b[36m0.2593\u001b[0m  28.2785\n",
      "     41        0.2854  28.1596\n",
      "     42        \u001b[36m0.2529\u001b[0m  28.1438\n",
      "     43        0.2532  28.1754\n",
      "     44        0.2773  28.2495\n",
      "     45        0.2581  28.3201\n",
      "     46        0.2763  28.3690\n",
      "     47        \u001b[36m0.2519\u001b[0m  28.3871\n",
      "     48        \u001b[36m0.2358\u001b[0m  28.3667\n",
      "     49        \u001b[36m0.2201\u001b[0m  28.3713\n",
      "     50        \u001b[36m0.2139\u001b[0m  28.5399\n",
      "     51        \u001b[36m0.2036\u001b[0m  28.4811\n",
      "     52        0.2442  28.5227\n",
      "     53        0.2078  28.6122\n",
      "     54        0.2048  28.6117\n",
      "     55        \u001b[36m0.1899\u001b[0m  28.6440\n",
      "     56        \u001b[36m0.1690\u001b[0m  28.5717\n",
      "     57        \u001b[36m0.1633\u001b[0m  28.7408\n",
      "     58        \u001b[36m0.1605\u001b[0m  28.6585\n",
      "     59        0.1696  28.6785\n",
      "     60        \u001b[36m0.1587\u001b[0m  29.0517\n",
      "[CV 2/5] END batch_size=16, lr=0.01, max_epochs=60;, score=0.904 total time=28.5min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5531\u001b[0m  27.6029\n",
      "      2        \u001b[36m0.4058\u001b[0m  27.7092\n",
      "      3        0.4302  27.6180\n",
      "      4        \u001b[36m0.4022\u001b[0m  27.6182\n",
      "      5        \u001b[36m0.3910\u001b[0m  27.6736\n",
      "      6        \u001b[36m0.3907\u001b[0m  27.7458\n",
      "      7        \u001b[36m0.3776\u001b[0m  27.7189\n",
      "      8        \u001b[36m0.3693\u001b[0m  27.7014\n",
      "      9        0.3807  27.6905\n",
      "     10        0.3801  27.7172\n",
      "     11        \u001b[36m0.3599\u001b[0m  27.7452\n",
      "     12        \u001b[36m0.3508\u001b[0m  27.6368\n",
      "     13        0.3537  27.6678\n",
      "     14        0.3607  27.6915\n",
      "     15        0.3607  27.8329\n",
      "     16        \u001b[36m0.3410\u001b[0m  27.8040\n",
      "     17        \u001b[36m0.3338\u001b[0m  27.8252\n",
      "     18        0.3472  27.8307\n",
      "     19        0.3383  27.8212\n",
      "     20        0.3370  27.7904\n",
      "     21        \u001b[36m0.3190\u001b[0m  27.9182\n",
      "     22        \u001b[36m0.3168\u001b[0m  27.8542\n",
      "     23        \u001b[36m0.3025\u001b[0m  27.8451\n",
      "     24        0.3338  28.0314\n",
      "     25        0.3296  28.1000\n",
      "     26        0.3142  28.0567\n",
      "     27        \u001b[36m0.2942\u001b[0m  28.1109\n",
      "     28        0.3155  28.1399\n",
      "     29        \u001b[36m0.2904\u001b[0m  28.1747\n",
      "     30        \u001b[36m0.2825\u001b[0m  27.9725\n",
      "     31        \u001b[36m0.2759\u001b[0m  28.0665\n",
      "     32        0.2886  28.1654\n",
      "     33        0.2795  28.1044\n",
      "     34        0.2908  28.0684\n",
      "     35        0.2805  28.0163\n",
      "     36        0.2793  28.0713\n",
      "     37        \u001b[36m0.2608\u001b[0m  27.9571\n",
      "     38        \u001b[36m0.2577\u001b[0m  27.9395\n",
      "     39        \u001b[36m0.2400\u001b[0m  28.0422\n",
      "     40        0.2403  28.1596\n",
      "     41        0.2490  28.1802\n",
      "     42        \u001b[36m0.2361\u001b[0m  28.1575\n",
      "     43        0.2639  28.1218\n",
      "     44        0.2410  28.1148\n",
      "     45        \u001b[36m0.2174\u001b[0m  28.1865\n",
      "     46        \u001b[36m0.1981\u001b[0m  28.1452\n",
      "     47        0.2105  28.1516\n",
      "     48        0.2284  28.1518\n",
      "     49        \u001b[36m0.1977\u001b[0m  28.2598\n",
      "     50        0.2008  28.1380\n",
      "     51        0.2169  28.2115\n",
      "     52        \u001b[36m0.1840\u001b[0m  28.2532\n",
      "     53        \u001b[36m0.1569\u001b[0m  28.2717\n",
      "     54        \u001b[36m0.1546\u001b[0m  28.2862\n",
      "     55        0.1679  28.2420\n",
      "     56        0.1677  28.2750\n",
      "     57        \u001b[36m0.1476\u001b[0m  28.3415\n",
      "     58        0.1909  28.4974\n",
      "     59        \u001b[36m0.1382\u001b[0m  28.6310\n",
      "     60        0.1522  28.6035\n",
      "[CV 3/5] END batch_size=16, lr=0.01, max_epochs=60;, score=0.898 total time=28.5min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5006\u001b[0m  27.7395\n",
      "      2        \u001b[36m0.4835\u001b[0m  27.7140\n",
      "      3        \u001b[36m0.3966\u001b[0m  27.6918\n",
      "      4        0.3983  27.4913\n",
      "      5        \u001b[36m0.3830\u001b[0m  27.5783\n",
      "      6        \u001b[36m0.3827\u001b[0m  27.5164\n",
      "      7        \u001b[36m0.3643\u001b[0m  27.5712\n",
      "      8        0.3672  27.5434\n",
      "      9        0.3776  27.5464\n",
      "     10        \u001b[36m0.3585\u001b[0m  27.5651\n",
      "     11        \u001b[36m0.3577\u001b[0m  27.5606\n",
      "     12        0.3683  27.5108\n",
      "     13        0.3759  27.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14        \u001b[36m0.3517\u001b[0m  27.5875\n",
      "     15        0.3629  27.5701\n",
      "     16        \u001b[36m0.3416\u001b[0m  27.5766\n",
      "     17        0.3563  27.6057\n",
      "     18        0.3494  27.6051\n",
      "     19        \u001b[36m0.3268\u001b[0m  27.5683\n",
      "     20        0.3392  27.5594\n",
      "     21        \u001b[36m0.3240\u001b[0m  27.5692\n",
      "     22        0.3320  27.6398\n",
      "     23        0.3347  27.6639\n",
      "     24        0.3255  27.6647\n",
      "     25        0.3281  27.6193\n",
      "     26        \u001b[36m0.3163\u001b[0m  27.6359\n",
      "     27        \u001b[36m0.3109\u001b[0m  27.7206\n",
      "     28        0.3111  27.6784\n",
      "     29        \u001b[36m0.2927\u001b[0m  27.6807\n",
      "     30        \u001b[36m0.2869\u001b[0m  27.6791\n",
      "     31        \u001b[36m0.2854\u001b[0m  27.7161\n",
      "     32        \u001b[36m0.2795\u001b[0m  27.7259\n",
      "     33        \u001b[36m0.2724\u001b[0m  28.1283\n",
      "     34        0.2852  27.7600\n",
      "     35        \u001b[36m0.2706\u001b[0m  27.6916\n",
      "     36        \u001b[36m0.2614\u001b[0m  27.7337\n",
      "     37        \u001b[36m0.2366\u001b[0m  27.7123\n",
      "     38        0.2438  27.7316\n",
      "     39        \u001b[36m0.2353\u001b[0m  27.6776\n",
      "     40        \u001b[36m0.2313\u001b[0m  27.7305\n",
      "     41        \u001b[36m0.2154\u001b[0m  27.6884\n",
      "     42        \u001b[36m0.2092\u001b[0m  27.7202\n",
      "     43        0.2142  27.7467\n",
      "     44        0.2222  27.8007\n",
      "     45        0.2218  27.7320\n",
      "     46        \u001b[36m0.1883\u001b[0m  27.7459\n",
      "     47        \u001b[36m0.1790\u001b[0m  27.7423\n",
      "     48        \u001b[36m0.1780\u001b[0m  27.7249\n",
      "     49        0.1964  27.7821\n",
      "     50        0.1803  27.7086\n",
      "     51        \u001b[36m0.1633\u001b[0m  27.7954\n",
      "     52        \u001b[36m0.1434\u001b[0m  27.8009\n",
      "     53        0.1766  27.8757\n",
      "     54        0.1587  27.8668\n",
      "     55        \u001b[36m0.1401\u001b[0m  27.8513\n",
      "     56        0.1437  27.7846\n",
      "     57        0.1642  27.7910\n",
      "     58        0.1658  27.8080\n",
      "     59        \u001b[36m0.1315\u001b[0m  27.8393\n",
      "     60        \u001b[36m0.1240\u001b[0m  27.8149\n",
      "[CV 4/5] END batch_size=16, lr=0.01, max_epochs=60;, score=0.907 total time=28.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5827\u001b[0m  27.4464\n",
      "      2        \u001b[36m0.4082\u001b[0m  27.4097\n",
      "      3        0.4307  27.4133\n",
      "      4        \u001b[36m0.4006\u001b[0m  27.4107\n",
      "      5        \u001b[36m0.3919\u001b[0m  27.5350\n",
      "      6        \u001b[36m0.3865\u001b[0m  27.4339\n",
      "      7        \u001b[36m0.3792\u001b[0m  27.4393\n",
      "      8        \u001b[36m0.3672\u001b[0m  27.4229\n",
      "      9        \u001b[36m0.3609\u001b[0m  27.4722\n",
      "     10        0.3612  27.4680\n",
      "     11        \u001b[36m0.3499\u001b[0m  27.4353\n",
      "     12        0.3528  27.4660\n",
      "     13        0.3611  27.4665\n",
      "     14        0.3626  27.4790\n",
      "     15        \u001b[36m0.3415\u001b[0m  27.4807\n",
      "     16        \u001b[36m0.3374\u001b[0m  27.4121\n",
      "     17        0.3498  27.4139\n",
      "     18        0.3507  27.4152\n",
      "     19        0.3380  27.4026\n",
      "     20        0.3387  27.4170\n",
      "     21        \u001b[36m0.3268\u001b[0m  27.5135\n",
      "     22        0.3327  27.4768\n",
      "     23        0.3372  27.4376\n",
      "     24        \u001b[36m0.3208\u001b[0m  27.5225\n",
      "     25        \u001b[36m0.3114\u001b[0m  27.5306\n",
      "     26        \u001b[36m0.3087\u001b[0m  27.5538\n",
      "     27        0.3265  27.6894\n",
      "     28        \u001b[36m0.2942\u001b[0m  27.6783\n",
      "     29        0.3000  27.7430\n",
      "     30        \u001b[36m0.2834\u001b[0m  28.1624\n",
      "     31        0.2898  29.1001\n",
      "     32        0.2847  29.1351\n",
      "     33        \u001b[36m0.2692\u001b[0m  30.8120\n",
      "     34        0.2941  28.7430\n",
      "     35        0.2788  28.0820\n",
      "     36        \u001b[36m0.2493\u001b[0m  28.0951\n",
      "     37        \u001b[36m0.2434\u001b[0m  28.0182\n",
      "     38        0.2616  28.0043\n",
      "     39        0.2516  28.1152\n",
      "     40        \u001b[36m0.2285\u001b[0m  28.1846\n",
      "     41        \u001b[36m0.2225\u001b[0m  28.1596\n",
      "     42        0.2327  28.1764\n",
      "     43        \u001b[36m0.1914\u001b[0m  28.1250\n",
      "     44        \u001b[36m0.1813\u001b[0m  28.2619\n",
      "     45        0.2042  28.2420\n",
      "     46        \u001b[36m0.1684\u001b[0m  28.2630\n",
      "     47        0.1830  29.3012\n",
      "     48        \u001b[36m0.1674\u001b[0m  31.0732\n",
      "     49        0.1768  35.2511\n",
      "     50        \u001b[36m0.1321\u001b[0m  36.6179\n",
      "     51        \u001b[36m0.1256\u001b[0m  36.9624\n",
      "     52        0.1446  35.3156\n",
      "     53        0.1441  34.7398\n",
      "     54        0.1629  33.3387\n",
      "     55        0.1439  33.6257\n",
      "     56        \u001b[36m0.1176\u001b[0m  33.9816\n",
      "     57        0.1224  33.6177\n",
      "     58        \u001b[36m0.1162\u001b[0m  33.6226\n",
      "     59        0.1439  34.0948\n",
      "     60        \u001b[36m0.0883\u001b[0m  33.4993\n",
      "[CV 5/5] END batch_size=16, lr=0.01, max_epochs=60;, score=0.879 total time=29.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4883\u001b[0m  33.0109\n",
      "      2        \u001b[36m0.4142\u001b[0m  30.5563\n",
      "      3        0.4455  27.6327\n",
      "      4        \u001b[36m0.4132\u001b[0m  27.6469\n",
      "      5        \u001b[36m0.3956\u001b[0m  27.7070\n",
      "      6        0.4105  27.6952\n",
      "      7        \u001b[36m0.3737\u001b[0m  27.7316\n",
      "      8        \u001b[36m0.3513\u001b[0m  27.7527\n",
      "      9        0.3696  27.7621\n",
      "     10        0.3701  27.7113\n",
      "     11        0.3597  27.8012\n",
      "     12        0.3535  27.8204\n",
      "     13        0.3599  27.7293\n",
      "     14        \u001b[36m0.3450\u001b[0m  27.8487\n",
      "     15        \u001b[36m0.3341\u001b[0m  27.8034\n",
      "     16        0.3365  27.8320\n",
      "     17        0.3353  27.9228\n",
      "     18        0.3447  28.0118\n",
      "     19        \u001b[36m0.3321\u001b[0m  27.9825\n",
      "     20        0.3329  28.0449\n",
      "     21        \u001b[36m0.3060\u001b[0m  28.0840\n",
      "     22        \u001b[36m0.3044\u001b[0m  28.1350\n",
      "     23        \u001b[36m0.3019\u001b[0m  28.1761\n",
      "     24        0.3188  28.1409\n",
      "     25        0.3278  28.2770\n",
      "     26        \u001b[36m0.2973\u001b[0m  28.3355\n",
      "     27        0.3116  28.6376\n",
      "     28        0.3167  28.5777\n",
      "     29        \u001b[36m0.2939\u001b[0m  28.5671\n",
      "     30        \u001b[36m0.2864\u001b[0m  28.5385\n",
      "     31        0.2940  28.6352\n",
      "     32        0.2926  28.4772\n",
      "     33        \u001b[36m0.2821\u001b[0m  28.5060\n",
      "     34        \u001b[36m0.2666\u001b[0m  28.5590\n",
      "     35        0.2818  28.7171\n",
      "     36        \u001b[36m0.2399\u001b[0m  28.6871\n",
      "     37        0.2495  28.7403\n",
      "     38        \u001b[36m0.2308\u001b[0m  28.8040\n",
      "     39        0.2525  28.8176\n",
      "     40        0.2315  28.8327\n",
      "     41        0.2552  28.9385\n",
      "     42        0.2477  28.9192\n",
      "     43        \u001b[36m0.1961\u001b[0m  28.9696\n",
      "     44        0.2165  28.9584\n",
      "     45        \u001b[36m0.1947\u001b[0m  28.9710\n",
      "     46        0.2127  28.8743\n",
      "     47        \u001b[36m0.1740\u001b[0m  28.7879\n",
      "     48        0.2109  28.9200\n",
      "     49        0.2080  28.9556\n",
      "     50        0.2108  28.8813\n",
      "     51        \u001b[36m0.1707\u001b[0m  28.8721\n",
      "     52        \u001b[36m0.1533\u001b[0m  28.8728\n",
      "     53        0.1854  28.9362\n",
      "     54        \u001b[36m0.1514\u001b[0m  28.9874\n",
      "     55        0.1681  28.9682\n",
      "     56        0.1585  29.0673\n",
      "     57        \u001b[36m0.1192\u001b[0m  29.0779\n",
      "     58        0.1396  29.0153\n",
      "     59        0.1430  29.0336\n",
      "     60        \u001b[36m0.1072\u001b[0m  29.1317\n",
      "     61        0.1320  29.0380\n",
      "     62        0.1205  28.9675\n",
      "     63        0.1289  29.0167\n",
      "     64        0.1079  28.9957\n",
      "     65        \u001b[36m0.0693\u001b[0m  28.9983\n",
      "     66        0.1029  29.0906\n",
      "     67        0.1068  29.1512\n",
      "     68        0.0774  29.1075\n",
      "     69        0.0966  29.0264\n",
      "     70        0.1074  29.1037\n",
      "     71        0.0849  29.0730\n",
      "     72        0.0932  29.0988\n",
      "     73        0.0833  29.1537\n",
      "     74        0.0835  29.0269\n",
      "     75        \u001b[36m0.0613\u001b[0m  29.1186\n",
      "     76        0.0835  29.1786\n",
      "     77        0.0747  29.1007\n",
      "     78        0.0645  28.9490\n",
      "     79        0.0672  29.0210\n",
      "     80        0.0772  29.0532\n",
      "[CV 1/5] END batch_size=16, lr=0.01, max_epochs=80;, score=0.882 total time=38.7min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5107\u001b[0m  27.6605\n",
      "      2        \u001b[36m0.4134\u001b[0m  27.7031\n",
      "      3        0.4307  27.6673\n",
      "      4        \u001b[36m0.4060\u001b[0m  27.7548\n",
      "      5        \u001b[36m0.3821\u001b[0m  27.7240\n",
      "      6        0.3927  27.7214\n",
      "      7        \u001b[36m0.3742\u001b[0m  27.7513\n",
      "      8        \u001b[36m0.3688\u001b[0m  27.7447\n",
      "      9        0.3790  27.7483\n",
      "     10        \u001b[36m0.3591\u001b[0m  27.7118\n",
      "     11        \u001b[36m0.3557\u001b[0m  27.6576\n",
      "     12        \u001b[36m0.3344\u001b[0m  27.6515\n",
      "     13        0.3668  27.7965\n",
      "     14        0.3435  27.6428\n",
      "     15        0.3533  27.8183\n",
      "     16        0.3577  27.6342\n",
      "     17        0.3394  27.6916\n",
      "     18        0.3481  27.6696\n",
      "     19        0.3414  27.7105\n",
      "     20        \u001b[36m0.3225\u001b[0m  27.7496\n",
      "     21        \u001b[36m0.3157\u001b[0m  27.7151\n",
      "     22        0.3345  27.6357\n",
      "     23        0.3168  27.7207\n",
      "     24        0.3309  27.7060\n",
      "     25        0.3211  27.6784\n",
      "     26        \u001b[36m0.3095\u001b[0m  27.7442\n",
      "     27        0.3192  27.7096\n",
      "     28        0.3178  27.7556\n",
      "     29        \u001b[36m0.2772\u001b[0m  27.7614\n",
      "     30        0.2945  27.8602\n",
      "     31        0.2950  27.7774\n",
      "     32        0.2786  27.8607\n",
      "     33        \u001b[36m0.2757\u001b[0m  27.9168\n",
      "     34        \u001b[36m0.2643\u001b[0m  27.9332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35        0.2658  27.9184\n",
      "     36        0.2654  27.8504\n",
      "     37        0.2768  27.8565\n",
      "     38        \u001b[36m0.2499\u001b[0m  27.9872\n",
      "     39        0.2538  28.0219\n",
      "     40        \u001b[36m0.2412\u001b[0m  28.0462\n",
      "     41        \u001b[36m0.2252\u001b[0m  27.9709\n",
      "     42        0.2273  28.0219\n",
      "     43        \u001b[36m0.2201\u001b[0m  28.0407\n",
      "     44        \u001b[36m0.2078\u001b[0m  28.0079\n",
      "     45        0.2210  28.0858\n",
      "     46        \u001b[36m0.1994\u001b[0m  28.1029\n",
      "     47        \u001b[36m0.1708\u001b[0m  28.1569\n",
      "     48        \u001b[36m0.1591\u001b[0m  28.1447\n",
      "     49        0.1771  28.1373\n",
      "     50        0.1812  28.1614\n",
      "     51        \u001b[36m0.1568\u001b[0m  28.2956\n",
      "     52        \u001b[36m0.1446\u001b[0m  28.0773\n",
      "     53        0.1820  28.1089\n",
      "     54        0.1529  28.0811\n",
      "     55        0.1761  28.0750\n",
      "     56        \u001b[36m0.1397\u001b[0m  28.1291\n",
      "     57        \u001b[36m0.1229\u001b[0m  28.0821\n",
      "     58        \u001b[36m0.1049\u001b[0m  28.1388\n",
      "     59        0.1251  28.2386\n",
      "     60        0.1050  28.1658\n",
      "     61        0.1058  28.1869\n",
      "     62        0.1103  28.1663\n",
      "     63        0.1370  28.2154\n",
      "     64        0.1178  28.2428\n",
      "     65        0.1069  28.2819\n",
      "     66        \u001b[36m0.0924\u001b[0m  28.2388\n",
      "     67        0.0958  28.2320\n",
      "     68        0.1188  28.2968\n",
      "     69        0.1168  28.2888\n",
      "     70        \u001b[36m0.0862\u001b[0m  28.2383\n",
      "     71        \u001b[36m0.0717\u001b[0m  28.2260\n",
      "     72        0.0886  28.2851\n",
      "     73        0.0822  28.2728\n",
      "     74        0.0725  28.4379\n",
      "     75        0.0998  28.4976\n",
      "     76        0.0823  28.4746\n",
      "     77        0.0718  28.5886\n",
      "     78        \u001b[36m0.0570\u001b[0m  28.5937\n",
      "     79        0.1092  28.5008\n",
      "     80        \u001b[36m0.0545\u001b[0m  28.5812\n",
      "[CV 2/5] END batch_size=16, lr=0.01, max_epochs=80;, score=0.922 total time=37.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5387\u001b[0m  27.7386\n",
      "      2        \u001b[36m0.4577\u001b[0m  27.7363\n",
      "      3        \u001b[36m0.4219\u001b[0m  27.7819\n",
      "      4        \u001b[36m0.3960\u001b[0m  27.8189\n",
      "      5        \u001b[36m0.3826\u001b[0m  27.7870\n",
      "      6        \u001b[36m0.3760\u001b[0m  27.7685\n",
      "      7        \u001b[36m0.3702\u001b[0m  27.5503\n",
      "      8        \u001b[36m0.3676\u001b[0m  27.5816\n",
      "      9        \u001b[36m0.3565\u001b[0m  27.5547\n",
      "     10        0.3572  27.6149\n",
      "     11        \u001b[36m0.3456\u001b[0m  27.7568\n",
      "     12        \u001b[36m0.3390\u001b[0m  27.7613\n",
      "     13        0.3491  27.8581\n",
      "     14        0.3439  27.7918\n",
      "     15        0.3442  27.7938\n",
      "     16        0.3426  27.8289\n",
      "     17        \u001b[36m0.3369\u001b[0m  27.8067\n",
      "     18        \u001b[36m0.3279\u001b[0m  27.7228\n",
      "     19        0.3404  27.6851\n",
      "     20        0.3309  27.6845\n",
      "     21        \u001b[36m0.3155\u001b[0m  27.6689\n",
      "     22        0.3288  27.7534\n",
      "     23        0.3184  27.8080\n",
      "     24        \u001b[36m0.3065\u001b[0m  27.7846\n",
      "     25        \u001b[36m0.3036\u001b[0m  27.7971\n",
      "     26        \u001b[36m0.2980\u001b[0m  27.8212\n",
      "     27        \u001b[36m0.2940\u001b[0m  27.8669\n",
      "     28        0.3212  27.7992\n",
      "     29        0.2961  27.8206\n",
      "     30        \u001b[36m0.2832\u001b[0m  27.8157\n",
      "     31        \u001b[36m0.2820\u001b[0m  27.7647\n",
      "     32        \u001b[36m0.2756\u001b[0m  27.7993\n",
      "     33        0.2797  27.8369\n",
      "     34        0.2871  27.8377\n",
      "     35        \u001b[36m0.2529\u001b[0m  27.8549\n",
      "     36        0.2548  27.8726\n",
      "     37        0.2588  27.9459\n",
      "     38        \u001b[36m0.2434\u001b[0m  28.0303\n",
      "     39        \u001b[36m0.2337\u001b[0m  28.0342\n",
      "     40        \u001b[36m0.2310\u001b[0m  28.0476\n",
      "     41        0.2593  28.1014\n",
      "     42        0.2439  28.0781\n",
      "     43        0.2404  28.0255\n",
      "     44        \u001b[36m0.2171\u001b[0m  27.9212\n",
      "     45        \u001b[36m0.2096\u001b[0m  27.9165\n",
      "     46        \u001b[36m0.1885\u001b[0m  27.9429\n",
      "     47        \u001b[36m0.1771\u001b[0m  27.9840\n",
      "     48        0.1826  27.8792\n",
      "     49        \u001b[36m0.1729\u001b[0m  27.9503\n",
      "     50        \u001b[36m0.1681\u001b[0m  27.9718\n",
      "     51        \u001b[36m0.1570\u001b[0m  27.9531\n",
      "     52        0.1672  27.9833\n",
      "     53        0.1618  28.0326\n",
      "     54        \u001b[36m0.1419\u001b[0m  28.0507\n",
      "     55        0.1588  27.9344\n",
      "     56        0.1502  27.9827\n",
      "     57        0.1487  28.0505\n",
      "     58        \u001b[36m0.1337\u001b[0m  27.9702\n",
      "     59        0.1542  27.9744\n",
      "     60        \u001b[36m0.1297\u001b[0m  28.0071\n",
      "     61        \u001b[36m0.1277\u001b[0m  28.0524\n",
      "     62        0.1437  28.0205\n",
      "     63        \u001b[36m0.1003\u001b[0m  28.0230\n",
      "     64        0.1154  28.0418\n",
      "     65        0.1206  28.0872\n",
      "     66        0.1171  27.9897\n",
      "     67        0.1129  27.9649\n",
      "     68        0.1307  28.0216\n",
      "     69        \u001b[36m0.0826\u001b[0m  28.0201\n",
      "     70        0.1091  27.9543\n",
      "     71        0.0965  27.9212\n",
      "     72        0.0931  27.9958\n",
      "     73        0.1122  28.0014\n",
      "     74        0.0994  27.9850\n",
      "     75        \u001b[36m0.0696\u001b[0m  27.9888\n",
      "     76        0.0818  28.0401\n",
      "     77        0.1052  28.0117\n",
      "     78        0.0875  28.0191\n",
      "     79        \u001b[36m0.0505\u001b[0m  27.9617\n",
      "     80        0.0750  27.9969\n",
      "[CV 3/5] END batch_size=16, lr=0.01, max_epochs=80;, score=0.913 total time=37.7min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5561\u001b[0m  27.5618\n",
      "      2        \u001b[36m0.4235\u001b[0m  27.5446\n",
      "      3        \u001b[36m0.3895\u001b[0m  27.6696\n",
      "      4        \u001b[36m0.3816\u001b[0m  27.7759\n",
      "      5        \u001b[36m0.3709\u001b[0m  27.7962\n",
      "      6        0.3726  27.7778\n",
      "      7        0.3726  27.7749\n",
      "      8        \u001b[36m0.3610\u001b[0m  27.8091\n",
      "      9        \u001b[36m0.3609\u001b[0m  27.8341\n",
      "     10        0.3675  27.8074\n",
      "     11        \u001b[36m0.3501\u001b[0m  27.8187\n",
      "     12        0.3595  27.8272\n",
      "     13        \u001b[36m0.3466\u001b[0m  27.8488\n",
      "     14        0.3548  27.8527\n",
      "     15        \u001b[36m0.3330\u001b[0m  27.8199\n",
      "     16        \u001b[36m0.3291\u001b[0m  27.8344\n",
      "     17        0.3366  27.9162\n",
      "     18        0.3413  27.9138\n",
      "     19        \u001b[36m0.3232\u001b[0m  27.8665\n",
      "     20        \u001b[36m0.3215\u001b[0m  27.9019\n",
      "     21        0.3232  27.8039\n",
      "     22        0.3352  27.8384\n",
      "     23        0.3516  27.8051\n",
      "     24        \u001b[36m0.3186\u001b[0m  27.7275\n",
      "     25        \u001b[36m0.3129\u001b[0m  27.8282\n",
      "     26        \u001b[36m0.2922\u001b[0m  27.8714\n",
      "     27        0.2992  27.8869\n",
      "     28        0.3035  27.7931\n",
      "     29        \u001b[36m0.2800\u001b[0m  27.8178\n",
      "     30        0.2855  27.9445\n",
      "     31        0.2810  27.9664\n",
      "     32        0.2830  27.8633\n",
      "     33        0.3199  28.0360\n",
      "     34        0.2971  28.0598\n",
      "     35        \u001b[36m0.2747\u001b[0m  28.1238\n",
      "     36        0.2860  28.1469\n",
      "     37        \u001b[36m0.2566\u001b[0m  28.2289\n",
      "     38        0.2825  28.2251\n",
      "     39        \u001b[36m0.2527\u001b[0m  28.2983\n",
      "     40        \u001b[36m0.2447\u001b[0m  28.2757\n",
      "     41        \u001b[36m0.2430\u001b[0m  28.4420\n",
      "     42        \u001b[36m0.2284\u001b[0m  28.3582\n",
      "     43        0.2319  28.4247\n",
      "     44        \u001b[36m0.2256\u001b[0m  28.5101\n",
      "     45        \u001b[36m0.2014\u001b[0m  28.5078\n",
      "     46        \u001b[36m0.1872\u001b[0m  28.4384\n",
      "     47        0.2023  28.5538\n",
      "     48        0.1984  28.6115\n",
      "     49        \u001b[36m0.1835\u001b[0m  28.5315\n",
      "     50        \u001b[36m0.1748\u001b[0m  28.4450\n",
      "     51        \u001b[36m0.1542\u001b[0m  28.3974\n",
      "     52        0.1782  28.4193\n",
      "     53        \u001b[36m0.1480\u001b[0m  28.4065\n",
      "     54        0.1499  28.4643\n",
      "     55        0.1487  28.4383\n",
      "     56        \u001b[36m0.1368\u001b[0m  28.5111\n",
      "     57        0.1437  28.5464\n",
      "     58        \u001b[36m0.1366\u001b[0m  28.5383\n",
      "     59        \u001b[36m0.1256\u001b[0m  28.5567\n",
      "     60        0.1302  28.7681\n",
      "     61        \u001b[36m0.1022\u001b[0m  28.6845\n",
      "     62        0.1273  28.6856\n",
      "     63        0.1225  28.8080\n",
      "     64        0.1129  28.7886\n",
      "     65        0.1025  28.8110\n",
      "     66        \u001b[36m0.0907\u001b[0m  28.8219\n",
      "     67        0.0948  28.7158\n",
      "     68        \u001b[36m0.0826\u001b[0m  28.6690\n",
      "     69        0.1254  29.1277\n",
      "     70        0.0831  29.1529\n",
      "     71        \u001b[36m0.0709\u001b[0m  28.9422\n",
      "     72        0.0916  28.9005\n",
      "     73        \u001b[36m0.0642\u001b[0m  28.8815\n",
      "     74        0.0718  29.0035\n",
      "     75        0.0731  29.0517\n",
      "     76        0.0895  29.0132\n",
      "     77        0.0776  29.0611\n",
      "     78        \u001b[36m0.0506\u001b[0m  29.1411\n",
      "     79        0.0526  29.1092\n",
      "     80        0.0896  29.0224\n",
      "[CV 4/5] END batch_size=16, lr=0.01, max_epochs=80;, score=0.919 total time=38.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5704\u001b[0m  27.6754\n",
      "      2        \u001b[36m0.4386\u001b[0m  27.6570\n",
      "      3        \u001b[36m0.4239\u001b[0m  27.6023\n",
      "      4        \u001b[36m0.3767\u001b[0m  27.6109\n",
      "      5        0.3908  27.5937\n",
      "      6        \u001b[36m0.3673\u001b[0m  27.5445\n",
      "      7        0.3737  27.5099\n",
      "      8        \u001b[36m0.3672\u001b[0m  27.5545\n",
      "      9        \u001b[36m0.3662\u001b[0m  27.5689\n",
      "     10        0.3704  27.5509\n",
      "     11        \u001b[36m0.3561\u001b[0m  27.5578\n",
      "     12        \u001b[36m0.3527\u001b[0m  27.6376\n",
      "     13        \u001b[36m0.3521\u001b[0m  27.6188\n",
      "     14        0.3626  27.5616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        \u001b[36m0.3500\u001b[0m  27.6521\n",
      "     16        0.3654  27.5838\n",
      "     17        0.3532  27.5191\n",
      "     18        \u001b[36m0.3453\u001b[0m  27.5878\n",
      "     19        \u001b[36m0.3371\u001b[0m  27.5873\n",
      "     20        \u001b[36m0.3274\u001b[0m  27.6313\n",
      "     21        \u001b[36m0.3228\u001b[0m  27.6182\n",
      "     22        0.3314  27.6669\n",
      "     23        \u001b[36m0.3119\u001b[0m  27.6104\n",
      "     24        0.3326  27.6434\n",
      "     25        \u001b[36m0.3095\u001b[0m  27.7451\n",
      "     26        \u001b[36m0.2893\u001b[0m  27.7766\n",
      "     27        0.2932  27.7697\n",
      "     28        0.2970  27.8681\n",
      "     29        0.2921  27.8850\n",
      "     30        \u001b[36m0.2836\u001b[0m  27.8559\n",
      "     31        0.2889  28.0895\n",
      "     32        \u001b[36m0.2826\u001b[0m  28.3076\n",
      "     33        \u001b[36m0.2631\u001b[0m  28.3350\n",
      "     34        0.2688  28.3009\n",
      "     35        \u001b[36m0.2615\u001b[0m  28.2742\n",
      "     36        \u001b[36m0.2522\u001b[0m  28.2364\n",
      "     37        \u001b[36m0.2235\u001b[0m  28.5902\n",
      "     38        0.2408  28.4719\n",
      "     39        0.2332  28.4742\n",
      "     40        0.2347  28.3800\n",
      "     41        \u001b[36m0.2078\u001b[0m  28.4229\n",
      "     42        0.2232  28.4506\n",
      "     43        \u001b[36m0.1813\u001b[0m  28.5827\n",
      "     44        \u001b[36m0.1760\u001b[0m  28.6662\n",
      "     45        \u001b[36m0.1736\u001b[0m  28.7077\n",
      "     46        0.1833  28.6960\n",
      "     47        \u001b[36m0.1559\u001b[0m  28.6653\n",
      "     48        0.2100  28.7300\n",
      "     49        0.1678  28.6598\n",
      "     50        0.1756  28.6518\n",
      "     51        \u001b[36m0.1394\u001b[0m  28.6298\n",
      "     52        \u001b[36m0.1316\u001b[0m  28.8245\n",
      "     53        \u001b[36m0.1244\u001b[0m  28.7772\n",
      "     54        \u001b[36m0.1016\u001b[0m  28.8603\n",
      "     55        0.1276  28.9578\n",
      "     56        \u001b[36m0.0900\u001b[0m  29.0489\n",
      "     57        0.1288  29.0049\n",
      "     58        0.1355  28.9300\n",
      "     59        0.1089  28.8819\n",
      "     60        0.1060  28.9896\n",
      "     61        0.1192  28.9037\n",
      "     62        0.1006  28.8504\n",
      "     63        0.1106  28.8730\n",
      "     64        \u001b[36m0.0715\u001b[0m  28.8845\n",
      "     65        0.0871  28.8039\n",
      "     66        0.0807  28.7930\n",
      "     67        0.0836  28.7834\n",
      "     68        0.0738  28.9939\n",
      "     69        0.0889  28.8722\n",
      "     70        0.0896  28.8058\n",
      "     71        \u001b[36m0.0657\u001b[0m  28.6661\n",
      "     72        0.0765  28.6106\n",
      "     73        \u001b[36m0.0655\u001b[0m  28.6993\n",
      "     74        \u001b[36m0.0570\u001b[0m  28.7715\n",
      "     75        \u001b[36m0.0479\u001b[0m  28.6841\n",
      "     76        \u001b[36m0.0451\u001b[0m  28.7873\n",
      "     77        0.0668  28.8280\n",
      "     78        0.0807  28.7254\n",
      "     79        0.0652  28.6747\n",
      "     80        0.0473  28.6512\n",
      "[CV 5/5] END batch_size=16, lr=0.01, max_epochs=80;, score=0.922 total time=38.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4370\u001b[0m  24.3760\n",
      "      2        \u001b[36m0.3577\u001b[0m  24.3921\n",
      "      3        0.3700  24.4049\n",
      "      4        0.3601  24.3480\n",
      "      5        \u001b[36m0.3346\u001b[0m  24.4401\n",
      "      6        0.3532  24.3589\n",
      "      7        0.3382  24.3394\n",
      "      8        \u001b[36m0.3095\u001b[0m  24.3885\n",
      "      9        0.3145  24.4395\n",
      "     10        0.3118  24.5198\n",
      "     11        \u001b[36m0.3068\u001b[0m  24.4269\n",
      "     12        \u001b[36m0.2863\u001b[0m  24.4362\n",
      "     13        \u001b[36m0.2649\u001b[0m  24.4148\n",
      "     14        0.2809  24.4595\n",
      "     15        \u001b[36m0.2617\u001b[0m  24.5261\n",
      "     16        \u001b[36m0.2397\u001b[0m  24.4468\n",
      "     17        0.2537  24.4420\n",
      "     18        \u001b[36m0.2256\u001b[0m  24.5014\n",
      "     19        0.2322  24.5036\n",
      "     20        0.2271  24.4799\n",
      "     21        \u001b[36m0.1835\u001b[0m  24.4449\n",
      "     22        0.1957  24.4775\n",
      "     23        0.1911  24.4686\n",
      "     24        0.1945  24.5445\n",
      "     25        \u001b[36m0.1641\u001b[0m  24.5411\n",
      "     26        \u001b[36m0.1390\u001b[0m  24.5385\n",
      "     27        0.1410  24.5258\n",
      "     28        \u001b[36m0.1313\u001b[0m  24.5668\n",
      "     29        0.1354  24.5727\n",
      "     30        \u001b[36m0.1304\u001b[0m  24.5601\n",
      "     31        \u001b[36m0.1147\u001b[0m  24.5768\n",
      "     32        0.1317  24.5630\n",
      "     33        0.1235  24.4823\n",
      "     34        0.1190  24.5216\n",
      "     35        \u001b[36m0.0982\u001b[0m  24.4584\n",
      "     36        0.1076  24.4511\n",
      "     37        \u001b[36m0.0752\u001b[0m  24.4487\n",
      "     38        0.0801  24.4179\n",
      "     39        \u001b[36m0.0623\u001b[0m  24.4363\n",
      "     40        0.1136  24.4654\n",
      "[CV 1/5] END batch_size=32, lr=0.001, max_epochs=40;, score=0.904 total time=16.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4346\u001b[0m  24.4963\n",
      "      2        \u001b[36m0.3819\u001b[0m  24.5178\n",
      "      3        \u001b[36m0.3534\u001b[0m  24.4997\n",
      "      4        0.3567  24.4166\n",
      "      5        \u001b[36m0.3411\u001b[0m  24.4625\n",
      "      6        \u001b[36m0.3348\u001b[0m  24.4917\n",
      "      7        \u001b[36m0.3257\u001b[0m  24.5176\n",
      "      8        \u001b[36m0.3152\u001b[0m  24.5124\n",
      "      9        \u001b[36m0.3029\u001b[0m  24.4438\n",
      "     10        0.3189  24.4494\n",
      "     11        \u001b[36m0.2952\u001b[0m  24.4878\n",
      "     12        0.2968  24.4652\n",
      "     13        \u001b[36m0.2772\u001b[0m  24.5133\n",
      "     14        \u001b[36m0.2530\u001b[0m  24.5062\n",
      "     15        \u001b[36m0.2344\u001b[0m  24.5101\n",
      "     16        0.2526  24.4359\n",
      "     17        \u001b[36m0.2281\u001b[0m  24.4566\n",
      "     18        0.2477  24.5192\n",
      "     19        \u001b[36m0.2086\u001b[0m  24.5134\n",
      "     20        0.2259  24.4708\n",
      "     21        \u001b[36m0.1949\u001b[0m  24.4853\n",
      "     22        \u001b[36m0.1471\u001b[0m  24.5055\n",
      "     23        0.1886  24.4947\n",
      "     24        0.1738  24.6160\n",
      "     25        \u001b[36m0.1364\u001b[0m  24.5641\n",
      "     26        0.1606  24.5995\n",
      "     27        0.1860  24.4978\n",
      "     28        \u001b[36m0.1308\u001b[0m  24.4648\n",
      "     29        0.1372  24.3968\n",
      "     30        \u001b[36m0.1231\u001b[0m  24.4543\n",
      "     31        \u001b[36m0.1212\u001b[0m  24.5239\n",
      "     32        0.1281  24.4413\n",
      "     33        \u001b[36m0.1055\u001b[0m  24.4382\n",
      "     34        \u001b[36m0.0894\u001b[0m  24.4151\n",
      "     35        0.1169  24.4910\n",
      "     36        \u001b[36m0.0806\u001b[0m  24.4698\n",
      "     37        \u001b[36m0.0804\u001b[0m  24.4840\n",
      "     38        0.1240  24.5161\n",
      "     39        \u001b[36m0.0780\u001b[0m  24.5419\n",
      "     40        \u001b[36m0.0553\u001b[0m  24.5345\n",
      "[CV 2/5] END batch_size=32, lr=0.001, max_epochs=40;, score=0.941 total time=16.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4313\u001b[0m  24.4715\n",
      "      2        \u001b[36m0.3880\u001b[0m  24.4252\n",
      "      3        \u001b[36m0.3563\u001b[0m  24.4524\n",
      "      4        \u001b[36m0.3366\u001b[0m  24.4652\n",
      "      5        0.3632  24.4204\n",
      "      6        0.3378  24.5457\n",
      "      7        \u001b[36m0.3299\u001b[0m  24.4020\n",
      "      8        \u001b[36m0.3056\u001b[0m  24.4107\n",
      "      9        0.3078  24.3912\n",
      "     10        \u001b[36m0.2972\u001b[0m  24.4295\n",
      "     11        0.3101  24.4405\n",
      "     12        \u001b[36m0.2853\u001b[0m  24.3938\n",
      "     13        \u001b[36m0.2832\u001b[0m  24.4091\n",
      "     14        \u001b[36m0.2430\u001b[0m  24.3984\n",
      "     15        0.2695  24.3942\n",
      "     16        \u001b[36m0.2421\u001b[0m  24.5343\n",
      "     17        \u001b[36m0.2230\u001b[0m  24.4180\n",
      "     18        0.2518  24.4447\n",
      "     19        \u001b[36m0.2158\u001b[0m  24.4392\n",
      "     20        0.2174  24.3591\n",
      "     21        \u001b[36m0.1922\u001b[0m  24.4733\n",
      "     22        \u001b[36m0.1863\u001b[0m  24.3628\n",
      "     23        \u001b[36m0.1600\u001b[0m  24.3425\n",
      "     24        0.1896  24.3538\n",
      "     25        0.1640  24.4531\n",
      "     26        0.1648  24.5020\n",
      "     27        0.1623  24.4708\n",
      "     28        \u001b[36m0.1374\u001b[0m  24.4076\n",
      "     29        \u001b[36m0.1263\u001b[0m  24.3383\n",
      "     30        \u001b[36m0.1116\u001b[0m  24.3920\n",
      "     31        0.1463  24.3157\n",
      "     32        0.1248  24.3260\n",
      "     33        0.1367  24.3432\n",
      "     34        \u001b[36m0.1104\u001b[0m  24.3522\n",
      "     35        0.1291  24.3881\n",
      "     36        0.1301  24.3657\n",
      "     37        0.1148  24.3657\n",
      "     38        \u001b[36m0.0884\u001b[0m  24.3689\n",
      "     39        \u001b[36m0.0765\u001b[0m  24.3666\n",
      "     40        0.0995  24.3772\n",
      "[CV 3/5] END batch_size=32, lr=0.001, max_epochs=40;, score=0.888 total time=16.7min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4271\u001b[0m  24.3377\n",
      "      2        \u001b[36m0.3880\u001b[0m  24.3046\n",
      "      3        \u001b[36m0.3564\u001b[0m  24.2891\n",
      "      4        0.3760  24.3706\n",
      "      5        \u001b[36m0.3539\u001b[0m  24.3376\n",
      "      6        \u001b[36m0.3529\u001b[0m  24.3162\n",
      "      7        \u001b[36m0.3349\u001b[0m  24.3810\n",
      "      8        \u001b[36m0.3225\u001b[0m  24.4080\n",
      "      9        \u001b[36m0.3152\u001b[0m  24.4519\n",
      "     10        0.3191  24.4333\n",
      "     11        \u001b[36m0.2926\u001b[0m  24.4016\n",
      "     12        \u001b[36m0.2812\u001b[0m  24.3899\n",
      "     13        0.2984  24.3558\n",
      "     14        0.2818  24.3790\n",
      "     15        \u001b[36m0.2567\u001b[0m  24.3822\n",
      "     16        \u001b[36m0.2394\u001b[0m  24.4023\n",
      "     17        0.2744  24.5167\n",
      "     18        0.2534  24.4759\n",
      "     19        \u001b[36m0.1984\u001b[0m  24.5968\n",
      "     20        0.2323  24.5098\n",
      "     21        \u001b[36m0.1872\u001b[0m  24.4912\n",
      "     22        0.2033  24.5238\n",
      "     23        \u001b[36m0.1758\u001b[0m  24.5003\n",
      "     24        \u001b[36m0.1709\u001b[0m  24.5256\n",
      "     25        \u001b[36m0.1527\u001b[0m  24.4930\n",
      "     26        \u001b[36m0.1438\u001b[0m  24.4853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27        0.1466  24.4657\n",
      "     28        0.1626  24.4935\n",
      "     29        \u001b[36m0.1399\u001b[0m  24.5300\n",
      "     30        \u001b[36m0.1399\u001b[0m  24.5230\n",
      "     31        0.1715  24.4646\n",
      "     32        \u001b[36m0.1292\u001b[0m  24.4687\n",
      "     33        \u001b[36m0.1009\u001b[0m  24.5066\n",
      "     34        0.1072  24.5427\n",
      "     35        0.1147  24.4712\n",
      "     36        \u001b[36m0.0984\u001b[0m  24.4625\n",
      "     37        \u001b[36m0.0774\u001b[0m  24.3287\n",
      "     38        \u001b[36m0.0728\u001b[0m  24.3432\n",
      "     39        \u001b[36m0.0717\u001b[0m  24.3925\n",
      "     40        0.0942  24.4177\n",
      "[CV 4/5] END batch_size=32, lr=0.001, max_epochs=40;, score=0.891 total time=16.7min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4317\u001b[0m  24.2438\n",
      "      2        \u001b[36m0.3595\u001b[0m  24.2906\n",
      "      3        \u001b[36m0.3526\u001b[0m  24.2554\n",
      "      4        \u001b[36m0.3508\u001b[0m  24.2124\n",
      "      5        \u001b[36m0.3502\u001b[0m  24.2682\n",
      "      6        \u001b[36m0.3303\u001b[0m  24.2523\n",
      "      7        0.3338  24.3098\n",
      "      8        \u001b[36m0.3199\u001b[0m  24.2475\n",
      "      9        0.3219  24.2033\n",
      "     10        \u001b[36m0.2807\u001b[0m  24.1813\n",
      "     11        0.2901  24.2108\n",
      "     12        \u001b[36m0.2627\u001b[0m  24.2116\n",
      "     13        \u001b[36m0.2536\u001b[0m  24.2234\n",
      "     14        0.2538  24.2105\n",
      "     15        \u001b[36m0.2425\u001b[0m  24.1877\n",
      "     16        \u001b[36m0.2146\u001b[0m  24.2642\n",
      "     17        \u001b[36m0.1954\u001b[0m  24.2804\n",
      "     18        0.1982  24.3188\n",
      "     19        0.2033  24.2699\n",
      "     20        \u001b[36m0.1748\u001b[0m  24.2569\n",
      "     21        \u001b[36m0.1727\u001b[0m  24.1917\n",
      "     22        \u001b[36m0.1675\u001b[0m  24.2129\n",
      "     23        0.1715  24.1956\n",
      "     24        \u001b[36m0.1579\u001b[0m  24.1970\n",
      "     25        \u001b[36m0.1163\u001b[0m  24.1563\n",
      "     26        0.1634  24.1709\n",
      "     27        \u001b[36m0.1158\u001b[0m  24.1804\n",
      "     28        0.1782  24.1739\n",
      "     29        0.1464  24.2338\n",
      "     30        \u001b[36m0.1101\u001b[0m  24.1517\n",
      "     31        0.1106  24.2071\n",
      "     32        \u001b[36m0.0951\u001b[0m  24.1808\n",
      "     33        \u001b[36m0.0797\u001b[0m  24.1964\n",
      "     34        0.1083  24.1707\n",
      "     35        0.0826  24.2009\n",
      "     36        0.0982  24.2285\n",
      "     37        0.1047  24.2446\n",
      "     38        0.0929  24.2605\n",
      "     39        \u001b[36m0.0769\u001b[0m  24.1959\n",
      "     40        \u001b[36m0.0686\u001b[0m  24.1843\n",
      "[CV 5/5] END batch_size=32, lr=0.001, max_epochs=40;, score=0.888 total time=16.6min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4290\u001b[0m  24.4818\n",
      "      2        \u001b[36m0.3910\u001b[0m  24.4139\n",
      "      3        \u001b[36m0.3728\u001b[0m  24.4716\n",
      "      4        \u001b[36m0.3533\u001b[0m  24.4662\n",
      "      5        \u001b[36m0.3486\u001b[0m  24.5238\n",
      "      6        \u001b[36m0.3347\u001b[0m  24.5665\n",
      "      7        0.3389  24.4514\n",
      "      8        \u001b[36m0.3248\u001b[0m  24.4448\n",
      "      9        \u001b[36m0.3129\u001b[0m  24.4904\n",
      "     10        \u001b[36m0.2943\u001b[0m  24.5014\n",
      "     11        \u001b[36m0.2825\u001b[0m  24.5073\n",
      "     12        \u001b[36m0.2801\u001b[0m  24.5398\n",
      "     13        \u001b[36m0.2664\u001b[0m  24.5510\n",
      "     14        \u001b[36m0.2397\u001b[0m  24.5199\n",
      "     15        \u001b[36m0.2360\u001b[0m  24.6077\n",
      "     16        0.2856  24.5767\n",
      "     17        \u001b[36m0.2153\u001b[0m  24.4116\n",
      "     18        \u001b[36m0.2057\u001b[0m  24.4177\n",
      "     19        0.2217  24.3886\n",
      "     20        \u001b[36m0.1737\u001b[0m  24.3997\n",
      "     21        0.1795  24.3772\n",
      "     22        \u001b[36m0.1709\u001b[0m  24.3436\n",
      "     23        0.1722  24.4688\n",
      "     24        \u001b[36m0.1388\u001b[0m  24.4360\n",
      "     25        0.1673  24.4072\n",
      "     26        \u001b[36m0.1261\u001b[0m  24.4270\n",
      "     27        0.1301  24.4153\n",
      "     28        0.1494  24.4022\n",
      "     29        \u001b[36m0.1257\u001b[0m  24.4102\n",
      "     30        \u001b[36m0.1138\u001b[0m  24.4227\n",
      "     31        \u001b[36m0.0765\u001b[0m  24.3902\n",
      "     32        0.0785  24.3692\n",
      "     33        0.0985  24.4641\n",
      "     34        0.1126  24.3932\n",
      "     35        0.0930  24.4713\n",
      "     36        0.0997  24.4188\n",
      "     37        0.1008  24.4859\n",
      "     38        0.0995  24.5701\n",
      "     39        \u001b[36m0.0748\u001b[0m  24.6204\n",
      "     40        \u001b[36m0.0593\u001b[0m  24.6706\n",
      "     41        0.0924  24.5892\n",
      "     42        0.1026  24.5538\n",
      "     43        0.0653  24.5748\n",
      "     44        0.0684  24.5735\n",
      "     45        \u001b[36m0.0519\u001b[0m  24.6466\n",
      "     46        \u001b[36m0.0388\u001b[0m  24.5968\n",
      "     47        0.0520  24.7169\n",
      "     48        0.0566  24.6136\n",
      "     49        0.0450  24.5986\n",
      "     50        0.0498  24.6940\n",
      "     51        0.0439  24.5759\n",
      "     52        0.0517  24.5730\n",
      "     53        0.0585  24.5793\n",
      "     54        0.1013  24.5925\n",
      "     55        0.0766  24.6285\n",
      "     56        0.0625  24.6148\n",
      "     57        0.0613  24.5144\n",
      "     58        0.0512  24.5775\n",
      "     59        0.0576  24.5982\n",
      "     60        0.0540  24.5766\n",
      "[CV 1/5] END batch_size=32, lr=0.001, max_epochs=60;, score=0.913 total time=25.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4293\u001b[0m  24.5768\n",
      "      2        \u001b[36m0.3718\u001b[0m  24.6070\n",
      "      3        \u001b[36m0.3698\u001b[0m  24.6051\n",
      "      4        \u001b[36m0.3576\u001b[0m  24.5671\n",
      "      5        \u001b[36m0.3323\u001b[0m  24.5626\n",
      "      6        0.3521  24.5906\n",
      "      7        \u001b[36m0.3292\u001b[0m  24.5572\n",
      "      8        \u001b[36m0.3108\u001b[0m  24.6341\n",
      "      9        0.3115  24.5798\n",
      "     10        \u001b[36m0.3074\u001b[0m  24.6071\n",
      "     11        \u001b[36m0.3012\u001b[0m  24.6130\n",
      "     12        \u001b[36m0.2748\u001b[0m  24.5734\n",
      "     13        0.2884  24.6106\n",
      "     14        \u001b[36m0.2473\u001b[0m  24.5529\n",
      "     15        0.2736  24.5690\n",
      "     16        0.2643  24.5635\n",
      "     17        \u001b[36m0.2257\u001b[0m  24.5571\n",
      "     18        0.2302  24.5990\n",
      "     19        \u001b[36m0.2128\u001b[0m  24.5878\n",
      "     20        \u001b[36m0.2055\u001b[0m  24.5693\n",
      "     21        \u001b[36m0.1928\u001b[0m  24.5676\n",
      "     22        \u001b[36m0.1755\u001b[0m  24.5725\n",
      "     23        \u001b[36m0.1718\u001b[0m  24.6458\n",
      "     24        0.1778  24.6055\n",
      "     25        \u001b[36m0.1662\u001b[0m  24.6041\n",
      "     26        \u001b[36m0.1306\u001b[0m  24.5970\n",
      "     27        0.1389  24.5553\n",
      "     28        \u001b[36m0.1292\u001b[0m  24.4717\n",
      "     29        \u001b[36m0.1255\u001b[0m  24.4178\n",
      "     30        \u001b[36m0.1101\u001b[0m  24.4287\n",
      "     31        0.1231  24.4880\n",
      "     32        0.1127  24.4208\n",
      "     33        \u001b[36m0.0949\u001b[0m  24.4896\n",
      "     34        0.1302  24.4438\n",
      "     35        \u001b[36m0.0845\u001b[0m  24.5006\n",
      "     36        0.0892  24.5207\n",
      "     37        0.1246  24.5066\n",
      "     38        0.1036  24.4977\n",
      "     39        0.0900  24.4884\n",
      "     40        0.0946  24.4463\n",
      "     41        \u001b[36m0.0764\u001b[0m  24.4470\n",
      "     42        \u001b[36m0.0728\u001b[0m  24.5250\n",
      "     43        \u001b[36m0.0503\u001b[0m  24.4639\n",
      "     44        \u001b[36m0.0460\u001b[0m  24.4430\n",
      "     45        0.0742  24.4806\n",
      "     46        0.0829  24.5229\n",
      "     47        0.0474  24.5488\n",
      "     48        0.0599  24.4988\n",
      "     49        0.0606  24.4607\n",
      "     50        \u001b[36m0.0443\u001b[0m  24.5068\n",
      "     51        0.0529  24.5192\n",
      "     52        0.0687  24.5565\n",
      "     53        0.0662  24.5297\n",
      "     54        \u001b[36m0.0401\u001b[0m  24.5416\n",
      "     55        0.0594  24.5210\n",
      "     56        0.0547  24.5039\n",
      "     57        0.0456  24.5387\n",
      "     58        \u001b[36m0.0388\u001b[0m  24.4719\n",
      "     59        0.0514  24.4785\n",
      "     60        0.0406  24.5916\n",
      "[CV 2/5] END batch_size=32, lr=0.001, max_epochs=60;, score=0.947 total time=25.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4456\u001b[0m  24.5588\n",
      "      2        \u001b[36m0.3650\u001b[0m  24.5648\n",
      "      3        0.3669  24.5672\n",
      "      4        \u001b[36m0.3569\u001b[0m  24.5394\n",
      "      5        \u001b[36m0.3507\u001b[0m  24.5250\n",
      "      6        \u001b[36m0.3457\u001b[0m  24.5996\n",
      "      7        \u001b[36m0.3380\u001b[0m  24.5215\n",
      "      8        \u001b[36m0.3239\u001b[0m  24.5162\n",
      "      9        \u001b[36m0.3168\u001b[0m  24.5714\n",
      "     10        \u001b[36m0.3132\u001b[0m  24.5750\n",
      "     11        \u001b[36m0.2990\u001b[0m  24.6274\n",
      "     12        \u001b[36m0.2922\u001b[0m  24.5721\n",
      "     13        \u001b[36m0.2834\u001b[0m  24.5583\n",
      "     14        \u001b[36m0.2807\u001b[0m  24.5772\n",
      "     15        \u001b[36m0.2702\u001b[0m  24.5137\n",
      "     16        \u001b[36m0.2680\u001b[0m  24.4865\n",
      "     17        0.2753  24.4697\n",
      "     18        0.2818  24.4758\n",
      "     19        \u001b[36m0.2388\u001b[0m  24.4687\n",
      "     20        0.2556  24.4684\n",
      "     21        0.2396  24.3901\n",
      "     22        \u001b[36m0.2168\u001b[0m  24.4003\n",
      "     23        \u001b[36m0.1936\u001b[0m  24.4083\n",
      "     24        0.2041  24.4052\n",
      "     25        0.2162  24.4302\n",
      "     26        0.1973  24.4362\n",
      "     27        0.2027  24.3915\n",
      "     28        \u001b[36m0.1496\u001b[0m  24.4076\n",
      "     29        0.1698  24.3867\n",
      "     30        0.1769  24.4125\n",
      "     31        0.1620  24.4519\n",
      "     32        \u001b[36m0.1483\u001b[0m  24.4791\n",
      "     33        0.1913  24.4509\n",
      "     34        \u001b[36m0.1286\u001b[0m  24.4596\n",
      "     35        0.1379  24.4913\n",
      "     36        \u001b[36m0.0965\u001b[0m  24.4104\n",
      "     37        0.1152  24.3764\n",
      "     38        0.1084  24.3613\n",
      "     39        0.1135  24.3962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     40        \u001b[36m0.0946\u001b[0m  24.4318\n",
      "     41        \u001b[36m0.0771\u001b[0m  24.4090\n",
      "     42        0.0939  24.5788\n",
      "     43        0.1164  24.5691\n",
      "     44        \u001b[36m0.0715\u001b[0m  24.4227\n",
      "     45        0.0724  24.4685\n",
      "     46        0.0894  24.4315\n",
      "     47        0.0754  24.3967\n",
      "     48        0.1050  24.3630\n",
      "     49        0.0752  24.4037\n",
      "     50        0.0776  24.4392\n",
      "     51        \u001b[36m0.0614\u001b[0m  24.3744\n",
      "     52        \u001b[36m0.0566\u001b[0m  24.3717\n",
      "     53        0.0598  24.5759\n",
      "     54        0.0652  24.5348\n",
      "     55        0.0642  24.6275\n",
      "     56        \u001b[36m0.0517\u001b[0m  24.5869\n",
      "     57        0.0579  24.5890\n",
      "     58        0.0619  24.6888\n",
      "     59        0.0631  24.5351\n",
      "     60        0.0578  24.5637\n",
      "[CV 3/5] END batch_size=32, lr=0.001, max_epochs=60;, score=0.891 total time=24.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4249\u001b[0m  24.3763\n",
      "      2        \u001b[36m0.3756\u001b[0m  24.3969\n",
      "      3        0.3808  24.5325\n",
      "      4        \u001b[36m0.3648\u001b[0m  24.5009\n",
      "      5        \u001b[36m0.3494\u001b[0m  24.4728\n",
      "      6        \u001b[36m0.3442\u001b[0m  24.4831\n",
      "      7        \u001b[36m0.3330\u001b[0m  24.4998\n",
      "      8        \u001b[36m0.3094\u001b[0m  24.5261\n",
      "      9        0.3179  24.5067\n",
      "     10        0.3145  24.4957\n",
      "     11        \u001b[36m0.2951\u001b[0m  24.3975\n",
      "     12        \u001b[36m0.2851\u001b[0m  24.4249\n",
      "     13        \u001b[36m0.2769\u001b[0m  24.4725\n",
      "     14        0.2843  24.4172\n",
      "     15        \u001b[36m0.2436\u001b[0m  24.3494\n",
      "     16        0.2502  24.3479\n",
      "     17        \u001b[36m0.2235\u001b[0m  24.3266\n",
      "     18        0.2656  24.3359\n",
      "     19        0.2290  24.3271\n",
      "     20        \u001b[36m0.2079\u001b[0m  24.3407\n",
      "     21        \u001b[36m0.1865\u001b[0m  24.3284\n",
      "     22        0.1925  24.3075\n",
      "     23        0.1887  24.4063\n",
      "     24        \u001b[36m0.1506\u001b[0m  24.3242\n",
      "     25        \u001b[36m0.1500\u001b[0m  24.3264\n",
      "     26        0.1523  24.3219\n",
      "     27        0.1521  24.3504\n",
      "     28        \u001b[36m0.1128\u001b[0m  24.4881\n",
      "     29        0.1855  24.3963\n",
      "     30        0.1501  24.4097\n",
      "     31        0.1286  24.4089\n",
      "     32        \u001b[36m0.1000\u001b[0m  24.4113\n",
      "     33        \u001b[36m0.0857\u001b[0m  24.4463\n",
      "     34        0.1198  24.4392\n",
      "     35        0.1394  24.4260\n",
      "     36        0.1275  24.4008\n",
      "     37        0.1029  24.3660\n",
      "     38        \u001b[36m0.0729\u001b[0m  24.4156\n",
      "     39        \u001b[36m0.0577\u001b[0m  24.4029\n",
      "     40        0.0724  24.4102\n",
      "     41        0.1052  24.3927\n",
      "     42        0.0968  24.3634\n",
      "     43        0.0771  24.4345\n",
      "     44        0.0718  24.4085\n",
      "     45        \u001b[36m0.0564\u001b[0m  24.4095\n",
      "     46        0.1103  24.4139\n",
      "     47        0.0658  24.3836\n",
      "     48        \u001b[36m0.0506\u001b[0m  24.4597\n",
      "     49        0.0899  24.3916\n",
      "     50        0.0824  24.4077\n",
      "     51        0.0581  24.3944\n",
      "     52        0.0630  24.3955\n",
      "     53        \u001b[36m0.0470\u001b[0m  24.4364\n",
      "     54        0.0672  24.4105\n",
      "     55        \u001b[36m0.0416\u001b[0m  24.4252\n",
      "     56        0.0586  24.3914\n",
      "     57        0.0689  24.3908\n",
      "     58        0.0713  24.4825\n",
      "     59        \u001b[36m0.0311\u001b[0m  24.4055\n",
      "     60        0.0539  24.3940\n",
      "[CV 4/5] END batch_size=32, lr=0.001, max_epochs=60;, score=0.904 total time=24.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4356\u001b[0m  24.3054\n",
      "      2        \u001b[36m0.3604\u001b[0m  24.2605\n",
      "      3        0.3760  24.2725\n",
      "      4        \u001b[36m0.3571\u001b[0m  24.2911\n",
      "      5        \u001b[36m0.3542\u001b[0m  24.2683\n",
      "      6        \u001b[36m0.3451\u001b[0m  24.3016\n",
      "      7        \u001b[36m0.3441\u001b[0m  24.2416\n",
      "      8        \u001b[36m0.3119\u001b[0m  24.2833\n",
      "      9        0.3222  24.2620\n",
      "     10        \u001b[36m0.3059\u001b[0m  24.2896\n",
      "     11        \u001b[36m0.3058\u001b[0m  24.2934\n",
      "     12        \u001b[36m0.2939\u001b[0m  24.2431\n",
      "     13        \u001b[36m0.2656\u001b[0m  24.4395\n",
      "     14        0.2758  24.3882\n",
      "     15        \u001b[36m0.2284\u001b[0m  24.3532\n",
      "     16        0.2348  24.4145\n",
      "     17        0.2342  24.4035\n",
      "     18        \u001b[36m0.2135\u001b[0m  24.2905\n",
      "     19        0.2494  24.2548\n",
      "     20        \u001b[36m0.1963\u001b[0m  24.2693\n",
      "     21        0.2003  24.3287\n",
      "     22        \u001b[36m0.1767\u001b[0m  24.2250\n",
      "     23        \u001b[36m0.1531\u001b[0m  24.2256\n",
      "     24        \u001b[36m0.1476\u001b[0m  24.2785\n",
      "     25        \u001b[36m0.1384\u001b[0m  24.3105\n",
      "     26        \u001b[36m0.1147\u001b[0m  24.2821\n",
      "     27        0.1313  24.2537\n",
      "     28        0.1397  24.2447\n",
      "     29        0.1213  24.2742\n",
      "     30        0.1195  24.3193\n",
      "     31        \u001b[36m0.1011\u001b[0m  24.3943\n",
      "     32        0.1222  24.3540\n",
      "     33        0.1037  24.3328\n",
      "     34        \u001b[36m0.0872\u001b[0m  24.3372\n",
      "     35        \u001b[36m0.0823\u001b[0m  24.3161\n",
      "     36        \u001b[36m0.0684\u001b[0m  24.3110\n",
      "     37        0.0856  24.3020\n",
      "     38        0.0996  24.2699\n",
      "     39        0.0769  24.2813\n",
      "     40        0.0854  24.2787\n",
      "     41        0.1037  24.2976\n",
      "     42        0.0922  24.2908\n",
      "     43        \u001b[36m0.0629\u001b[0m  24.3102\n",
      "     44        \u001b[36m0.0457\u001b[0m  24.2280\n",
      "     45        0.0623  24.2232\n",
      "     46        0.0551  24.2895\n",
      "     47        0.0648  24.2518\n",
      "     48        0.0598  24.2162\n",
      "     49        0.0943  24.2137\n",
      "     50        0.0856  24.2619\n",
      "     51        0.0815  24.2629\n",
      "     52        0.0600  24.2425\n",
      "     53        0.0587  24.2579\n",
      "     54        \u001b[36m0.0447\u001b[0m  24.3298\n",
      "     55        0.0451  24.3172\n",
      "     56        0.0834  24.2871\n",
      "     57        0.0733  24.2660\n",
      "     58        0.0657  24.2551\n",
      "     59        0.0662  24.2777\n",
      "     60        0.0855  24.2228\n",
      "[CV 5/5] END batch_size=32, lr=0.001, max_epochs=60;, score=0.876 total time=24.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4179\u001b[0m  24.4017\n",
      "      2        \u001b[36m0.3547\u001b[0m  24.4283\n",
      "      3        \u001b[36m0.3503\u001b[0m  24.5050\n",
      "      4        0.3531  24.4772\n",
      "      5        \u001b[36m0.3335\u001b[0m  24.4419\n",
      "      6        \u001b[36m0.3259\u001b[0m  24.4142\n",
      "      7        0.3305  24.4117\n",
      "      8        \u001b[36m0.3121\u001b[0m  24.5191\n",
      "      9        0.3196  24.5629\n",
      "     10        \u001b[36m0.2973\u001b[0m  24.5073\n",
      "     11        \u001b[36m0.2706\u001b[0m  24.5165\n",
      "     12        \u001b[36m0.2582\u001b[0m  24.5221\n",
      "     13        \u001b[36m0.2518\u001b[0m  24.5223\n",
      "     14        0.2587  24.5063\n",
      "     15        0.2538  24.4822\n",
      "     16        \u001b[36m0.2381\u001b[0m  24.4178\n",
      "     17        \u001b[36m0.2086\u001b[0m  24.4255\n",
      "     18        \u001b[36m0.1999\u001b[0m  24.4740\n",
      "     19        \u001b[36m0.1663\u001b[0m  24.5124\n",
      "     20        0.1821  24.4843\n",
      "     21        \u001b[36m0.1597\u001b[0m  24.4692\n",
      "     22        0.1739  24.4747\n",
      "     23        \u001b[36m0.1555\u001b[0m  24.4896\n",
      "     24        \u001b[36m0.1302\u001b[0m  24.4865\n",
      "     25        0.1354  24.4762\n",
      "     26        0.1366  24.4253\n",
      "     27        \u001b[36m0.1058\u001b[0m  24.4210\n",
      "     28        0.1138  24.4029\n",
      "     29        0.1143  24.4725\n",
      "     30        0.1067  24.4179\n",
      "     31        0.1122  24.4170\n",
      "     32        \u001b[36m0.1015\u001b[0m  24.5273\n",
      "     33        0.1115  24.5698\n",
      "     34        0.1138  24.6179\n",
      "     35        \u001b[36m0.0804\u001b[0m  24.6062\n",
      "     36        0.1025  24.6290\n",
      "     37        0.1047  24.6075\n",
      "     38        \u001b[36m0.0659\u001b[0m  24.5910\n",
      "     39        0.0741  24.6252\n",
      "     40        \u001b[36m0.0643\u001b[0m  24.4424\n",
      "     41        0.0755  24.4099\n",
      "     42        \u001b[36m0.0566\u001b[0m  24.4018\n",
      "     43        0.0636  24.4364\n",
      "     44        0.0588  24.4537\n",
      "     45        0.0643  24.5089\n",
      "     46        0.0719  24.4757\n",
      "     47        0.0700  24.5238\n",
      "     48        0.0582  24.5070\n",
      "     49        \u001b[36m0.0545\u001b[0m  24.4736\n",
      "     50        0.0654  24.4573\n",
      "     51        \u001b[36m0.0535\u001b[0m  24.4717\n",
      "     52        \u001b[36m0.0533\u001b[0m  24.4950\n",
      "     53        \u001b[36m0.0366\u001b[0m  24.5468\n",
      "     54        0.0481  24.4730\n",
      "     55        0.0553  24.5232\n",
      "     56        0.0392  24.4909\n",
      "     57        \u001b[36m0.0268\u001b[0m  24.4647\n",
      "     58        0.0391  24.5380\n",
      "     59        0.0465  24.5027\n",
      "     60        0.0422  24.4778\n",
      "     61        0.0377  24.4878\n",
      "     62        0.0492  24.5057\n",
      "     63        0.0614  24.4936\n",
      "     64        0.0559  24.5035\n",
      "     65        0.0434  24.4826\n",
      "     66        0.0283  24.4946\n",
      "     67        0.0504  24.4858\n",
      "     68        0.0648  24.5186\n",
      "     69        0.0318  24.5095\n",
      "     70        \u001b[36m0.0247\u001b[0m  24.4549\n",
      "     71        0.0326  24.5323\n",
      "     72        0.0340  24.4845\n",
      "     73        \u001b[36m0.0141\u001b[0m  24.5084\n",
      "     74        0.0342  24.4869\n",
      "     75        0.0437  24.4621\n",
      "     76        0.0509  24.5049\n",
      "     77        0.0463  24.4683\n",
      "     78        0.0541  24.5335\n",
      "     79        0.0501  24.5112\n",
      "     80        0.0387  24.4672\n",
      "[CV 1/5] END batch_size=32, lr=0.001, max_epochs=80;, score=0.922 total time=33.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4140\u001b[0m  24.3918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.3815\u001b[0m  24.4917\n",
      "      3        \u001b[36m0.3645\u001b[0m  24.4245\n",
      "      4        \u001b[36m0.3436\u001b[0m  24.3990\n",
      "      5        0.3588  24.3847\n",
      "      6        \u001b[36m0.3430\u001b[0m  24.4441\n",
      "      7        \u001b[36m0.3289\u001b[0m  24.5225\n",
      "      8        \u001b[36m0.3084\u001b[0m  24.5173\n",
      "      9        0.3156  24.4668\n",
      "     10        \u001b[36m0.3074\u001b[0m  24.5761\n",
      "     11        \u001b[36m0.3013\u001b[0m  24.6610\n",
      "     12        \u001b[36m0.2940\u001b[0m  24.6357\n",
      "     13        \u001b[36m0.2852\u001b[0m  24.4232\n",
      "     14        \u001b[36m0.2747\u001b[0m  24.4540\n",
      "     15        \u001b[36m0.2694\u001b[0m  24.6003\n",
      "     16        \u001b[36m0.2507\u001b[0m  24.5605\n",
      "     17        \u001b[36m0.2397\u001b[0m  24.5112\n",
      "     18        0.2503  24.4275\n",
      "     19        \u001b[36m0.1968\u001b[0m  24.4649\n",
      "     20        0.2196  24.4359\n",
      "     21        0.1995  24.5185\n",
      "     22        \u001b[36m0.1784\u001b[0m  24.4827\n",
      "     23        0.1946  24.4488\n",
      "     24        \u001b[36m0.1770\u001b[0m  24.4534\n",
      "     25        \u001b[36m0.1741\u001b[0m  24.4368\n",
      "     26        \u001b[36m0.1714\u001b[0m  24.4916\n",
      "     27        \u001b[36m0.1523\u001b[0m  24.4750\n",
      "     28        \u001b[36m0.1342\u001b[0m  24.4782\n",
      "     29        0.1372  24.4543\n",
      "     30        \u001b[36m0.1329\u001b[0m  24.4360\n",
      "     31        \u001b[36m0.1236\u001b[0m  24.6222\n",
      "     32        \u001b[36m0.0910\u001b[0m  24.5892\n",
      "     33        0.1127  24.5773\n",
      "     34        0.0920  24.6567\n",
      "     35        0.1532  24.6482\n",
      "     36        0.0946  24.5076\n",
      "     37        \u001b[36m0.0810\u001b[0m  24.4097\n",
      "     38        0.0951  24.4704\n",
      "     39        0.1590  24.4274\n",
      "     40        0.1177  24.4176\n",
      "     41        0.0843  24.4809\n",
      "     42        0.1160  24.4285\n",
      "     43        \u001b[36m0.0735\u001b[0m  24.4266\n",
      "     44        \u001b[36m0.0546\u001b[0m  24.4521\n",
      "     45        0.1328  24.4550\n",
      "     46        0.1100  24.5024\n",
      "     47        0.0884  24.4326\n",
      "     48        0.0769  24.5652\n",
      "     49        0.0773  24.5969\n",
      "     50        0.0605  24.5698\n",
      "     51        0.0657  24.6359\n",
      "     52        0.0777  24.6099\n",
      "     53        0.0658  24.5761\n",
      "     54        0.0551  24.6030\n",
      "     55        0.0619  24.6376\n",
      "     56        0.0562  24.6339\n",
      "     57        \u001b[36m0.0424\u001b[0m  24.6067\n",
      "     58        0.0492  24.6276\n",
      "     59        0.0616  24.6002\n",
      "     60        0.0699  24.6741\n",
      "     61        0.0520  24.6265\n",
      "     62        0.0451  24.6186\n",
      "     63        \u001b[36m0.0400\u001b[0m  24.6174\n",
      "     64        0.0718  24.6465\n",
      "     65        0.0475  24.6703\n",
      "     66        0.0442  24.6091\n",
      "     67        0.0461  24.6170\n",
      "     68        \u001b[36m0.0268\u001b[0m  24.6290\n",
      "     69        0.0559  24.5704\n",
      "     70        0.0633  24.6535\n",
      "     71        0.0523  24.6266\n",
      "     72        0.0382  24.5843\n",
      "     73        0.0389  24.5028\n",
      "     74        0.0373  24.4796\n",
      "     75        0.0387  24.5242\n",
      "     76        0.0428  24.4911\n",
      "     77        0.0304  24.5414\n",
      "     78        \u001b[36m0.0234\u001b[0m  24.5245\n",
      "     79        0.0323  24.4806\n",
      "     80        0.0394  24.5186\n",
      "[CV 2/5] END batch_size=32, lr=0.001, max_epochs=80;, score=0.922 total time=33.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4408\u001b[0m  24.4331\n",
      "      2        \u001b[36m0.3699\u001b[0m  24.3879\n",
      "      3        \u001b[36m0.3677\u001b[0m  24.4094\n",
      "      4        \u001b[36m0.3534\u001b[0m  24.4289\n",
      "      5        0.3661  24.4042\n",
      "      6        \u001b[36m0.3406\u001b[0m  24.3892\n",
      "      7        \u001b[36m0.3289\u001b[0m  24.3502\n",
      "      8        \u001b[36m0.3193\u001b[0m  24.4333\n",
      "      9        0.3205  24.6330\n",
      "     10        \u001b[36m0.3077\u001b[0m  24.4273\n",
      "     11        0.3085  24.3880\n",
      "     12        \u001b[36m0.2899\u001b[0m  24.4163\n",
      "     13        \u001b[36m0.2638\u001b[0m  24.4325\n",
      "     14        0.2832  24.4456\n",
      "     15        0.2652  24.4211\n",
      "     16        \u001b[36m0.2493\u001b[0m  24.4245\n",
      "     17        \u001b[36m0.2281\u001b[0m  24.3831\n",
      "     18        0.2297  24.4185\n",
      "     19        0.2367  24.3729\n",
      "     20        \u001b[36m0.2091\u001b[0m  24.3606\n",
      "     21        \u001b[36m0.1888\u001b[0m  24.5390\n",
      "     22        0.1974  24.5482\n",
      "     23        \u001b[36m0.1828\u001b[0m  24.5903\n",
      "     24        \u001b[36m0.1827\u001b[0m  24.5051\n",
      "     25        \u001b[36m0.1626\u001b[0m  24.5380\n",
      "     26        0.1712  24.5095\n",
      "     27        \u001b[36m0.1601\u001b[0m  24.5233\n",
      "     28        0.1793  24.5859\n",
      "     29        \u001b[36m0.1520\u001b[0m  24.5120\n",
      "     30        \u001b[36m0.1127\u001b[0m  24.5028\n",
      "     31        \u001b[36m0.1009\u001b[0m  24.5317\n",
      "     32        0.1239  24.3811\n",
      "     33        0.1138  24.3989\n",
      "     34        0.1165  24.3623\n",
      "     35        0.1293  24.3698\n",
      "     36        \u001b[36m0.0957\u001b[0m  24.3723\n",
      "     37        0.0959  24.4084\n",
      "     38        0.0973  24.4194\n",
      "     39        \u001b[36m0.0687\u001b[0m  24.3453\n",
      "     40        0.0860  24.3512\n",
      "     41        0.1190  24.3402\n",
      "     42        0.1347  24.3367\n",
      "     43        0.0727  24.4537\n",
      "     44        0.0730  24.3468\n",
      "     45        0.0840  24.3839\n",
      "     46        \u001b[36m0.0643\u001b[0m  24.3844\n",
      "     47        0.0753  24.3781\n",
      "     48        \u001b[36m0.0595\u001b[0m  24.4449\n",
      "     49        0.0966  24.4161\n",
      "     50        0.0681  24.3605\n",
      "     51        0.0692  24.4474\n",
      "     52        0.0859  24.4727\n",
      "     53        0.0782  24.4975\n",
      "     54        \u001b[36m0.0573\u001b[0m  24.4316\n",
      "     55        \u001b[36m0.0350\u001b[0m  24.4731\n",
      "     56        0.0668  24.4560\n",
      "     57        0.0693  24.4717\n",
      "     58        0.0479  24.5235\n",
      "     59        \u001b[36m0.0346\u001b[0m  24.5554\n",
      "     60        0.0660  24.5449\n",
      "     61        0.0588  24.5543\n",
      "     62        0.0407  24.5339\n",
      "     63        0.0396  24.5952\n",
      "     64        0.0477  24.5793\n",
      "     65        0.0832  24.5715\n",
      "     66        0.0457  24.5623\n",
      "     67        0.0508  24.5841\n",
      "     68        \u001b[36m0.0337\u001b[0m  24.5737\n",
      "     69        \u001b[36m0.0310\u001b[0m  24.5602\n",
      "     70        0.0325  24.5324\n",
      "     71        0.0705  24.5461\n",
      "     72        0.0433  24.5996\n",
      "     73        0.0329  24.5487\n",
      "     74        0.0383  24.5591\n",
      "     75        0.0326  24.6005\n",
      "     76        0.0316  24.5313\n",
      "     77        0.0531  24.5747\n",
      "     78        0.0958  24.5683\n",
      "     79        0.0377  24.5627\n",
      "     80        0.0379  24.5155\n",
      "[CV 3/5] END batch_size=32, lr=0.001, max_epochs=80;, score=0.929 total time=33.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4218\u001b[0m  24.5016\n",
      "      2        \u001b[36m0.3777\u001b[0m  24.5216\n",
      "      3        \u001b[36m0.3650\u001b[0m  24.4715\n",
      "      4        \u001b[36m0.3453\u001b[0m  24.4590\n",
      "      5        0.3501  24.4978\n",
      "      6        0.3620  24.5965\n",
      "      7        0.3517  24.5245\n",
      "      8        \u001b[36m0.3278\u001b[0m  24.4551\n",
      "      9        \u001b[36m0.3201\u001b[0m  24.5019\n",
      "     10        0.3328  24.4931\n",
      "     11        \u001b[36m0.3151\u001b[0m  24.5059\n",
      "     12        \u001b[36m0.2891\u001b[0m  24.4485\n",
      "     13        \u001b[36m0.2750\u001b[0m  24.4968\n",
      "     14        \u001b[36m0.2542\u001b[0m  24.4750\n",
      "     15        0.2633  24.4490\n",
      "     16        \u001b[36m0.2469\u001b[0m  24.5126\n",
      "     17        \u001b[36m0.2394\u001b[0m  24.4506\n",
      "     18        \u001b[36m0.2355\u001b[0m  24.4662\n",
      "     19        \u001b[36m0.2046\u001b[0m  24.4080\n",
      "     20        0.2071  24.4121\n",
      "     21        \u001b[36m0.1841\u001b[0m  24.3721\n",
      "     22        0.2027  24.2899\n",
      "     23        \u001b[36m0.1498\u001b[0m  24.2983\n",
      "     24        0.1820  24.2743\n",
      "     25        \u001b[36m0.1425\u001b[0m  24.3099\n",
      "     26        0.1656  24.5815\n",
      "     27        \u001b[36m0.1226\u001b[0m  24.5042\n",
      "     28        0.1393  24.4957\n",
      "     29        0.1655  24.4944\n",
      "     30        0.1319  24.5217\n",
      "     31        \u001b[36m0.1103\u001b[0m  24.2962\n",
      "     32        \u001b[36m0.1048\u001b[0m  24.3180\n",
      "     33        \u001b[36m0.1044\u001b[0m  24.3588\n",
      "     34        \u001b[36m0.0986\u001b[0m  24.3997\n",
      "     35        \u001b[36m0.0967\u001b[0m  24.4285\n",
      "     36        0.1484  24.4105\n",
      "     37        \u001b[36m0.0942\u001b[0m  24.3946\n",
      "     38        0.0961  24.3933\n",
      "     39        0.1088  24.4681\n",
      "     40        \u001b[36m0.0740\u001b[0m  24.3853\n",
      "     41        \u001b[36m0.0644\u001b[0m  24.3609\n",
      "     42        0.0756  24.3872\n",
      "     43        0.0858  24.4704\n",
      "     44        \u001b[36m0.0500\u001b[0m  24.4052\n",
      "     45        0.0582  24.4517\n",
      "     46        0.0668  24.4171\n",
      "     47        0.0807  24.3653\n",
      "     48        0.0595  24.3933\n",
      "     49        \u001b[36m0.0477\u001b[0m  24.4427\n",
      "     50        0.0651  24.5027\n",
      "     51        0.0697  24.3911\n",
      "     52        \u001b[36m0.0464\u001b[0m  24.4110\n",
      "     53        0.0488  24.4240\n",
      "     54        0.0792  24.4065\n",
      "     55        0.0583  24.4448\n",
      "     56        \u001b[36m0.0396\u001b[0m  24.4269\n",
      "     57        0.0541  24.3751\n",
      "     58        0.0683  24.4250\n",
      "     59        0.0648  24.3907\n",
      "     60        0.0441  24.4824\n",
      "     61        0.0421  24.4415\n",
      "     62        0.0565  24.4095\n",
      "     63        0.0576  24.4182\n",
      "     64        0.0426  24.4394\n",
      "     65        0.0588  24.4391\n",
      "     66        0.0678  24.4551\n",
      "     67        0.0631  24.4861\n",
      "     68        0.0533  24.3898\n",
      "     69        \u001b[36m0.0392\u001b[0m  24.4033\n",
      "     70        \u001b[36m0.0315\u001b[0m  24.4387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     71        \u001b[36m0.0151\u001b[0m  24.3899\n",
      "     72        0.0203  24.3950\n",
      "     73        0.0304  24.3752\n",
      "     74        0.0373  24.3951\n",
      "     75        0.0173  24.5432\n",
      "     76        0.0287  24.4351\n",
      "     77        0.0308  24.4562\n",
      "     78        0.0938  24.4649\n",
      "     79        0.0426  24.4545\n",
      "     80        0.0305  24.4690\n",
      "[CV 4/5] END batch_size=32, lr=0.001, max_epochs=80;, score=0.922 total time=33.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4291\u001b[0m  24.3121\n",
      "      2        \u001b[36m0.3783\u001b[0m  24.3580\n",
      "      3        \u001b[36m0.3591\u001b[0m  24.3538\n",
      "      4        0.3662  24.3232\n",
      "      5        \u001b[36m0.3556\u001b[0m  24.3347\n",
      "      6        \u001b[36m0.3277\u001b[0m  24.3315\n",
      "      7        0.3421  24.3625\n",
      "      8        \u001b[36m0.3080\u001b[0m  24.3610\n",
      "      9        0.3147  24.3974\n",
      "     10        \u001b[36m0.2874\u001b[0m  24.3264\n",
      "     11        0.3064  24.3357\n",
      "     12        \u001b[36m0.2748\u001b[0m  24.3507\n",
      "     13        \u001b[36m0.2697\u001b[0m  24.4418\n",
      "     14        \u001b[36m0.2567\u001b[0m  24.3289\n",
      "     15        0.2725  24.3390\n",
      "     16        \u001b[36m0.2255\u001b[0m  24.3391\n",
      "     17        \u001b[36m0.2121\u001b[0m  24.3277\n",
      "     18        0.2174  24.3791\n",
      "     19        \u001b[36m0.1973\u001b[0m  24.3612\n",
      "     20        \u001b[36m0.1862\u001b[0m  24.3108\n",
      "     21        \u001b[36m0.1779\u001b[0m  24.3121\n",
      "     22        \u001b[36m0.1599\u001b[0m  24.3506\n",
      "     23        0.1833  24.3591\n",
      "     24        \u001b[36m0.1206\u001b[0m  24.3531\n",
      "     25        0.1324  24.3733\n",
      "     26        0.1252  24.4517\n",
      "     27        0.1609  24.4703\n",
      "     28        0.1417  24.4958\n",
      "     29        0.1573  24.4381\n",
      "     30        0.1796  24.4447\n",
      "     31        \u001b[36m0.1204\u001b[0m  24.4167\n",
      "     32        \u001b[36m0.1180\u001b[0m  24.4765\n",
      "     33        \u001b[36m0.1022\u001b[0m  24.4026\n",
      "     34        \u001b[36m0.0948\u001b[0m  24.3601\n",
      "     35        \u001b[36m0.0886\u001b[0m  24.3530\n",
      "     36        \u001b[36m0.0727\u001b[0m  24.3688\n",
      "     37        0.0855  24.3367\n",
      "     38        0.0820  24.3746\n",
      "     39        0.0850  24.3418\n",
      "     40        \u001b[36m0.0544\u001b[0m  24.3493\n",
      "     41        0.0605  24.3471\n",
      "     42        0.0979  24.3549\n",
      "     43        0.0719  24.3178\n",
      "     44        0.0820  24.2658\n",
      "     45        0.0673  24.3118\n",
      "     46        0.1044  24.2935\n",
      "     47        0.0683  24.2555\n",
      "     48        \u001b[36m0.0508\u001b[0m  24.3193\n",
      "     49        0.0549  24.2575\n",
      "     50        0.0596  24.2119\n",
      "     51        0.0580  24.3009\n",
      "     52        \u001b[36m0.0425\u001b[0m  24.2365\n",
      "     53        0.0470  24.2995\n",
      "     54        \u001b[36m0.0415\u001b[0m  24.2432\n",
      "     55        0.0556  24.2665\n",
      "     56        0.0565  24.2770\n",
      "     57        0.0690  24.3235\n",
      "     58        0.1301  24.3530\n",
      "     59        0.0703  24.2802\n",
      "     60        0.0642  24.3008\n",
      "     61        0.0559  24.3479\n",
      "     62        0.0605  24.3756\n",
      "     63        0.0528  24.3528\n",
      "     64        \u001b[36m0.0408\u001b[0m  24.3450\n",
      "     65        0.0807  24.3341\n",
      "     66        0.0631  24.3786\n",
      "     67        0.0654  24.3822\n",
      "     68        \u001b[36m0.0335\u001b[0m  24.3061\n",
      "     69        0.0949  24.3698\n",
      "     70        0.0524  24.4214\n",
      "     71        0.0458  24.4116\n",
      "     72        0.0400  24.4736\n",
      "     73        0.0353  24.4333\n",
      "     74        0.0659  24.4140\n",
      "     75        0.0477  24.4015\n",
      "     76        0.0356  24.4421\n",
      "     77        0.0814  24.4368\n",
      "     78        0.0387  24.3811\n",
      "     79        \u001b[36m0.0268\u001b[0m  24.4082\n",
      "     80        0.0333  24.4204\n",
      "[CV 5/5] END batch_size=32, lr=0.001, max_epochs=80;, score=0.898 total time=32.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5384\u001b[0m  24.5455\n",
      "      2        \u001b[36m0.4297\u001b[0m  24.4831\n",
      "      3        \u001b[36m0.3747\u001b[0m  24.5058\n",
      "      4        0.3893  24.5173\n",
      "      5        \u001b[36m0.3682\u001b[0m  24.5029\n",
      "      6        0.3896  24.6501\n",
      "      7        \u001b[36m0.3649\u001b[0m  24.6192\n",
      "      8        \u001b[36m0.3598\u001b[0m  24.6248\n",
      "      9        \u001b[36m0.3534\u001b[0m  24.6495\n",
      "     10        \u001b[36m0.3487\u001b[0m  24.6404\n",
      "     11        0.3739  24.7051\n",
      "     12        0.3639  24.8000\n",
      "     13        0.3691  24.6946\n",
      "     14        0.3679  24.6581\n",
      "     15        0.3489  24.6312\n",
      "     16        \u001b[36m0.3390\u001b[0m  24.6822\n",
      "     17        \u001b[36m0.3264\u001b[0m  24.6847\n",
      "     18        0.3330  24.6430\n",
      "     19        0.3309  24.6896\n",
      "     20        0.3355  24.7054\n",
      "     21        \u001b[36m0.3217\u001b[0m  24.7532\n",
      "     22        \u001b[36m0.2998\u001b[0m  24.7240\n",
      "     23        \u001b[36m0.2938\u001b[0m  24.7440\n",
      "     24        0.3131  24.6926\n",
      "     25        \u001b[36m0.2806\u001b[0m  24.7191\n",
      "     26        0.2831  24.6521\n",
      "     27        0.2915  24.6836\n",
      "     28        \u001b[36m0.2669\u001b[0m  24.6320\n",
      "     29        \u001b[36m0.2567\u001b[0m  24.6367\n",
      "     30        0.2692  24.7049\n",
      "     31        0.2678  24.6829\n",
      "     32        0.2767  24.6871\n",
      "     33        \u001b[36m0.2510\u001b[0m  24.6813\n",
      "     34        0.2680  24.8022\n",
      "     35        \u001b[36m0.2465\u001b[0m  24.8261\n",
      "     36        \u001b[36m0.2156\u001b[0m  24.8144\n",
      "     37        0.2172  24.7930\n",
      "     38        0.2292  24.8072\n",
      "     39        \u001b[36m0.1853\u001b[0m  24.8098\n",
      "     40        0.2197  24.8808\n",
      "[CV 1/5] END batch_size=32, lr=0.01, max_epochs=40;, score=0.854 total time=16.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5017\u001b[0m  24.6344\n",
      "      2        \u001b[36m0.4239\u001b[0m  24.6460\n",
      "      3        \u001b[36m0.3971\u001b[0m  24.4804\n",
      "      4        \u001b[36m0.3746\u001b[0m  24.5035\n",
      "      5        0.3969  24.4784\n",
      "      6        \u001b[36m0.3735\u001b[0m  24.4357\n",
      "      7        0.3778  24.5768\n",
      "      8        0.3758  24.5768\n",
      "      9        0.3798  24.6302\n",
      "     10        \u001b[36m0.3348\u001b[0m  24.5666\n",
      "     11        0.3381  24.6147\n",
      "     12        0.3387  24.5714\n",
      "     13        0.3397  24.5856\n",
      "     14        \u001b[36m0.3341\u001b[0m  24.6251\n",
      "     15        \u001b[36m0.3242\u001b[0m  24.6024\n",
      "     16        0.3464  24.5920\n",
      "     17        \u001b[36m0.3220\u001b[0m  24.6062\n",
      "     18        0.3340  24.6388\n",
      "     19        \u001b[36m0.3199\u001b[0m  24.6414\n",
      "     20        \u001b[36m0.3086\u001b[0m  24.5913\n",
      "     21        0.3347  24.6447\n",
      "     22        0.3338  24.5680\n",
      "     23        0.3102  24.5696\n",
      "     24        0.3212  24.6492\n",
      "     25        \u001b[36m0.3073\u001b[0m  24.7132\n",
      "     26        0.3142  24.7044\n",
      "     27        0.3183  24.7830\n",
      "     28        0.3101  24.8651\n",
      "     29        \u001b[36m0.2832\u001b[0m  24.8176\n",
      "     30        0.2991  24.8991\n",
      "     31        \u001b[36m0.2715\u001b[0m  24.8728\n",
      "     32        \u001b[36m0.2578\u001b[0m  24.9179\n",
      "     33        0.2899  25.1918\n",
      "     34        0.2724  25.2891\n",
      "     35        0.2686  25.3597\n",
      "     36        0.2634  25.2882\n",
      "     37        0.2824  25.3922\n",
      "     38        \u001b[36m0.2535\u001b[0m  25.4265\n",
      "     39        \u001b[36m0.2366\u001b[0m  25.3042\n",
      "     40        0.2431  25.4206\n",
      "[CV 2/5] END batch_size=32, lr=0.01, max_epochs=40;, score=0.876 total time=17.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5137\u001b[0m  24.4603\n",
      "      2        \u001b[36m0.4765\u001b[0m  24.4835\n",
      "      3        \u001b[36m0.3865\u001b[0m  24.4605\n",
      "      4        0.4111  24.4678\n",
      "      5        \u001b[36m0.3793\u001b[0m  24.4636\n",
      "      6        \u001b[36m0.3680\u001b[0m  24.4233\n",
      "      7        \u001b[36m0.3647\u001b[0m  24.3565\n",
      "      8        0.3821  24.3950\n",
      "      9        0.3698  24.4877\n",
      "     10        \u001b[36m0.3442\u001b[0m  24.5016\n",
      "     11        \u001b[36m0.3365\u001b[0m  24.5366\n",
      "     12        0.3522  24.5059\n",
      "     13        \u001b[36m0.3339\u001b[0m  24.7276\n",
      "     14        0.3515  25.4201\n",
      "     15        0.3572  24.4316\n",
      "     16        0.3380  24.4630\n",
      "     17        0.3379  24.3825\n",
      "     18        0.3499  24.4120\n",
      "     19        0.3452  24.3741\n",
      "     20        \u001b[36m0.3294\u001b[0m  24.4135\n",
      "     21        0.3418  24.6264\n",
      "     22        \u001b[36m0.3153\u001b[0m  24.4400\n",
      "     23        0.3234  24.5329\n",
      "     24        0.3369  24.8785\n",
      "     25        0.3342  24.6243\n",
      "     26        0.3294  24.4734\n",
      "     27        0.3180  24.4408\n",
      "     28        \u001b[36m0.2968\u001b[0m  24.4641\n",
      "     29        0.3048  24.4765\n",
      "     30        0.3154  24.6031\n",
      "     31        0.3058  24.6095\n",
      "     32        \u001b[36m0.2961\u001b[0m  24.5688\n",
      "     33        \u001b[36m0.2940\u001b[0m  24.5658\n",
      "     34        \u001b[36m0.2781\u001b[0m  24.5314\n",
      "     35        0.2846  24.5880\n",
      "     36        0.2829  24.6373\n",
      "     37        0.2803  24.5839\n",
      "     38        0.2847  24.6608\n",
      "     39        0.2799  24.5571\n",
      "     40        \u001b[36m0.2754\u001b[0m  24.6084\n",
      "[CV 3/5] END batch_size=32, lr=0.01, max_epochs=40;, score=0.848 total time=16.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5120\u001b[0m  24.4663\n",
      "      2        \u001b[36m0.4009\u001b[0m  24.5168\n",
      "      3        0.4032  24.6427\n",
      "      4        \u001b[36m0.3851\u001b[0m  24.5150\n",
      "      5        \u001b[36m0.3574\u001b[0m  24.4555\n",
      "      6        0.4054  25.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.3459\u001b[0m  24.8667\n",
      "      8        0.3530  24.9118\n",
      "      9        0.3481  24.3997\n",
      "     10        0.3467  24.3560\n",
      "     11        0.3492  24.6350\n",
      "     12        \u001b[36m0.3318\u001b[0m  24.6106\n",
      "     13        0.3407  24.4081\n",
      "     14        0.3392  24.5098\n",
      "     15        \u001b[36m0.3154\u001b[0m  24.5138\n",
      "     16        0.3257  24.6195\n",
      "     17        0.3281  24.4913\n",
      "     18        \u001b[36m0.3049\u001b[0m  24.5690\n",
      "     19        0.3270  24.7352\n",
      "     20        0.3196  24.4630\n",
      "     21        \u001b[36m0.2971\u001b[0m  24.4618\n",
      "     22        \u001b[36m0.2877\u001b[0m  24.4495\n",
      "     23        0.3024  24.4088\n",
      "     24        0.3004  24.4948\n",
      "     25        \u001b[36m0.2837\u001b[0m  24.3857\n",
      "     26        \u001b[36m0.2681\u001b[0m  24.7412\n",
      "     27        \u001b[36m0.2635\u001b[0m  25.0711\n",
      "     28        0.2689  24.5551\n",
      "     29        0.2855  24.5505\n",
      "     30        \u001b[36m0.2564\u001b[0m  24.5479\n",
      "     31        0.2943  24.5221\n",
      "     32        0.2672  24.6259\n",
      "     33        \u001b[36m0.2520\u001b[0m  24.5280\n",
      "     34        0.2887  24.5583\n",
      "     35        \u001b[36m0.2254\u001b[0m  24.4172\n",
      "     36        0.2353  24.4218\n",
      "     37        0.2277  24.4031\n",
      "     38        \u001b[36m0.1952\u001b[0m  24.3792\n",
      "     39        \u001b[36m0.1844\u001b[0m  24.4330\n",
      "     40        0.2254  24.4566\n",
      "[CV 4/5] END batch_size=32, lr=0.01, max_epochs=40;, score=0.891 total time=16.8min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.6080\u001b[0m  24.2085\n",
      "      2        \u001b[36m0.4125\u001b[0m  24.2032\n",
      "      3        \u001b[36m0.3721\u001b[0m  24.2066\n",
      "      4        0.3834  24.2162\n",
      "      5        \u001b[36m0.3717\u001b[0m  24.2381\n",
      "      6        0.3843  24.2094\n",
      "      7        \u001b[36m0.3614\u001b[0m  24.2429\n",
      "      8        \u001b[36m0.3570\u001b[0m  24.1810\n",
      "      9        \u001b[36m0.3444\u001b[0m  24.1516\n",
      "     10        0.3781  24.2197\n",
      "     11        0.3536  24.2303\n",
      "     12        0.3513  24.2236\n",
      "     13        0.3685  24.2125\n",
      "     14        0.3583  24.1985\n",
      "     15        \u001b[36m0.3353\u001b[0m  24.2731\n",
      "     16        0.3372  24.2747\n",
      "     17        0.3415  24.2735\n",
      "     18        0.3362  24.2381\n",
      "     19        \u001b[36m0.3233\u001b[0m  24.2579\n",
      "     20        0.3514  24.2477\n",
      "     21        \u001b[36m0.3124\u001b[0m  24.2660\n",
      "     22        0.3320  24.2980\n",
      "     23        \u001b[36m0.3026\u001b[0m  24.3251\n",
      "     24        \u001b[36m0.2906\u001b[0m  24.2739\n",
      "     25        0.3242  24.3561\n",
      "     26        0.3337  24.3736\n",
      "     27        0.3016  24.4097\n",
      "     28        \u001b[36m0.2769\u001b[0m  24.4335\n",
      "     29        0.2839  24.4325\n",
      "     30        0.3074  24.4343\n",
      "     31        \u001b[36m0.2569\u001b[0m  24.4110\n",
      "     32        0.2715  24.4853\n",
      "     33        0.2659  24.4990\n",
      "     34        0.2620  24.4122\n",
      "     35        0.2812  24.4043\n",
      "     36        0.2601  24.4314\n",
      "     37        0.2581  24.4099\n",
      "     38        0.2645  24.6519\n",
      "     39        \u001b[36m0.2446\u001b[0m  26.1128\n",
      "     40        \u001b[36m0.2290\u001b[0m  24.7467\n",
      "[CV 5/5] END batch_size=32, lr=0.01, max_epochs=40;, score=0.866 total time=16.7min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5051\u001b[0m  24.5474\n",
      "      2        \u001b[36m0.4150\u001b[0m  24.5443\n",
      "      3        \u001b[36m0.3805\u001b[0m  24.5436\n",
      "      4        0.3890  24.4653\n",
      "      5        \u001b[36m0.3711\u001b[0m  24.4401\n",
      "      6        0.3823  24.5896\n",
      "      7        \u001b[36m0.3557\u001b[0m  24.5938\n",
      "      8        0.3630  24.5532\n",
      "      9        0.3943  24.5019\n",
      "     10        0.3624  24.6267\n",
      "     11        0.3650  24.6841\n",
      "     12        \u001b[36m0.3450\u001b[0m  24.7120\n",
      "     13        \u001b[36m0.3271\u001b[0m  24.6588\n",
      "     14        0.3339  24.6641\n",
      "     15        0.3343  25.7810\n",
      "     16        0.3437  24.8863\n",
      "     17        0.3372  24.9595\n",
      "     18        0.3321  24.6892\n",
      "     19        0.3423  24.6505\n",
      "     20        \u001b[36m0.3092\u001b[0m  24.7076\n",
      "     21        0.3239  24.6421\n",
      "     22        0.3277  24.6503\n",
      "     23        0.3225  24.6886\n",
      "     24        \u001b[36m0.3041\u001b[0m  24.6885\n",
      "     25        0.3157  24.7192\n",
      "     26        \u001b[36m0.2980\u001b[0m  24.6379\n",
      "     27        \u001b[36m0.2691\u001b[0m  24.6370\n",
      "     28        0.2920  24.6399\n",
      "     29        0.3189  24.6606\n",
      "     30        0.2804  24.7126\n",
      "     31        \u001b[36m0.2578\u001b[0m  24.6236\n",
      "     32        0.2734  24.6324\n",
      "     33        0.2655  24.6369\n",
      "     34        \u001b[36m0.2433\u001b[0m  24.6633\n",
      "     35        0.2489  24.6670\n",
      "     36        \u001b[36m0.2300\u001b[0m  24.7005\n",
      "     37        0.2355  24.8159\n",
      "     38        0.2545  24.8135\n",
      "     39        0.2357  24.8756\n",
      "     40        \u001b[36m0.2096\u001b[0m  24.8157\n",
      "     41        \u001b[36m0.1754\u001b[0m  24.8669\n",
      "     42        0.1952  24.8732\n",
      "     43        \u001b[36m0.1580\u001b[0m  24.8557\n",
      "     44        0.1803  24.8177\n",
      "     45        0.1913  24.9004\n",
      "     46        0.1607  24.9078\n",
      "     47        \u001b[36m0.1538\u001b[0m  24.9133\n",
      "     48        \u001b[36m0.1371\u001b[0m  24.9201\n",
      "     49        0.1563  24.9512\n",
      "     50        0.1720  24.9128\n",
      "     51        \u001b[36m0.1319\u001b[0m  24.9042\n",
      "     52        0.1667  24.7347\n",
      "     53        0.1355  24.6970\n",
      "     54        \u001b[36m0.1306\u001b[0m  24.8218\n",
      "     55        \u001b[36m0.1305\u001b[0m  24.9116\n",
      "     56        0.1549  24.9648\n",
      "     57        \u001b[36m0.1084\u001b[0m  25.0253\n",
      "     58        0.1142  24.9362\n",
      "     59        \u001b[36m0.1066\u001b[0m  24.9500\n",
      "     60        0.1544  24.9273\n",
      "[CV 1/5] END batch_size=32, lr=0.01, max_epochs=60;, score=0.901 total time=25.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5052\u001b[0m  24.5636\n",
      "      2        \u001b[36m0.4112\u001b[0m  24.6289\n",
      "      3        0.4126  24.4172\n",
      "      4        \u001b[36m0.3869\u001b[0m  24.4662\n",
      "      5        0.3882  24.4134\n",
      "      6        \u001b[36m0.3727\u001b[0m  24.4524\n",
      "      7        \u001b[36m0.3620\u001b[0m  24.4786\n",
      "      8        \u001b[36m0.3466\u001b[0m  24.4319\n",
      "      9        0.3602  24.4640\n",
      "     10        0.3596  24.4302\n",
      "     11        0.3477  24.5083\n",
      "     12        0.3524  24.5057\n",
      "     13        \u001b[36m0.3412\u001b[0m  24.4751\n",
      "     14        \u001b[36m0.3360\u001b[0m  24.4443\n",
      "     15        0.3435  24.4304\n",
      "     16        \u001b[36m0.3187\u001b[0m  24.4869\n",
      "     17        0.3284  24.6552\n",
      "     18        \u001b[36m0.3140\u001b[0m  24.5731\n",
      "     19        \u001b[36m0.2989\u001b[0m  24.5759\n",
      "     20        0.3282  24.5554\n",
      "     21        0.3120  24.5664\n",
      "     22        \u001b[36m0.2883\u001b[0m  24.5514\n",
      "     23        0.2980  24.5755\n",
      "     24        0.2933  24.6089\n",
      "     25        \u001b[36m0.2788\u001b[0m  24.8740\n",
      "     26        0.2814  25.0410\n",
      "     27        \u001b[36m0.2674\u001b[0m  24.8223\n",
      "     28        0.2898  24.8100\n",
      "     29        \u001b[36m0.2536\u001b[0m  24.7870\n",
      "     30        0.2800  24.8864\n",
      "     31        \u001b[36m0.2417\u001b[0m  24.8930\n",
      "     32        0.2683  24.9289\n",
      "     33        \u001b[36m0.2356\u001b[0m  25.0199\n",
      "     34        0.2759  25.1424\n",
      "     35        \u001b[36m0.2246\u001b[0m  25.1758\n",
      "     36        0.2534  25.1848\n",
      "     37        \u001b[36m0.2157\u001b[0m  25.2388\n",
      "     38        \u001b[36m0.1990\u001b[0m  25.1674\n",
      "     39        \u001b[36m0.1884\u001b[0m  25.1149\n",
      "     40        \u001b[36m0.1700\u001b[0m  25.0730\n",
      "     41        0.1836  24.9982\n",
      "     42        0.1806  24.8701\n",
      "     43        0.1859  24.8599\n",
      "     44        0.1770  24.8694\n",
      "     45        \u001b[36m0.1646\u001b[0m  24.8724\n",
      "     46        \u001b[36m0.1540\u001b[0m  24.9072\n",
      "     47        0.1594  24.8231\n",
      "     48        0.1615  24.8471\n",
      "     49        0.1771  24.8786\n",
      "     50        \u001b[36m0.1536\u001b[0m  24.9684\n",
      "     51        \u001b[36m0.1218\u001b[0m  24.9614\n",
      "     52        \u001b[36m0.1132\u001b[0m  25.0811\n",
      "     53        0.1182  25.1271\n",
      "     54        0.1496  25.0655\n",
      "     55        0.1262  25.1078\n",
      "     56        0.1341  25.0869\n",
      "     57        0.1471  25.1034\n",
      "     58        0.1176  25.2026\n",
      "     59        0.1268  25.0909\n",
      "     60        \u001b[36m0.0849\u001b[0m  25.1326\n",
      "[CV 2/5] END batch_size=32, lr=0.01, max_epochs=60;, score=0.919 total time=25.3min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5092\u001b[0m  24.6075\n",
      "      2        \u001b[36m0.3980\u001b[0m  24.6040\n",
      "      3        \u001b[36m0.3815\u001b[0m  24.6215\n",
      "      4        0.3856  24.4746\n",
      "      5        \u001b[36m0.3678\u001b[0m  24.4615\n",
      "      6        0.3912  24.5113\n",
      "      7        0.3791  24.4509\n",
      "      8        \u001b[36m0.3588\u001b[0m  24.4643\n",
      "      9        \u001b[36m0.3482\u001b[0m  24.5072\n",
      "     10        0.3612  24.4997\n",
      "     11        0.3507  24.5592\n",
      "     12        0.3581  24.5024\n",
      "     13        \u001b[36m0.3469\u001b[0m  24.4788\n",
      "     14        \u001b[36m0.3412\u001b[0m  24.4884\n",
      "     15        \u001b[36m0.3328\u001b[0m  24.5387\n",
      "     16        0.3423  24.5709\n",
      "     17        \u001b[36m0.3285\u001b[0m  25.1205\n",
      "     18        \u001b[36m0.3227\u001b[0m  24.5162\n",
      "     19        \u001b[36m0.3226\u001b[0m  24.4841\n",
      "     20        0.3306  24.5002\n",
      "     21        \u001b[36m0.3176\u001b[0m  24.5408\n",
      "     22        \u001b[36m0.3058\u001b[0m  24.5322\n",
      "     23        0.3300  24.6030\n",
      "     24        0.3060  24.5947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        0.3245  24.6228\n",
      "     26        \u001b[36m0.2993\u001b[0m  24.6717\n",
      "     27        \u001b[36m0.2849\u001b[0m  24.6423\n",
      "     28        0.3052  24.5899\n",
      "     29        \u001b[36m0.2832\u001b[0m  24.6578\n",
      "     30        \u001b[36m0.2758\u001b[0m  24.7459\n",
      "     31        \u001b[36m0.2746\u001b[0m  24.6964\n",
      "     32        \u001b[36m0.2625\u001b[0m  24.7088\n",
      "     33        0.2664  24.8085\n",
      "     34        \u001b[36m0.2593\u001b[0m  25.5325\n",
      "     35        0.2596  24.8789\n",
      "     36        \u001b[36m0.2433\u001b[0m  24.6696\n",
      "     37        0.2542  24.7311\n",
      "     38        0.2663  24.7865\n",
      "     39        \u001b[36m0.2351\u001b[0m  24.6729\n",
      "     40        \u001b[36m0.2155\u001b[0m  24.7235\n",
      "     41        \u001b[36m0.1783\u001b[0m  24.6050\n",
      "     42        0.2147  24.6182\n",
      "     43        0.2060  24.6370\n",
      "     44        0.2160  24.6841\n",
      "     45        0.1817  24.8427\n",
      "     46        0.1981  24.8857\n",
      "     47        0.1982  24.8529\n",
      "     48        \u001b[36m0.1571\u001b[0m  24.9200\n",
      "     49        0.1884  25.3480\n",
      "     50        0.1710  24.8832\n",
      "     51        0.1688  24.8785\n",
      "     52        0.1826  24.9565\n",
      "     53        0.1845  25.1085\n",
      "     54        0.1690  24.9054\n",
      "     55        \u001b[36m0.1519\u001b[0m  24.9427\n",
      "     56        0.1588  24.9265\n",
      "     57        \u001b[36m0.1403\u001b[0m  24.8350\n",
      "     58        \u001b[36m0.1324\u001b[0m  24.8919\n",
      "     59        0.1464  24.8613\n",
      "     60        \u001b[36m0.0985\u001b[0m  24.8545\n",
      "[CV 3/5] END batch_size=32, lr=0.01, max_epochs=60;, score=0.904 total time=25.2min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5358\u001b[0m  24.3199\n",
      "      2        \u001b[36m0.4283\u001b[0m  24.3362\n",
      "      3        \u001b[36m0.4193\u001b[0m  24.6384\n",
      "      4        \u001b[36m0.3888\u001b[0m  24.3658\n",
      "      5        \u001b[36m0.3734\u001b[0m  24.3663\n",
      "      6        0.3758  24.3843\n",
      "      7        0.3745  24.2970\n",
      "      8        \u001b[36m0.3574\u001b[0m  24.3718\n",
      "      9        0.3986  24.3368\n",
      "     10        0.3657  24.4688\n",
      "     11        0.3693  24.5348\n",
      "     12        0.3577  24.4896\n",
      "     13        \u001b[36m0.3317\u001b[0m  24.4237\n",
      "     14        0.3466  24.5423\n",
      "     15        0.3370  24.4839\n",
      "     16        0.3548  24.4882\n",
      "     17        0.3440  24.4411\n",
      "     18        0.3479  24.4579\n",
      "     19        \u001b[36m0.3303\u001b[0m  24.4652\n",
      "     20        \u001b[36m0.3266\u001b[0m  24.4602\n",
      "     21        \u001b[36m0.3251\u001b[0m  24.4660\n",
      "     22        0.3316  24.5076\n",
      "     23        \u001b[36m0.3075\u001b[0m  24.4755\n",
      "     24        \u001b[36m0.3071\u001b[0m  24.4886\n",
      "     25        0.3116  24.3948\n",
      "     26        0.3195  24.4365\n",
      "     27        \u001b[36m0.3017\u001b[0m  24.4046\n",
      "     28        0.3036  24.4452\n",
      "     29        0.3105  24.3962\n",
      "     30        0.3055  24.4261\n",
      "     31        \u001b[36m0.2896\u001b[0m  24.4608\n",
      "     32        \u001b[36m0.2791\u001b[0m  24.5104\n",
      "     33        0.2800  24.6336\n",
      "     34        \u001b[36m0.2684\u001b[0m  24.8523\n",
      "     35        \u001b[36m0.2650\u001b[0m  24.6426\n",
      "     36        0.2805  24.6825\n",
      "     37        \u001b[36m0.2628\u001b[0m  24.6342\n",
      "     38        0.2669  24.6290\n",
      "     39        \u001b[36m0.2428\u001b[0m  24.6229\n",
      "     40        0.2444  24.6314\n",
      "     41        0.2579  24.6968\n",
      "     42        \u001b[36m0.2373\u001b[0m  24.8464\n",
      "     43        \u001b[36m0.2194\u001b[0m  24.7976\n",
      "     44        0.2424  24.8082\n",
      "     45        0.2256  24.7875\n",
      "     46        0.2301  24.7864\n",
      "     47        \u001b[36m0.2102\u001b[0m  25.1149\n",
      "     48        \u001b[36m0.1967\u001b[0m  24.8048\n",
      "     49        \u001b[36m0.1895\u001b[0m  24.8075\n",
      "     50        0.2036  24.8921\n",
      "     51        \u001b[36m0.1841\u001b[0m  24.8413\n",
      "     52        0.1953  24.8414\n",
      "     53        \u001b[36m0.1810\u001b[0m  24.7861\n",
      "     54        \u001b[36m0.1531\u001b[0m  24.8335\n",
      "     55        0.2137  24.8316\n",
      "     56        0.1675  24.8147\n",
      "     57        0.1824  24.8419\n",
      "     58        0.1723  24.7382\n",
      "     59        \u001b[36m0.1446\u001b[0m  24.7103\n",
      "     60        0.1662  24.7307\n",
      "[CV 4/5] END batch_size=32, lr=0.01, max_epochs=60;, score=0.898 total time=25.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5013\u001b[0m  24.3029\n",
      "      2        \u001b[36m0.4453\u001b[0m  24.3275\n",
      "      3        \u001b[36m0.3940\u001b[0m  24.7270\n",
      "      4        0.4053  25.1313\n",
      "      5        \u001b[36m0.3882\u001b[0m  25.6009\n",
      "      6        \u001b[36m0.3839\u001b[0m  26.3795\n",
      "      7        \u001b[36m0.3674\u001b[0m  25.0670\n",
      "      8        0.3681  24.7417\n",
      "      9        \u001b[36m0.3457\u001b[0m  25.2413\n",
      "     10        0.3759  25.1765\n",
      "     11        0.3662  25.7457\n",
      "     12        0.3511  24.3420\n",
      "     13        0.3473  24.2728\n",
      "     14        \u001b[36m0.3353\u001b[0m  24.5587\n",
      "     15        0.3354  24.5894\n",
      "     16        0.3398  24.4019\n",
      "     17        0.3431  24.2384\n",
      "     18        0.3438  24.2657\n",
      "     19        \u001b[36m0.3158\u001b[0m  24.2273\n",
      "     20        \u001b[36m0.3122\u001b[0m  24.2812\n",
      "     21        0.3188  24.2335\n",
      "     22        \u001b[36m0.3081\u001b[0m  24.2012\n",
      "     23        \u001b[36m0.3050\u001b[0m  24.2808\n",
      "     24        0.3126  24.2796\n",
      "     25        \u001b[36m0.2903\u001b[0m  24.3006\n",
      "     26        \u001b[36m0.2890\u001b[0m  24.2724\n",
      "     27        \u001b[36m0.2709\u001b[0m  24.3194\n",
      "     28        0.2737  24.3189\n",
      "     29        0.2971  24.3853\n",
      "     30        \u001b[36m0.2666\u001b[0m  24.3532\n",
      "     31        \u001b[36m0.2640\u001b[0m  24.4570\n",
      "     32        \u001b[36m0.2620\u001b[0m  24.4914\n",
      "     33        0.2743  24.4251\n",
      "     34        0.2714  24.4907\n",
      "     35        \u001b[36m0.2545\u001b[0m  24.5127\n",
      "     36        \u001b[36m0.2371\u001b[0m  24.4328\n",
      "     37        0.2549  24.3568\n",
      "     38        \u001b[36m0.2322\u001b[0m  24.3506\n",
      "     39        0.2418  24.3774\n",
      "     40        \u001b[36m0.1934\u001b[0m  24.4142\n",
      "     41        0.2143  24.4100\n",
      "     42        0.2047  24.3984\n",
      "     43        \u001b[36m0.1923\u001b[0m  24.3351\n",
      "     44        \u001b[36m0.1672\u001b[0m  24.2844\n",
      "     45        0.1716  24.3319\n",
      "     46        0.1879  24.3462\n",
      "     47        \u001b[36m0.1588\u001b[0m  24.3404\n",
      "     48        0.1789  24.3831\n",
      "     49        0.2070  24.3421\n",
      "     50        0.1631  24.3379\n",
      "     51        \u001b[36m0.1354\u001b[0m  24.3548\n",
      "     52        0.1858  24.3466\n",
      "     53        0.1532  24.4008\n",
      "     54        \u001b[36m0.1145\u001b[0m  24.4229\n",
      "     55        0.1350  24.5750\n",
      "     56        0.1521  24.3504\n",
      "     57        0.1435  24.3996\n",
      "     58        0.1388  24.4078\n",
      "     59        0.1205  24.4092\n",
      "     60        0.1694  24.3805\n",
      "[CV 5/5] END batch_size=32, lr=0.01, max_epochs=60;, score=0.907 total time=25.0min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5735\u001b[0m  24.5040\n",
      "      2        \u001b[36m0.3885\u001b[0m  24.4965\n",
      "      3        \u001b[36m0.3811\u001b[0m  24.4660\n",
      "      4        \u001b[36m0.3699\u001b[0m  24.4132\n",
      "      5        0.3982  24.4244\n",
      "      6        0.3815  24.4436\n",
      "      7        \u001b[36m0.3593\u001b[0m  24.4488\n",
      "      8        \u001b[36m0.3585\u001b[0m  24.4352\n",
      "      9        \u001b[36m0.3416\u001b[0m  24.4237\n",
      "     10        0.3611  24.4427\n",
      "     11        0.3524  24.4800\n",
      "     12        0.3493  24.5356\n",
      "     13        \u001b[36m0.3359\u001b[0m  24.4678\n",
      "     14        0.3499  24.4416\n",
      "     15        \u001b[36m0.3178\u001b[0m  24.4455\n",
      "     16        0.3327  24.4960\n",
      "     17        0.3311  24.5060\n",
      "     18        0.3203  24.5474\n",
      "     19        0.3271  24.7835\n",
      "     20        0.3222  26.2445\n",
      "     21        \u001b[36m0.3161\u001b[0m  25.3779\n",
      "     22        \u001b[36m0.3145\u001b[0m  25.3971\n",
      "     23        \u001b[36m0.3145\u001b[0m  24.7154\n",
      "     24        \u001b[36m0.3090\u001b[0m  24.7155\n",
      "     25        0.3146  24.6585\n",
      "     26        0.3291  24.6599\n",
      "     27        \u001b[36m0.3057\u001b[0m  24.7037\n",
      "     28        0.3058  24.6771\n",
      "     29        \u001b[36m0.3051\u001b[0m  24.6934\n",
      "     30        \u001b[36m0.3011\u001b[0m  24.7321\n",
      "     31        \u001b[36m0.2764\u001b[0m  24.7110\n",
      "     32        \u001b[36m0.2694\u001b[0m  24.7194\n",
      "     33        0.2911  24.7069\n",
      "     34        0.3127  24.7818\n",
      "     35        \u001b[36m0.2556\u001b[0m  24.7908\n",
      "     36        \u001b[36m0.2489\u001b[0m  24.8092\n",
      "     37        \u001b[36m0.2346\u001b[0m  24.7598\n",
      "     38        0.2439  24.7258\n",
      "     39        0.2382  24.8759\n",
      "     40        \u001b[36m0.2083\u001b[0m  24.8753\n",
      "     41        0.2126  24.8703\n",
      "     42        \u001b[36m0.1941\u001b[0m  24.9885\n",
      "     43        0.2222  24.9666\n",
      "     44        0.2079  24.9343\n",
      "     45        \u001b[36m0.1878\u001b[0m  24.8930\n",
      "     46        0.2074  24.9498\n",
      "     47        0.2000  24.9508\n",
      "     48        \u001b[36m0.1680\u001b[0m  24.9451\n",
      "     49        0.1728  24.9437\n",
      "     50        0.1936  25.0148\n",
      "     51        \u001b[36m0.1657\u001b[0m  25.0204\n",
      "     52        \u001b[36m0.1467\u001b[0m  25.0077\n",
      "     53        \u001b[36m0.1452\u001b[0m  24.9329\n",
      "     54        0.1757  25.1291\n",
      "     55        0.1917  25.1505\n",
      "     56        0.1874  25.1765\n",
      "     57        0.1530  25.0665\n",
      "     58        0.1573  25.2963\n",
      "     59        \u001b[36m0.1177\u001b[0m  26.0089\n",
      "     60        0.1567  25.5321\n",
      "     61        0.1356  26.4586\n",
      "     62        \u001b[36m0.1106\u001b[0m  25.6646\n",
      "     63        \u001b[36m0.1033\u001b[0m  26.9967\n",
      "     64        0.1229  29.0896\n",
      "     65        0.1377  28.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     66        0.1140  25.1405\n",
      "     67        0.1222  25.5777\n",
      "     68        0.1174  25.4661\n",
      "     69        \u001b[36m0.0808\u001b[0m  27.0345\n",
      "     70        0.0819  25.6902\n",
      "     71        0.0927  25.6145\n",
      "     72        0.1342  26.0949\n",
      "     73        0.0899  26.6405\n",
      "     74        0.0958  30.2725\n",
      "     75        0.0942  25.5012\n",
      "     76        \u001b[36m0.0677\u001b[0m  25.5670\n",
      "     77        \u001b[36m0.0505\u001b[0m  25.5173\n",
      "     78        0.0555  25.0609\n",
      "     79        0.0660  25.1993\n",
      "     80        0.0797  25.3443\n",
      "[CV 1/5] END batch_size=32, lr=0.01, max_epochs=80;, score=0.870 total time=34.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5564\u001b[0m  24.7396\n",
      "      2        \u001b[36m0.4232\u001b[0m  24.7993\n",
      "      3        \u001b[36m0.3848\u001b[0m  24.7371\n",
      "      4        0.3960  25.0821\n",
      "      5        \u001b[36m0.3691\u001b[0m  24.7458\n",
      "      6        0.3790  25.0053\n",
      "      7        \u001b[36m0.3579\u001b[0m  24.7587\n",
      "      8        0.3740  25.1358\n",
      "      9        0.3638  25.2398\n",
      "     10        \u001b[36m0.3426\u001b[0m  25.0156\n",
      "     11        0.3536  24.8592\n",
      "     12        0.3542  24.8137\n",
      "     13        \u001b[36m0.3404\u001b[0m  24.5592\n",
      "     14        0.3453  24.8267\n",
      "     15        \u001b[36m0.3385\u001b[0m  24.7421\n",
      "     16        \u001b[36m0.3332\u001b[0m  25.6505\n",
      "     17        \u001b[36m0.3237\u001b[0m  24.9521\n",
      "     18        0.3290  24.8015\n",
      "     19        \u001b[36m0.3165\u001b[0m  24.6448\n",
      "     20        0.3328  24.9808\n",
      "     21        0.3221  24.7605\n",
      "     22        \u001b[36m0.3084\u001b[0m  24.5602\n",
      "     23        0.3123  25.1787\n",
      "     24        0.3213  25.1267\n",
      "     25        \u001b[36m0.2951\u001b[0m  24.8145\n",
      "     26        0.3176  25.4194\n",
      "     27        0.3001  25.2112\n",
      "     28        \u001b[36m0.2931\u001b[0m  24.9429\n",
      "     29        0.3203  24.7490\n",
      "     30        \u001b[36m0.2882\u001b[0m  24.5366\n",
      "     31        0.2892  24.5269\n",
      "     32        \u001b[36m0.2875\u001b[0m  25.0516\n",
      "     33        \u001b[36m0.2841\u001b[0m  24.7901\n",
      "     34        0.2962  25.1457\n",
      "     35        \u001b[36m0.2803\u001b[0m  24.8645\n",
      "     36        \u001b[36m0.2651\u001b[0m  25.2282\n",
      "     37        \u001b[36m0.2646\u001b[0m  24.9553\n",
      "     38        \u001b[36m0.2498\u001b[0m  25.3649\n",
      "     39        \u001b[36m0.2475\u001b[0m  24.6909\n",
      "     40        0.2578  24.6789\n",
      "     41        \u001b[36m0.2435\u001b[0m  25.2355\n",
      "     42        \u001b[36m0.2423\u001b[0m  25.1955\n",
      "     43        0.2452  25.0878\n",
      "     44        \u001b[36m0.2382\u001b[0m  24.9612\n",
      "     45        \u001b[36m0.2197\u001b[0m  24.8874\n",
      "     46        0.3057  24.9279\n",
      "     47        0.2850  25.2138\n",
      "     48        0.2291  24.9648\n",
      "     49        0.2278  25.5890\n",
      "     50        \u001b[36m0.2062\u001b[0m  25.3607\n",
      "     51        \u001b[36m0.1870\u001b[0m  26.2671\n",
      "     52        0.1904  25.0277\n",
      "     53        \u001b[36m0.1634\u001b[0m  24.8999\n",
      "     54        0.2191  25.7152\n",
      "     55        0.1676  25.1051\n",
      "     56        \u001b[36m0.1590\u001b[0m  24.9539\n",
      "     57        \u001b[36m0.1495\u001b[0m  25.1123\n",
      "     58        0.1752  25.1569\n",
      "     59        \u001b[36m0.1493\u001b[0m  25.5648\n",
      "     60        0.1499  24.9845\n",
      "     61        \u001b[36m0.1343\u001b[0m  24.9605\n",
      "     62        0.1490  24.9174\n",
      "     63        0.1646  24.9983\n",
      "     64        0.1355  25.0741\n",
      "     65        \u001b[36m0.1237\u001b[0m  25.0984\n",
      "     66        0.1255  25.0401\n",
      "     67        \u001b[36m0.1180\u001b[0m  25.0326\n",
      "     68        \u001b[36m0.0957\u001b[0m  25.0884\n",
      "     69        0.1139  25.0321\n",
      "     70        0.1030  25.0017\n",
      "     71        \u001b[36m0.0939\u001b[0m  24.9204\n",
      "     72        0.0999  24.9181\n",
      "     73        \u001b[36m0.0835\u001b[0m  25.0463\n",
      "     74        0.1037  25.0048\n",
      "     75        \u001b[36m0.0829\u001b[0m  25.7681\n",
      "     76        0.0842  25.5666\n",
      "     77        0.1005  25.6593\n",
      "     78        0.0939  25.3958\n",
      "     79        0.0919  25.4053\n",
      "     80        \u001b[36m0.0748\u001b[0m  25.1223\n",
      "[CV 2/5] END batch_size=32, lr=0.01, max_epochs=80;, score=0.907 total time=33.9min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5790\u001b[0m  24.7897\n",
      "      2        \u001b[36m0.3923\u001b[0m  24.9488\n",
      "      3        0.4455  25.0458\n",
      "      4        0.4162  25.6838\n",
      "      5        \u001b[36m0.3923\u001b[0m  25.3578\n",
      "      6        \u001b[36m0.3799\u001b[0m  25.1887\n",
      "      7        \u001b[36m0.3583\u001b[0m  26.2345\n",
      "      8        \u001b[36m0.3561\u001b[0m  28.1120\n",
      "      9        0.3574  24.8531\n",
      "     10        \u001b[36m0.3530\u001b[0m  24.7157\n",
      "     11        \u001b[36m0.3519\u001b[0m  25.3224\n",
      "     12        \u001b[36m0.3422\u001b[0m  24.9791\n",
      "     13        0.3642  28.3949\n",
      "     14        \u001b[36m0.3305\u001b[0m  25.9943\n",
      "     15        \u001b[36m0.3267\u001b[0m  24.7062\n",
      "     16        0.3401  24.7330\n",
      "     17        0.3415  24.4760\n",
      "     18        0.3341  24.4268\n",
      "     19        \u001b[36m0.3183\u001b[0m  24.7756\n",
      "     20        0.3388  24.5158\n",
      "     21        0.3260  25.8778\n",
      "     22        \u001b[36m0.3160\u001b[0m  25.0380\n",
      "     23        0.3418  24.5471\n",
      "     24        \u001b[36m0.3134\u001b[0m  24.5395\n",
      "     25        0.3272  24.4882\n",
      "     26        0.3184  25.0210\n",
      "     27        \u001b[36m0.3030\u001b[0m  25.1967\n",
      "     28        \u001b[36m0.3020\u001b[0m  25.6196\n",
      "     29        \u001b[36m0.2960\u001b[0m  25.0471\n",
      "     30        0.2967  24.7512\n",
      "     31        \u001b[36m0.2895\u001b[0m  25.1269\n",
      "     32        0.2995  25.4198\n",
      "     33        0.3036  25.2551\n",
      "     34        \u001b[36m0.2847\u001b[0m  25.0358\n",
      "     35        \u001b[36m0.2611\u001b[0m  24.6889\n",
      "     36        0.2757  24.8198\n",
      "     37        0.2717  25.5629\n",
      "     38        0.2765  24.8427\n",
      "     39        \u001b[36m0.2536\u001b[0m  24.9066\n",
      "     40        0.2681  24.9174\n",
      "     41        0.2596  24.8648\n",
      "     42        \u001b[36m0.2476\u001b[0m  24.8695\n",
      "     43        \u001b[36m0.2298\u001b[0m  25.1076\n",
      "     44        0.2389  25.0620\n",
      "     45        \u001b[36m0.2083\u001b[0m  25.5471\n",
      "     46        0.2306  25.3412\n",
      "     47        0.2257  24.8601\n",
      "     48        \u001b[36m0.1967\u001b[0m  25.5448\n",
      "     49        0.2166  24.9344\n",
      "     50        0.2003  25.2540\n",
      "     51        \u001b[36m0.1860\u001b[0m  25.3178\n",
      "     52        0.2340  25.7979\n",
      "     53        \u001b[36m0.1587\u001b[0m  25.2042\n",
      "     54        0.1754  25.3144\n",
      "     55        0.1594  26.0854\n",
      "     56        \u001b[36m0.1521\u001b[0m  25.2282\n",
      "     57        \u001b[36m0.1397\u001b[0m  25.9492\n",
      "     58        0.1534  26.4610\n",
      "     59        \u001b[36m0.1382\u001b[0m  24.8393\n",
      "     60        \u001b[36m0.1040\u001b[0m  25.1422\n",
      "     61        0.1577  24.9870\n",
      "     62        0.2727  25.0572\n",
      "     63        0.1524  24.9154\n",
      "     64        0.1667  25.4206\n",
      "     65        0.1449  25.1779\n",
      "     66        0.1419  25.3998\n",
      "     67        0.1960  25.7851\n",
      "     68        0.1412  25.7013\n",
      "     69        0.1588  25.8654\n",
      "     70        0.1229  26.0345\n",
      "     71        \u001b[36m0.0997\u001b[0m  27.7136\n",
      "     72        0.1018  24.9657\n",
      "     73        \u001b[36m0.0937\u001b[0m  24.8622\n",
      "     74        0.0941  25.2434\n",
      "     75        0.0948  25.4031\n",
      "     76        \u001b[36m0.0822\u001b[0m  24.9746\n",
      "     77        0.1297  24.6741\n",
      "     78        0.1132  24.6739\n",
      "     79        0.1183  24.6737\n",
      "     80        0.0839  24.6717\n",
      "[CV 3/5] END batch_size=32, lr=0.01, max_epochs=80;, score=0.938 total time=34.1min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4955\u001b[0m  24.2652\n",
      "      2        \u001b[36m0.4037\u001b[0m  24.3133\n",
      "      3        \u001b[36m0.3879\u001b[0m  24.2321\n",
      "      4        \u001b[36m0.3860\u001b[0m  24.2339\n",
      "      5        \u001b[36m0.3785\u001b[0m  24.2529\n",
      "      6        \u001b[36m0.3710\u001b[0m  24.3363\n",
      "      7        0.4101  24.3269\n",
      "      8        0.3781  24.2861\n",
      "      9        0.3781  24.3592\n",
      "     10        \u001b[36m0.3444\u001b[0m  24.3938\n",
      "     11        0.3495  24.3907\n",
      "     12        \u001b[36m0.3435\u001b[0m  24.3826\n",
      "     13        0.3602  24.2434\n",
      "     14        0.3577  24.2800\n",
      "     15        0.3551  24.3219\n",
      "     16        \u001b[36m0.3229\u001b[0m  24.3317\n",
      "     17        0.3390  24.4126\n",
      "     18        0.3278  24.4161\n",
      "     19        0.3243  24.4516\n",
      "     20        \u001b[36m0.3080\u001b[0m  24.4126\n",
      "     21        0.3146  24.4836\n",
      "     22        0.3088  24.4625\n",
      "     23        \u001b[36m0.2974\u001b[0m  24.4545\n",
      "     24        0.2996  24.4734\n",
      "     25        \u001b[36m0.2888\u001b[0m  24.3832\n",
      "     26        0.2956  24.4323\n",
      "     27        \u001b[36m0.2855\u001b[0m  24.4151\n",
      "     28        0.2969  24.4563\n",
      "     29        \u001b[36m0.2756\u001b[0m  24.4132\n",
      "     30        \u001b[36m0.2550\u001b[0m  24.4312\n",
      "     31        0.2684  24.5000\n",
      "     32        \u001b[36m0.2458\u001b[0m  24.5818\n",
      "     33        0.2855  24.5638\n",
      "     34        0.2631  24.5009\n",
      "     35        \u001b[36m0.2282\u001b[0m  24.5373\n",
      "     36        0.2701  24.5571\n",
      "     37        \u001b[36m0.2244\u001b[0m  24.5409\n",
      "     38        0.2560  24.6520\n",
      "     39        0.2747  24.5871\n",
      "     40        \u001b[36m0.2109\u001b[0m  24.6214\n",
      "     41        \u001b[36m0.2046\u001b[0m  24.7129\n",
      "     42        \u001b[36m0.2010\u001b[0m  24.7667\n",
      "     43        \u001b[36m0.1931\u001b[0m  24.8634\n",
      "     44        \u001b[36m0.1811\u001b[0m  24.7523\n",
      "     45        0.1995  24.7878\n",
      "     46        \u001b[36m0.1545\u001b[0m  24.7957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     47        0.1659  24.8549\n",
      "     48        0.2012  24.8047\n",
      "     49        \u001b[36m0.1495\u001b[0m  24.8162\n",
      "     50        0.1593  24.7863\n",
      "     51        0.1537  24.8109\n",
      "     52        \u001b[36m0.1494\u001b[0m  24.8425\n",
      "     53        0.1547  24.9278\n",
      "     54        0.1615  25.3637\n",
      "     55        \u001b[36m0.1356\u001b[0m  26.3155\n",
      "     56        0.1824  25.1045\n",
      "     57        0.1515  25.1084\n",
      "     58        \u001b[36m0.1135\u001b[0m  25.0848\n",
      "     59        0.1389  25.0525\n",
      "     60        \u001b[36m0.1072\u001b[0m  25.1725\n",
      "     61        0.1154  25.1691\n",
      "     62        \u001b[36m0.1049\u001b[0m  25.1833\n",
      "     63        \u001b[36m0.0844\u001b[0m  25.1939\n",
      "     64        0.0954  25.6355\n",
      "     65        0.1186  26.0692\n",
      "     66        0.1102  25.8550\n",
      "     67        0.1086  25.3050\n",
      "     68        \u001b[36m0.0711\u001b[0m  25.8235\n",
      "     69        0.0713  25.5491\n",
      "     70        0.0774  26.0517\n",
      "     71        0.1203  25.3315\n",
      "     72        0.1129  25.2547\n",
      "     73        0.0879  25.2459\n",
      "     74        0.0808  25.2682\n",
      "     75        \u001b[36m0.0657\u001b[0m  25.3155\n",
      "     76        \u001b[36m0.0466\u001b[0m  25.4185\n",
      "     77        0.0735  25.3496\n",
      "     78        0.0810  25.2268\n",
      "     79        0.0608  25.2645\n",
      "     80        0.0836  25.3443\n",
      "[CV 4/5] END batch_size=32, lr=0.01, max_epochs=80;, score=0.901 total time=33.5min\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.5077\u001b[0m  24.4248\n",
      "      2        \u001b[36m0.4080\u001b[0m  24.3854\n",
      "      3        \u001b[36m0.3836\u001b[0m  24.4045\n",
      "      4        0.3848  24.4450\n",
      "      5        \u001b[36m0.3540\u001b[0m  24.4361\n",
      "      6        0.3602  24.5244\n",
      "      7        0.3635  25.0300\n",
      "      8        0.3694  24.7011\n",
      "      9        0.3665  24.3832\n",
      "     10        0.3549  24.3718\n",
      "     11        \u001b[36m0.3534\u001b[0m  24.4488\n",
      "     12        0.3665  24.4422\n",
      "     13        \u001b[36m0.3415\u001b[0m  24.4497\n",
      "     14        0.3427  24.4566\n",
      "     15        \u001b[36m0.3394\u001b[0m  24.4388\n",
      "     16        \u001b[36m0.3387\u001b[0m  24.4544\n",
      "     17        \u001b[36m0.3268\u001b[0m  24.5488\n",
      "     18        \u001b[36m0.3219\u001b[0m  24.4364\n",
      "     19        \u001b[36m0.3082\u001b[0m  24.5366\n",
      "     20        \u001b[36m0.3075\u001b[0m  24.6786\n",
      "     21        0.3152  24.7128\n",
      "     22        \u001b[36m0.2998\u001b[0m  25.4020\n",
      "     23        0.3017  25.4676\n",
      "     24        0.3009  24.4191\n",
      "     25        \u001b[36m0.2977\u001b[0m  24.3561\n",
      "     26        \u001b[36m0.2841\u001b[0m  24.3086\n",
      "     27        0.3159  24.4462\n",
      "     28        0.2992  24.2879\n",
      "     29        0.2863  24.4317\n",
      "     30        0.2846  24.3718\n",
      "     31        0.2883  24.4571\n",
      "     32        \u001b[36m0.2686\u001b[0m  24.5481\n",
      "     33        \u001b[36m0.2672\u001b[0m  24.7974\n",
      "     34        \u001b[36m0.2596\u001b[0m  24.4486\n",
      "     35        0.2681  24.4917\n",
      "     36        \u001b[36m0.2590\u001b[0m  24.5177\n",
      "     37        0.2905  24.7028\n",
      "     38        0.2595  24.7297\n",
      "     39        \u001b[36m0.2484\u001b[0m  24.6766\n",
      "     40        0.2754  24.8263\n",
      "     41        \u001b[36m0.2422\u001b[0m  24.7927\n",
      "     42        0.2509  24.8575\n",
      "     43        \u001b[36m0.2191\u001b[0m  24.7805\n",
      "     44        0.2475  24.7901\n",
      "     45        0.2199  24.7590\n",
      "     46        0.2208  24.7761\n",
      "     47        \u001b[36m0.2165\u001b[0m  24.7061\n",
      "     48        \u001b[36m0.1987\u001b[0m  24.7361\n",
      "     49        0.2026  24.7454\n",
      "     50        0.2157  24.8336\n",
      "     51        \u001b[36m0.1982\u001b[0m  24.8579\n",
      "     52        \u001b[36m0.1952\u001b[0m  24.8064\n",
      "     53        0.1978  24.8650\n",
      "     54        0.1998  24.8720\n",
      "     55        \u001b[36m0.1855\u001b[0m  24.9383\n",
      "     56        \u001b[36m0.1745\u001b[0m  24.9764\n",
      "     57        \u001b[36m0.1612\u001b[0m  24.8940\n",
      "     58        0.1761  24.8925\n",
      "     59        0.1655  24.8945\n",
      "     60        0.1681  24.9247\n",
      "     61        0.1669  24.9247\n",
      "     62        0.1686  24.8880\n",
      "     63        \u001b[36m0.1373\u001b[0m  25.0402\n",
      "     64        0.1552  24.8374\n",
      "     65        0.1424  24.8929\n",
      "     66        0.1627  24.8964\n",
      "     67        \u001b[36m0.1250\u001b[0m  24.9359\n",
      "     68        0.1565  24.8645\n",
      "     69        0.1413  24.8209\n",
      "     70        0.1562  24.8725\n",
      "     71        \u001b[36m0.1153\u001b[0m  24.8585\n",
      "     72        0.1272  24.8658\n",
      "     73        0.1310  24.9138\n",
      "     74        0.1316  24.8585\n",
      "     75        0.1375  24.9238\n",
      "     76        0.1181  24.8893\n",
      "     77        \u001b[36m0.0939\u001b[0m  24.9048\n",
      "     78        \u001b[36m0.0835\u001b[0m  24.9339\n",
      "     79        0.1031  24.9093\n",
      "     80        0.0966  24.9846\n",
      "[CV 5/5] END batch_size=32, lr=0.01, max_epochs=80;, score=0.882 total time=33.4min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_max_epochs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1149.204040</td>\n",
       "      <td>28.791707</td>\n",
       "      <td>13.045013</td>\n",
       "      <td>0.370769</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.001, 'max_epochs': 40}</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.898758</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1681.458399</td>\n",
       "      <td>21.375225</td>\n",
       "      <td>12.913659</td>\n",
       "      <td>0.377485</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.001, 'max_epochs': 60}</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.910559</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2221.969596</td>\n",
       "      <td>3.378738</td>\n",
       "      <td>12.819789</td>\n",
       "      <td>0.432096</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.001, 'max_epochs': 80}</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.916770</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1129.347267</td>\n",
       "      <td>4.466733</td>\n",
       "      <td>12.909704</td>\n",
       "      <td>0.391310</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.01, 'max_epochs': 40}</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.880745</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1707.554254</td>\n",
       "      <td>32.336747</td>\n",
       "      <td>13.257086</td>\n",
       "      <td>0.995476</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.01, 'max_epochs': 60}</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.878882</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2273.645899</td>\n",
       "      <td>22.463364</td>\n",
       "      <td>12.972561</td>\n",
       "      <td>0.389849</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>80</td>\n",
       "      <td>{'batch_size': 16, 'lr': 0.01, 'max_epochs': 80}</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.911801</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>990.647284</td>\n",
       "      <td>3.929943</td>\n",
       "      <td>12.811673</td>\n",
       "      <td>0.336206</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.001, 'max_epochs': 40}</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.888199</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.888199</td>\n",
       "      <td>0.902484</td>\n",
       "      <td>0.020088</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1481.331152</td>\n",
       "      <td>5.487078</td>\n",
       "      <td>12.892663</td>\n",
       "      <td>0.316047</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.001, 'max_epochs': 60}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.906211</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1971.130551</td>\n",
       "      <td>4.801546</td>\n",
       "      <td>12.831889</td>\n",
       "      <td>0.371756</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.001, 'max_epochs': 80}</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.918634</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>998.108085</td>\n",
       "      <td>5.765190</td>\n",
       "      <td>12.892324</td>\n",
       "      <td>0.373880</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.01, 'max_epochs': 40}</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.867081</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1495.120297</td>\n",
       "      <td>6.693886</td>\n",
       "      <td>12.861754</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.01, 'max_epochs': 60}</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015.304704</td>\n",
       "      <td>17.182463</td>\n",
       "      <td>12.928282</td>\n",
       "      <td>0.355020</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>80</td>\n",
       "      <td>{'batch_size': 32, 'lr': 0.01, 'max_epochs': 80}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.899379</td>\n",
       "      <td>0.023373</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     1149.204040     28.791707        13.045013        0.370769   \n",
       "1     1681.458399     21.375225        12.913659        0.377485   \n",
       "2     2221.969596      3.378738        12.819789        0.432096   \n",
       "3     1129.347267      4.466733        12.909704        0.391310   \n",
       "4     1707.554254     32.336747        13.257086        0.995476   \n",
       "5     2273.645899     22.463364        12.972561        0.389849   \n",
       "6      990.647284      3.929943        12.811673        0.336206   \n",
       "7     1481.331152      5.487078        12.892663        0.316047   \n",
       "8     1971.130551      4.801546        12.831889        0.371756   \n",
       "9      998.108085      5.765190        12.892324        0.373880   \n",
       "10    1495.120297      6.693886        12.861754        0.313772   \n",
       "11    2015.304704     17.182463        12.928282        0.355020   \n",
       "\n",
       "   param_batch_size param_lr param_max_epochs  \\\n",
       "0                16    0.001               40   \n",
       "1                16    0.001               60   \n",
       "2                16    0.001               80   \n",
       "3                16     0.01               40   \n",
       "4                16     0.01               60   \n",
       "5                16     0.01               80   \n",
       "6                32    0.001               40   \n",
       "7                32    0.001               60   \n",
       "8                32    0.001               80   \n",
       "9                32     0.01               40   \n",
       "10               32     0.01               60   \n",
       "11               32     0.01               80   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'batch_size': 16, 'lr': 0.001, 'max_epochs': 40}           0.900621   \n",
       "1   {'batch_size': 16, 'lr': 0.001, 'max_epochs': 60}           0.906832   \n",
       "2   {'batch_size': 16, 'lr': 0.001, 'max_epochs': 80}           0.897516   \n",
       "3    {'batch_size': 16, 'lr': 0.01, 'max_epochs': 40}           0.881988   \n",
       "4    {'batch_size': 16, 'lr': 0.01, 'max_epochs': 60}           0.891304   \n",
       "5    {'batch_size': 16, 'lr': 0.01, 'max_epochs': 80}           0.881988   \n",
       "6   {'batch_size': 32, 'lr': 0.001, 'max_epochs': 40}           0.903727   \n",
       "7   {'batch_size': 32, 'lr': 0.001, 'max_epochs': 60}           0.913043   \n",
       "8   {'batch_size': 32, 'lr': 0.001, 'max_epochs': 80}           0.922360   \n",
       "9    {'batch_size': 32, 'lr': 0.01, 'max_epochs': 40}           0.854037   \n",
       "10   {'batch_size': 32, 'lr': 0.01, 'max_epochs': 60}           0.900621   \n",
       "11   {'batch_size': 32, 'lr': 0.01, 'max_epochs': 80}           0.869565   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.937888           0.897516           0.906832   \n",
       "1            0.922360           0.900621           0.897516   \n",
       "2            0.928571           0.934783           0.916149   \n",
       "3            0.928571           0.854037           0.891304   \n",
       "4            0.903727           0.897516           0.906832   \n",
       "5            0.922360           0.913043           0.919255   \n",
       "6            0.940994           0.888199           0.891304   \n",
       "7            0.947205           0.891304           0.903727   \n",
       "8            0.922360           0.928571           0.922360   \n",
       "9            0.875776           0.847826           0.891304   \n",
       "10           0.919255           0.903727           0.897516   \n",
       "11           0.906832           0.937888           0.900621   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.850932         0.898758        0.027888                9  \n",
       "1            0.925466         0.910559        0.011351                4  \n",
       "2            0.906832         0.916770        0.013665                2  \n",
       "3            0.847826         0.880745        0.028974               11  \n",
       "4            0.878882         0.895652        0.009938               10  \n",
       "5            0.922360         0.911801        0.015290                3  \n",
       "6            0.888199         0.902484        0.020088                7  \n",
       "7            0.875776         0.906211        0.024008                5  \n",
       "8            0.897516         0.918634        0.010830                1  \n",
       "9            0.866460         0.867081        0.015516               12  \n",
       "10           0.906832         0.905590        0.007505                6  \n",
       "11           0.881988         0.899379        0.023373                8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x_, outputs)\n",
    "\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwyjqEG8zAmg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "10_04_try_cbam_add_tabular_gridsearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
